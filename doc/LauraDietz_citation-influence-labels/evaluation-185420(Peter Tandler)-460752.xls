Evaluation sheet		v0.1			
		Abstract	Authors	Title	
citingPub	460752	In ubiquitous computing environments, multiple users work with a wide range of different devices. In many cases, users interact and collaborate using multiple heterogeneous devices at the same time. The configuration of the devices should be able to change frequently due to a highly dynamic, flexible and mobile nature of new work practices. This produces new requirements for the architecture of an appropriate software infrastructure. In this paper, an architecture designed to meet these requirements is proposed. To test its applicability, this architecture was used as the basis for the implementation of BEACH, the software infrastructure of i-LAND (the ubiquitous computing environment at GMD-IPSI). It provides the functionality for synchronous cooperation and interaction with roomware components, i.e. room elements with integrated information technology. In conclusion, our experiences with the current implementation are presented.<	Peter Tandler	Software Infrastructure for Ubiquitous Computing Environments: Supporting Synchronous Collaboration with Heterogeneous Devices	
evalAuthor	185420		Peter Tandler		

Evaluation Legend					
xx	strongly influenced				
x	influenced				
o	not really influenced				
oo	unrelated				
?	can't judge				

Evaluation					
======	id	Abstract	Authors	Title	SELF-CITATION
xx	412180	This article introduces a new interaction model called Instrumental Interaction that extends and generalizes the  principles of direct manipulation. It covers existing  interaction styles, including traditional WIMP interfaces, as  well as new interaction styles such as two-handed input and  augmented reality. It defines a design space for new  interaction techniques and a set of properties for comparing  them. Instrumental Interaction describes graphical user  interfaces in terms of domain objects and interaction  instruments. Interaction between users and domain objects  is mediated by interaction instruments, similar to the tools  and instruments we use in the real world to interact with  physical objects. The article presents the model, applies it  to describe and compare a number of interaction techniques,  and shows how it was used to create a new interface for  searching and replacing text.  Keywords  Interaction model, WIMP interfaces, direct manipulation,  post-WIMP interfaces, instrumental ...	Michel Beaudouin-lafon	Instrumental Interaction: An Interaction Model for Designing Post-WIMP User Interfaces	
xx	260090	"We are investigating how people move from individual to group work through the use of both personal digital  assistants (PDAs) and a shared public display. Our scenario  of this work covers the following activities. First, mobile  individuals can create ""personal"" notes on their PDAs.  Second, when individuals meet in real time, they can  selectively ""publicize"" notes by moving them to a shared  public display. Third, the group can manipulate personal  and public items in real time through both PDAs and the  shared public display, where the notes contained on both  PDAs and public display are automatically synchronized.  Finally, people leave a meeting with a common record of  their activity. We describe our SharedNotes system that  illustrates how people move through this scenario. We also  highlight a variety of problematic design issues that result  from having different devices and from having the system  enforce a rigid distinction between personal and public  information.  Keywords  Personal dig..."	Jason Laberge, Michael Boyle, Saul Greenberg	PDAs and Shared Public Displays: Making Personal Information Public, and Public Information Personal	
xx	229556	A major difficulty in writing Single Display Groupware (co-present collaborative) applications is getting input from multiple devices. We introduce MID, a Java package that addresses this problem and offers an architecture to access advanced events through Java. In this paper, we describe the features, architecture and limitations of MID. We also briefly describe an application that uses MID to get input from multiple mice: KidPad. Keywords Single Display Groupware (SDG), Computer-Supported Cooperative Work (CSCW), Multiple Input Devices (MID), Multi-Modal Input, Java, DirectInput, Windows 98, Universal Serial Bus (USB), KidPad, Jazz, Pad++. INTRODUCTION Communication, collaboration, and coordination are brought to many people's desktops thanks to groupware applications such as Lotus Notes and Microsoft Exchange, some of the leading commercial products in the field of Computer-Supported Cooperative Work (CSCW). They help people collaborate when they are not in the same place at th...<	Benjamin B. Bederson, Juan Pablo Hourcade	Architecture and Implementation of a Java Package for Multiple Input Devices (MID)	
o	239716	"This paper presents our vision of Human Computer Interaction (HCI): ""Tangible Bits."" Tangible Bits allows  users to ""grasp &amp; manipulate"" bits in the center of users'  attention by coupling the bits with everyday physical  objects and architectural surfaces. Tangible Bits also  enables users to be aware of background bits at the  periphery of human perception using ambient display media  such as light, sound, airflow, and water movement in an  augmented space. The goal of Tangible Bits is to bridge  the gaps between both cyberspace and the physical  environment, as well as the foreground and background of  human activities.  This paper describes three key concepts of Tangible Bits:  interactive surfaces; the coupling of bits with graspable  physical objects; and ambient media for background  awareness. We illustrate these concepts with three  prototype systems -- the metaDESK, transBOARD and  ambientROOM -- to identify underlying research issues.  Keywords  tangible user interface, ambient media, gras..."	Brygg Ullmer, Hitoshi Ishii	Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms	
o	81310	Today's interface design tools either force designers to handle a tremendous number of design details, or limit their control over design decisions. Neither of these approaches taps the true strengths of either human designers or computers in the design process. This paper presents a human-computer collaborative system that uses a modelbased approach for interface design to help designers search the design space effectively and construct executable specifications of application user interfaces. This human-inthe -loop environment focuses human designers on decision making, and utilizes the bookkeeping capabilities of computers for regular and tedious tasks. We describe (a) the underlying modeling technique and an execution environment that allows even incompletely-specified designs to be executed for evaluation and testing purposes, and (b) a tool that decomposes high-level design goals into the necessary implementation steps, and helps designers manage the myriad of details that arise ...<	Pedro Szekely, Ping Luo, Robert Neches	Management Of Interface Design In Humanoid	
o	291862	Interfaces based on recognition technologies are used extensively in both the commercial and research worlds.  But recognizers are still error-prone, and this results in  human performance problems, brittle dialogues, and other  barriers to acceptance and utility of recognition systems.  Interface techniques specialized to recognition systems can  help reduce the burden of recognition errors, but building  these interfaces depends on knowledge about the ambiguity  inherent in recognition. We have extended a user interface  toolkit in order to model and to provide structured support  for ambiguity at the input event level. This makes it  possible to build re-usable interface components for  resolving ambiguity and dealing with recognition errors.  These interfaces can help to reduce the negative effects of  recognition errors. By providing these components at a  toolkit level, we make it easier for application writers to  provide good support for error handling. Further, with  this robust support, we a...	G. D. Abowd, Jen Mankoff, Scott Hudson	Providing Integrated Toolkit-Level Support for Ambiguity in Recognition-Based Interfaces	
x	24358	"The Amulet user interface development environment makes it easier for programmers to create highly-interactive, graphical user interface software for Unix, Windows or the  Macintosh. Amulet uses new models for objects, constraints, animation, input, output,  commands, and undo. The object system is a prototype-instance model in which there is  no distinction between classes and instances or between methods and data. The constraint  system allows any value of any object to be computed by arbitrary code and supports  multiple constraint solvers. Animations can be attached to existing objects with a single  line of code. Input from the user is handled by ""interactor"" objects which support reuse of  behavior objects. The output model provides a declarative definition of the graphics and  supports automatic refresh. Command objects encapsulate all of the information needed  about operations, including support for various ways to undo them. A key feature of the  Amulet design is that all graphical obj..."	Alan Ferrency, Alex Klimovitski, Andrew Faulring, Andy Mickish, Brad A. Myers, Bruce Kyle, Ellen Borison, Patrick Doane, Rich Mcdaniel, R. J. Miller	The Amulet Environment: New Models for Effective User Interface Software Development	
o	295834	In this paper, we describe the process behind the design of Audio Aura. The goal of Audio Aura is to provide  serendipitous information, via background auditory cues,  that is tied to people's physical actions in the workplace. We  used scenarios to explore issues in serendipitous  information such as privacy and work practice. Our sound  design was guided by a number of strategies for creating  peripheral sounds grouped in cohesive ecologies. Faced  with an physical and software infrastructure under  development in a laboratory distant from our sound studio,  we prototyped different sonic landscapes in VRML worlds.  In our infrastructure design, we made a number of trade-offs  in our use of legacy systems and our client-server design.  Keywords: Audio, Augmented Reality, Auditory Icons,  Active Badge, VRML. Earcons, Awareness, Periphery  INTRODUCTION  In this work we explore using audio to connect a person's  activities in the physical world with information culled from  the virtual ...	Elizabeth D. Mynatt, Jason B. Ellis, Maribeth Back, Michael Baer, Roy Want	Designing Audio Aura	
xx	378845	Context-enabled applications are just emerging and promise richer interaction by taking environmental context  into account. However, they are difficult to build due to  their distributed nature and the use of unconventional  sensors. The concepts of toolkits and widget libraries in  graphical user interfaces has been tremendously successful,  allowing programmers to leverage off existing building  blocks to build interactive systems more easily. We  introduce the concept of context widgets that mediate  between the environment and the application in the same  way graphical widgets mediate between the user and the  application. We illustrate the concept of context widgets  with the beginnings of a widget library we have developed  for sensing presence, identity and activity of people and  things. We assess the success of our approach with two  example context-enabled applications we have built and an  existing application to which we have added contextsensing  capabilities.  Keywords  Context-enabled ...	Anind K. Dey, Daniel Salber, G. D. Abowd	The Context Toolkit: Aiding the Development of Context-Enabled Applications	
xx	181141	We introduce a model for supporting collaborative work between people that are physically close to each other. We call this model Single Display Groupware (SDG). In this paper, we describe this model, comparing it to more traditional remote  collaboration. We describe the requirements that SDG places on computer technology, and our understanding of the benefits  and costs of SDG systems. Finally, we describe a prototype SDG system that we built and the results of a usability test we  ran with 60 elementary school children.  Keywords  CSCW, Single Display Groupware, children, educational applications, input devices, Pad++, KidPad.  INTRODUCTION  In the early 1970's, researchers at Xerox PARC created an atmosphere in which they lived and worked with technology of the  future. When the world's first personal computer, the Alto, was invented, it had only a single keyboard and mouse. This  fundamental design legacy has carried through to nearly all modern computer systems. Although networks have...	Allison Druin, Benjamin B. Bederson, Jason Stewart	Single Display Groupware: A Model for Co-present Collaboration	
xx	176607	This paper describes DOLPHIN, a fully group aware application designed to provide computer support for  different types of meetings: face--to--face meetings with  a large interactive electronic whiteboard with or  without networked computers provided to the  participants, extensions of these meetings with remote  participants at their desktop computers connected via  computer and audio/video networks and/ or participants  in a second meeting room also provided with an  electronic whiteboard and networked computers.  DOLPHIN supports the creation and manipulation of  informal structures (e.g. free hand drawings,  handwritten scribbles) as well as formal structures (e.g.  hypermedia documents with typed nodes and links) and  their coexistence and transformation.  KEYWORDS: electronic meeting rooms, document--  based cooperation, shared workspaces, collaborative  writing/drawing, brainstorming, planning, hypermedia,  pen--based interaction, interactive whiteboards  1 INTRODUCTION  Cooperation of people can ...	Jeroen Hol, Jorg M. Haake, Norbert A. Streitz, Jeroen Hol, Jorg M. Haake, Norbert A. Streitz	DOLPHIN: Integrated Meeting Support across LiveBoards, Local and Remote Desktop Environments	x
xx	423611	In the past, a central mainframe computer provided terminals for many users. In the current age of the personal desktop computer, there is one computer for one person. Observation of early adopters and predictions about the future point to an era where each person will have multiple devices and computational power will be ubiquitous. Against this background, we present a vision for the workspaces of the future and a user-centered approach for an integrated design of virtual information spaces and real architectural spaces. The resulting environments are called cooperative buildings. The design approach is based on the roomware concept. By roomware, we mean computer-augmented objects resulting from the integration of room elements, e.g., walls, doors, furniture (tables, chairs, etc.) with computer-based information devices. They are part of the vision that the world around us will be the interface to information -- where the computer as a device will disappear and people's interaction w...<	Christian Mller-tomfelde, Norbert A. Streitz, Tobias Peter	Roomware: Towards the next generation of human-computer interaction based on an integrated design of real and virtual worlds	x
o	429819	HUMANOID is a user interface design tool that lets designers express abstract conceptualizations of an interface in an executable  form, allowing designers to experiment with scenarios  and dialogues even before the application model is  completely worked out. Three properties of the HUMANOID  approach allow it to do so: a modularization of design issues  into independent dimensions, support for multiple levels of  specificity in mapping application models to user interface  constructs, and mechanisms for constructing executable default  user interface implementations from whatever level of  specificity has been provided by the designer.  KEYWORDS: Design Processes, Development Tools and  Methods, User Interface Management Systems, Rapid Prototyping,  Interface Design Representation, Dialogue Specification.  INTRODUCTION  Interface design really begins much earlier than current  tools recognize. Long before a designer is ready to experiment  with presentation issues like the layout of widgets chosen...	Pedro Szekely, Ping Luo, Robert Neches	Facilitating the Exploration of Interface Design Alternatives: The HUMANOID Model of Interface Design	
x	385223	This paper introduces the notion of plasticity, a new property of interactive systems that denotes a particular type of user interface adaptation. Plasticity is the capacity of a user interface to withstand variations of both the system physical characteristics and the environment while preserving usability. Typically, a `plastic' electronic agenda would run both on a workstation and on a hand-held computer without requiring a complete system redesign and re-implementation. We present a generic framework inspired by the model-based approach, for supporting the development of plastic user interfaces. Within this framework, a plastic user interface is specified once and serves multiple sources of physical variations. The goal is to guarantee usability continuity under variations in physical constraints while minimizing development and maintenance costs. This framework is illustrated with two simple case studies. Preliminary results and the state of the art in HCI open a new research ag...<	Martina Angela Sasse, Chris Johnson, David Thevenin, Jo Coutaz	Plasticity of User Interfaces: Framework and Research Agenda	
======					
