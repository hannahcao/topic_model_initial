Evaluation sheet		v0.1		
		Abstract	Authors	Title
citingPub	35995	In order to rank the performance of machine learning algorithms, many researchers conduct  experiments on benchmark data sets. Since  most learning algorithms have domain-specific  parameters, it is a popular custom to adapt  these parameters to obtain a minimal error rate  on the test set. The same rate is then used  to rank the algorithm, which causes an optimistic  bias. We quantify this bias, showing,  in particular, that an algorithm with more parameters  will probably be ranked higher than  an equally good algorithm with fewer parameters.  We demonstrate this result, showing the  number of parameters and trials required in order  to pretend to outperform C4.5 or FOIL,  respectively, for various benchmark problems.  We then describe out how unbiased ranking experiments  should be conducted.  1 Introduction  Estimating the accuracy of a classifier is a topic that has  experienced much attention in the ML community. One  of the main results is that N -fold cross validation provides  a bias-free [ Sto74...	Ralf Herbrich, Tobias Scheffer	Unbiased Assessment of Learning Algorithms
evalAuthor	2788		Tobias Scheffer	

Evaluation Legend				
xx	strongly influenced			
x	influenced			
o	not really influenced			
oo	unrelated			
?	can't judge			

Evaluation				
======	id	Abstract	Authors	Title
oo	137427	Finite element methods are used extensively by engineers and modelling scientists to analyse stresses in physical structures. These structures are represented quantitatively as finite collections of elements. The deformation of each element is computed using linear algebraic equations. In order to design a numerical model of a physical structure it is necessary to decide the appropriate resolution for modelling each component part. Considerable expertise is required in choosing these resolution values. Too fine a mesh leads to unnecessary computational overheads when executing the model. Too coarse a mesh produces intolerable approximation errors. In this paper we demonstrate that rules for deciding on appropriate resolution values can be inductively constructed from expert-provided examples. The Inductive Logic Programming algorithm Golem is employed for this purpose. Cross-validation testing of rules produced by Golem in this domain indicate an acuracy of around 79% correct on unseen...<	Bojan Dolsak, S. H. Muggleton	The Application of Inductive Logic Programming to Finite Element Mesh Design
x	356583	In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular domain, a feature subset selection method should consider how the algorithm and the training data interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show improvements over the original design. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter-based approach to feature subset selection. Significant improvement in accuracy on real problems is achieved for the two families of induction algorithms used: decision trees and Naive-Bayes. 1 Intr...<	H.John, Ron Kohavi	Wrappers for Feature Subset Selection
o 	523339	In this doctoral dissertation, we study three basic problems in machine learning and two new hypothesis spaces with corresponding learning algorithms. The problems we investigate are: accuracy estimation, feature subset selection, and parameter tuning. The latter two problems are related and are studied under the wrapper approach. The hypothesis spaces we investigate are: decision tables with a default majority rule (DTMs) and oblivious read-once decision graphs (OODGs).<	Ron Kohavi, Yoav Shoham	Wrappers For Performance Enhancement And Oblivious Decision Graphs
======				
