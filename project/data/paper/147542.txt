147542

#abstract
We exhibit a theoretically founded algorithm T2 for agnostic PAC-learning of decision trees of at  most 2 levels, whose computation time is almost  linear in the size of the training set. We evaluate  the performance of this learning algorithm T2  on 15 common "real-world" datasets, and show  that for most of these datasets T2 provides simple  decision trees with little or no loss in predictive  power (compared with C4.5). In fact, for datasets  with continuous attributes its error rate tends to be  lower than that of C4.5. To the best of our knowledge  this is the first time that a PAC-learning algorithm  is shown to be applicable to "real-world"  classification problems.  Since one can prove that T2 is an agnostic PAClearning  algorithm, T2 is guaranteed to produce  close to optimal 2-level decision trees from sufficiently  large training sets for any (!) distribution  of data. In this regard T2 differs strongly from all  other learning algorithms that are considered in  applied machine learning, for w...
