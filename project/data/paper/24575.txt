24575

#abstract
Previous research has shown that a technique called error-correcting output coding  (ECOC) can dramatically improve the  classification accuracy of supervised learning  algorithms that learn to classify data  points into one of k AE 2 classes. This  paper presents an investigation of why the  ECOC technique works, particularly when  employed with decision-tree learning algorithms.  It shows that the ECOC method---  like any form of voting or committee---can  reduce the variance of the learning algorithm.  Furthermore---unlike methods that  simply combine multiple runs of the same  learning algorithm---ECOC can correct for  errors caused by the bias of the learning algorithm.  Experiments show that this bias  correction ability relies on the non-local behavior  of C4.5.  1 Introduction  Error-correcting output coding (ECOC) is a method  for applying binary (two-class) learning algorithms  to solve k-class supervised learning problems. It  works by converting the k-class supervised learning  problem into a la...
