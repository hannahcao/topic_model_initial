{"user_name":" Graph Indexing: A Frequent Structure-based Approach  ","user_timeline":[{"aspect":"abstract","tweet":" ABSTRACT Graph has become increasingly important in modelling complicated structures and schemaless data such as proteins, chemical compounds, and XML documents. Given a graph query, it is desirable to retrieve graphs quickly from a large database via graph-based indices. In this paper, we investigate the issues of indexing graphs and propose a novel solution by applying a graph mining technique. Different from the existing path-based methods, our approach, called gIndex, makes use of frequent substructure as the basic indexing feature. Frequent substructures are ideal candidates since they explore the intrinsic characteristics of the data and are relatively stable to database updates. To reduce the size of index structure, two techniques, size-increasing support constraint and discriminative fragments, are introduced. Our performance study shows that gIndex has 10 times smaller index size, but achieves 3\u201aÄì10 times better performance in comparison with a typical path-based method, GraphGrep. The gIndex approach not only provides an elegant solution to the graph indexing problem, but also demonstrates how database indexing and query processing can benefit from data mining, especially frequent pattern mining. Furthermore, the concepts developed here can be applied to indexing sequences, trees, and other complicated structures as well. "},{"aspect":"expanalysis","tweet":" 8. CONCLUSIONS Graph indexing plays a critical role at efficient query processing in graph databases which have gained increasing popularity in bioinformatics, Web analysis, and other applications involving complex structures. Previous graphindexing approaches take paths as indexing features and suffer from overly large index size and substantial query processing overhead. In this paper, we have explored a rather different approach to graph indexing: indexing based on frequent subgraph structures. Recent progress in graph mining has turned frequent substructure-based indexing into reality. Using canonical labeling, subgraph structures can be mapped into ordered sequences. By exploring several novel concepts, especially size-increasing support constraint and discriminative structure, frequent subgraph-based indices can be made compact and effective. Also, using the incremental updating property, gIndex can be constructed by a single scan of a database. Our performance study shows that our graph indexing method, gIndex, performs better and consumes less space than the path-based indexing method. This work can be extended to indexing trees, sequences, and other structures based on their underlying frequent patterns in the database. The frequent pattern-based indexing makes indexing adaptable to the data stored in the database and are relatively stable despite of frequent updates. This work also shows that indexing and query processing can really benefit from data mining, which may promote more studies on application of data mining at improving database system performance. 9. ACKNOWLEDGMENTS We would like to thank Rosalba Giugno and Dennis Shasha for providing GraphGrep; and Michihiro Kuramochi and George Karypis for providing the synthetic graph data generator. "},{"aspect":"expdata","tweet":""},{"aspect":"background","tweet":" 1. INTRODUCTION Graphs have become increasingly important in modelling complicated structures and schemaless data such as proteins, circuits, images, Web, and XML documents. Conceptually, any kind of data can be represented by graphs. Besides the prevalent use of XML in Web documents, we also witness \u201aàó This work was supported in part by the U.S. National Science Foundation NSF IIS-02-09199, an IBM Faculty Award, and an IBM Summer Internship. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding agencies. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGMOD 2004 June 13-18, 2004, Paris, France. Copyright 2004 ACM 1-58113-859-8/04/06 . . . $5.00. Xifeng Yan \u201aÄ\u2020 Philip S. Yu \u201aÄ° Jiawei Han \u201aÄ\u2020 \u201aÄ\u2020 Department of Computer Science University of Illinois at Urbana-Champaign {xyan, hanj}@cs.uiuc.edu \u201aÄ° IBM T. J. Watson Research Center psyu@us.ibm.com the wide usage of graph databases in various domains. For example, in computer vision, graphs are used to represent complex relationships, such as the organization of entities in images. These relationships can be used to identify objects and scenes. Efficient retrieval of graph-based models is an essential problem in pattern recognition, as indicated by the wealth of research literature. In chemical informatics and bio-informatics, scientists use graphs to represent compounds and proteins. Daylight system [8], a commercial product for compound registration, has already been used in chemical informatics. Benefiting from such a system, researchers are able to do screening, designing, and knowledge discovery from compound or molecular databases. In the core of many graph-related applications, lies a common and critical problem: how to efficiently process graph queries and retrieve related graphs. In some cases, the success of an application directly relies on the efficiency of the query processing system. The classical graph query problem can be described as follows: Given a graph database D = {g1, g2, . . . , gn} and a graph query q, find all the graphs in which q is a subgraph. It is inefficient to perform a sequential scan on the graph database and check whether q is a subgraph of gi. Sequential scan is very costly because one has to not only access the whole graph database but also check subgraph isomorphism which is NP-complete. Clearly, it is necessary to build graph indices in order to help processing graph queries. XML query is a simple kind of graph query, which is usually built around path expressions. Various indexing methods [6, 12, 5, 9, 4, 14, 3] have been developed to process XML queries. These methods are optimized for path expressions and tree-structured data. In order to answer arbitrary graph queries, GraphGrep and Daylight systems are proposed in [14, 8]. Since all of these methods take path as the basic indexing unit, we categorize them as path-based indexing approach. In this paper, GraphGrep is taken as an example of path-based indexing since it represents the state of the art technique for graph indexing. Its general idea is as follows: enumerate all the existing paths in a database up to maxL length and index them, where a path is a vertex sequence, v1, v2, . . . , vk, s.t., \u201aàÄ1 \u201aâ§ i \u201aâ§ k \u201aàí 1, (vi, vi+1) is an edge. It uses the index to identify every graph gi that contains all the paths (up to maxL length) in query q. The path-based approach has two advantages: 1. Paths are easier to manipulate than trees and graphs. 2. The index space is predefined: all the paths up to maxL length are selected. In order to answer tree- or graph- structured queries, a path-based approach has to break them into paths, search each path separately for the graphs containing the path, and join the results. Since the structural information could be lost when breaking such queries apart, it is likely that many false positive answers will be returned. Thus, a path-based approach is not suitable for complex graph queries. The advantages mentioned above of path-based indexing now become its weak points for indexing graphs: 1. Path is too simple: structural information is lost. 2. There are too many paths: the set of paths in a graph database usually is huge. The following example illustrates the disadvantages of pathbased approaches. Figure 1 is a sample chemical dataset extracted from an AIDS antiviral screening database 1 . For simplicity, we ignore the bond type. C C C C (a) C C C C C (b) Figure 1: A Sample Database C C C C Figure 2: A Sample Query Figure 2 shows a sample query, 2,3-dimethylbutane. Assume that this query is posed to the sample database. Although only graph (c) in Figure 1 is the answer, graphs (a) and (b) cannot be pruned since both of them contain all the paths existing in the query graph: c, c \u201aàí c, c \u201aàí c \u201aàí c, and c \u201aàí c \u201aàí c \u201aàí c. In this case, carbon chains (up to length 4) are not discriminative enough to tell the difference in the sample graphs. This indicates that path may not be a good structure to serve as the index feature for graph databases. As another problem, a graph database may contain too many paths if its graphs are large and diverse. For example, by randomly extracting 10, 000 graphs from the antiviral screening database, we find that there are totally around 100, 000 paths with length up to 10. Most of them are redundant based on our observation. It is inefficient to index all of them. The above analysis motivates us to search for an alternative solution. \u201aÄúCan we use graph structure instead of path as the basic index feature?\u201aÄù This study provides a firm answer to this question. It shows that a graph-based index can significantly improve query performance over a path-based one. Certainly, the number of graph structures is usually much larger than the number of paths in a graph database. To overcome this difficulty, only frequent subgraphs (i.e., frequent substructures) with length up to maxL are retained C C C C C C (c) 1 http://dtp.nci.nih.gov/docs/aids/aids data.html. C C C C C C C for indexing; whereas the frequent subgraphs can be generated by existing frequent graph mining algorithms efficiently [7, 10, 20, 17, 2, 21]. In order to avoid the exponential growth of the number of frequent subgraphs, the support threshold is progressively increased when the subgraphs grow large. That is, we use low support for small subgraphs and high support for large subgraphs. Meanwhile, the concept of discriminative structure is introduced to reduce the redundancy among the frequent subgraphs selected as index features. These ideas lead to the development of our new algorithm, gIndex. gIndex can scale down the number of indexing features in the above example on the AIDS antiviral screening database to 3, 000, but improve query response time by 3 to 10 times on average. gIndex also explores novel concepts to improve query search time, including using the Apriori pruning and maximum discriminative structures to reduce the number of subgraphs to be examined for index access and query processing. Frequent subgraphs are ideal candidates for indexing since they are relatively stable to database updates, thereby making incremental maintenance of index affordable. They also provide an efficient solution on index construction: we can first mine discriminative structures from a small portion of a large database, and then build the complete index based on these structures by scanning the whole database once. In this paper, the issues of feature selection, index search, index construction, and incremental maintenance are thoroughly explored. The contribution of this study is not only at providing a novel and efficient solution to graph indexing, but also at the demonstration of how data mining technology may help solving indexing and query processing problems. This may inspire us to further explore the application of data mining in query processing and data management. Furthermore, the concepts developed here can also be applied to indexing sequences, trees, and other complex structures. The remaining of the paper is organized as follows. Section 2 defines the preliminary concepts and briefly analyzes the graph query processing problem. Section 3 introduces frequent fragment and the size-increasing support constraint. Discriminative fragment is introduced in Section 4. Section 5 formulates the algorithm and presents the index construction and incremental maintenance processes. Our performance study is reported in Section 6. Related work is discussed in Section 7, and Section 8 summarizes our study. "},{"aspect":"expintro","tweet":" 6. EXPERIMENTAL RESULT In this section, we report our experiments that validate the effectiveness and efficiency of the gIndex algorithm. The performance of gIndex is compared with that of GraphGrep, a path-based approach [14]. Our experiments demonstrate that: 1. The index size of gIndex is more than 10 times smaller than that of GraphGrep; 2. gIndex outperforms GraphGrep by 3 to 10 times in various query loads; and 3. the index returned by the incremental maintenance algorithm is effective: it performs as well as the index computed from scratch provided the data distribution does not change much. We use two kinds of datasets in our experiments: one real dataset and a series of synthetic datasets (we ignore the edge labels). Most of our experiments have been performed on the real dataset since it is the source of real demand. 1. The real dataset we tested is that of an AIDS antiviral screen dataset containing chemical compounds. This dataset is available publicly on the website of the Developmental Therapeutics Program. As of March 2002, the dataset contains 43,905 classified chemical molecules. 2. The synthetic data generator was provided by Kuramochi et al. [10]. The generator allows the user to specify the number of graphs (D), their average size (T ), the number of seed graphs (S), the average size of seed graphs (I), and the number of distinct labels (L). All our experiments are performed on a 1.5GHZ, 1GBmemory, Intel PC running RedHat 8.0. Both GraphGrep and gIndex are compiled with gcc/g++. "},{"aspect":"problemdef","tweet":" 2. PRELIMINARIES As a general data structure, labeled graph is used to model complicated structures and schemaless data. In labeled graph, vertex and edge represent entity and relationship, respectively. The attributes associated with entities and relationships are called labels. XML is a kind of directed labeled graph. The chemical compounds shown in Figure 1 are undirected labeled graphs. In this paper, we investigate indexing techniques for undirected labeled graphs. It is straightforward to extend our method to process other kinds of graphs. As a notational convention, the vertex set of a graph g is denoted by V (g), the edge set by E(g), and the size of a graph by len(g), which is defined by |E(g)| in this paper. A label function, l, maps a vertex or an edge to a label. A graph g is a subgraph of another graph g \u201aÄ≤ if there exists a subgraph isomorphism from g to g \u201aÄ≤ , denoted by g \u201aäÜ g \u201aÄ≤ . g \u201aÄ≤ is called a super-graph of g. Definition 1 (Subgraph Isomorphism). A subgraph isomorphism is an injective function f : V (g) \u201aÜí V (g \u201aÄ≤ ), such that (1) \u201aàÄu \u201aàà V (g), l(u) = l \u201aÄ≤ (f(u)), and (2) \u201aàÄ(u, v) \u201aàà E(g), (f(u), f(v)) \u201aàà E(g \u201aÄ≤ ) and l(u, v) = l \u201aÄ≤ (f(u), f(v)), where l and l \u201aÄ≤ are the label function of g and g \u201aÄ≤ , respectively. f is called an embedding of g in g \u201aÄ≤ . Definition 2 (Graph Query Processing). Given a graph database D = {g1, g2, . . . , gn} and a query graph q, it returns the query answer set Dq = {gi|q \u201aäÜ gi, gi \u201aàà D}. Example 1. Figure 1 shows a sample labeled graph dataset. This dataset will be used as our running example. For the query q shown in Figure 2, the query answer set, Dq, has only one element: graph (c) in Figure 1. In general, graph query can be any kind of SQL statements applied to graphs. Besides the topological condition, one may also use other conditions to perform indexing. In this paper, we focus on indexing graphs only based on their topology. The processing of graph queries can be divided into two major steps: 1. Index construction, which is a preprocessing step, performed by enumerating and selecting features in graph database D. The graph feature set is denoted by F 2 . For any graph feature f \u201aàà F , Df is the set of graphs containing f, Df = {gi|f \u201aäÜ gi, gi \u201aàà D}. 2. Query processing, which consists of two substeps: (1) Search, which enumerates all the features in a query graph, q, to compute the candidate query answer set, Cq = ÔøΩ f Df (f \u201aäÜ q and f \u201aàà F ); each graph in Cq contains all q\u201aÄôs features in the feature set. Therefore, Dq is a subset of Cq. (2) Verification, which checks graph g in Cq to verify whether q is really a subgraph of g. Cost Analysis. In graph query processing, the major concern is Query Response Time: Tsearch + |Cq| \u201aàó Tiso test, (1) where Tsearch is the time spent in the search step and Tiso test is the average time of subgraph isomorphism testing, which is conducted over query q and graphs in Cq. In the verification step, it takes |Cq| \u201aàó Tiso test to prune false positives in Cq. Usually the verification time dominates Eq. (1) since the computational complexity of Tiso test is NP-complete. Approximately, the value of Tiso test does not change too much for a given query. Thus, the key to improve query response time is to minimize the size of the candidate answer set, |Cq|. If a graph database is very large such that the index cannot be held in the memory, Tsearch may be critical for the query response time. We are also interested in minimizing the index size M, which is approximately proportional to the size of the feature set |F |: M \u201aàù |F | (2) 2 A graph without any vertex and edge is denoted by f\u201aàÖ, f\u201aàÖ is viewed as a special feature, which is a subgraph of any graph. For completeness, F must include f\u201aàÖ. Thus, in order to reduce the index size, it is important to maintain a compact feature set. Otherwise, if the index is too large to reside in the memory, the cost of accessing F may be even greater than that of accessing the graph database itself. In the next section, we will begin our examination of minimizing |Cq| and |F |. 3. FREQUENT FRAGMENT Given a graph database D, |Dg| is the number of graphs in D where g is a subgraph. |Dg| is called (absolute) support, denoted by support(g). A graph g is frequent if its support is no less than a minimum support threshold, minSup. As one can see, frequent graph is a relative concept. Whether a graph is frequent depends on the setting of minSup. We use the term \u201aÄúfragment\u201aÄù to refer to a small subgraph (i.e., substructure) existing in graph databases and query graphs. Figure 3 shows two frequent fragments in the sample database with minSup = 2. C C C (a) C C C C C (b) Figure 3: Frequent Fragments Frequent fragments expose the intrinsic characteristic of a graph database. Suppose all the frequent fragments with minimum support minSup are indexed. Given a query graph q, if q is frequent, the graphs containing q can be retrieved directly since q is indexed. Otherwise, q probably has a frequent subgraph f whose support may be close to minSup. Since any graph with q embedded must contain q\u201aÄôs subgraphs, Df is a candidate answer set of query q. If minSup is low, it is not expensive to verify the small number of graphs in Df in order to find the query answer set. Therefore, it is feasible to index frequent fragments for graph query processing. A further examination helps clarify the case where query q is not frequent in the graph database. We sort all q\u201aÄôs subgraphs in the support decreasing order: f1, f2, . . . , fn. There must exist a boundary between fi and fi+1 where support(fi) \u201aâ\u2022 minSup and support(fi+1) < minSup. Since all the frequent fragments with minimum support minSup are indexed, the graphs containing fj (1 \u201aâ§ j \u201aâ§ i) are known. Therefore, we can compute the candidate answer set Cq ÔøΩ by 1\u201aâ§j\u201aâ§i Dfj , whose size is at most support(fi). For many queries, support(fi) is likely to be close to minSup. Hence the intersection of its frequent fragments, ÔøΩ 1\u201aâ§j\u201aâ§i Dfj , leads to a small size of Cq. Therefore, the cost of verifying Cq is minimal when minSup is low. This is confirmed by our experiments in Section 6. The above discussion exposes our key idea in graph indexing: It is feasible to construct high-quality indices using only frequent fragments. However, for low support queries (i.e., queries whose answer set is small), the size of candidate answer set Cq is related to the setting of minSup. If minSup is set too high, the size of Cq may be too large. If minSup is set too low, it is too difficult to generate all the frequent fragments because there may exist an exponential number of frequent fragments under low support. C Should we enforce a uniform minSup for all the fragments? Let\u201aÄôs examine a simple example: a completely connected graph with 10 vertices, each of which has a distinct label. There are 45 1-edge subgraphs, 360 2-edge ones, and more than 1, 814, 400 8-edge ones 3 . As one can see, in order to reduce the overall index size, it is appropriate for the index scheme to have low minimum support on small fragments (for effectiveness) and high minimum support on large fragments (for compactness). This criterion on the selection of frequent fragments for effective indexing is called size-increasing support constraint. Definition 3 (Size-increasing Support). Given a monotonically nondecreasing function, œà(l), pattern g is frequent under the size-increasing support constraint if and only if support(g) \u201aâ\u2022 œà(len(g)), and œà(l) is a size-increasing support function. By enforcing the size-increasing support constraint, we bias the feature selection to small fragments with low minimum support and large fragments with high minimum support. Especially, we always choose the (absolute) minSup to be 1 for size-0 fragment to ensure the completeness of the indexing. This method leads to two advantages: (1) the number of frequent fragments so obtained is much less than that with the lowest uniform minSup, and (2) low-support large fragments may be indexed well by their smaller subgraphs; thereby we do not miss useful fragments for indexing. support(%) 20 15 10 5 Œò Œ∏ 0 0 5 10 fragment size (edges) (a) exponential support(%) 20 15 10 5 Œò Œ∏ 0 0 5 10 fragment size (edges) (b) piecewise-linear Figure 4: Size-increasing Support Functions Example 2. Figure 4 shows two size-increasing support functions: exponential and piecewise-linear. We select size- 1 fragments with minimum support Œ∏ and larger fragments with higher support until we exhaust fragments up to size of maxL with minimum support Œò. A typical setting of Œ∏ and Œò is 1 and 0.1N, respectively, where N is the size of the database. We have a wide range of monotonically nondecreasing functions to use as œà(l). By using frequent fragments with the size-increasing support constraint, we have a smaller number of fragments to index. However, the number of indexed fragments may still be huge when the support is low. For example, 1,000 graphs may easily produce 100,000 fragments of that kind. It is both time and space consuming to index them. In the next section, we design a distillation procedure to acquire the best fragments, i.e., discriminative fragments, from the frequent fragments. In the end, only the most useful fragments are retained as indexing features. 3 For any n-vertex complete graph with different vertex labels, the number of size-k connected subgraphs is greater than C k+1 n √ó (k + 1)!/2, which is the number of size-k paths (k < n). 4. DISCRIMINATIVE FRAGMENT Do we need to index every frequent fragment? Let\u201aÄôs have some analysis. If two similar frequent fragments, f1 and f2, are contained by the same set of graphs in the database, i.e., Df1 = Df2, it is probably wise to include only one of them in the feature set. Generally speaking, among similar fragments with the same support, it is often sufficient to index only the smallest common fragment since more query graphs may contain the smallest fragment. That is to say, if f \u201aÄ≤ , a supergraph of f, has the same support as f, it will not be able to provide more information than f if both are selected as indexing features. Thus f \u201aÄ≤ should be removed from the feature set. In this case, we say f \u201aÄ≤ is not more discriminative than f. Note that this is contrary to the closed graph concept introduced in [21], which is to reduce the number of frequent subgraphs generated in graph mining, where the maximum fragments are retained. Example 3. All the graphs in the sample database (Figure 1) contain carbon-chains: c, c\u201aàíc, c\u201aàíc\u201aàíc, and c\u201aàíc\u201aàíc\u201aàíc. Fragments c\u201aàíc, c\u201aàíc\u201aàíc, and c\u201aàíc\u201aàíc\u201aàíc do not provide more indexing power than fragment c. Thus, they are useless for indexing. So far, we considered only the discriminative power between a fragment and one of its subgraphs. This concept can be further extended to the combination of its subgraphs. Definition 4 (Redundant Fragment). Fragment x is redundant with respect to feature set F if Dx \u201aâà ÔøΩ f\u201aààF \u201aàßf\u201aäÜx Df . Each graph in set ÔøΩ f\u201aààF \u201aàßf\u201aäÜx Df contains all x\u201aÄôs subgraphs in the feature set F . If Dx is close to ÔøΩ f\u201aààF \u201aàßf\u201aäÜx Df , it implies the presence of fragment x in a graph can be predicted well by the presence of its subgraphs. Thus, fragment x should not be used as an indexing feature since it does not provide any benefit to pruning if its subgraphs are already being used as indexing features. In such case, x is a redundant fragment. In contrast, there are fragments which are not redundant, called discriminative fragments. Definition 5 (Discriminative Fragment). Fragment x is discriminative with respect to F if Dx \u201aâ™ ÔøΩ f\u201aààF \u201aàßf\u201aäÜx Df . Example 4. Let us examine the query example in Figure 2. As shown in Example 3, carbon chains, c \u201aàí c, c \u201aàí c \u201aàí c, and c \u201aàí c \u201aàí c \u201aàí c, are redundant and should not be used as indexing features in this dataset. The carbon ring (Figure 5 (c)) is a discriminative fragment since only graph (c) in Figure 1 contains it while graphs (b) and (c) in Figure 1 have all of its subgraphs. Fragments (a) and (b) in Figure 5 are discriminative too. Since Dx is always a subset of ÔøΩ f\u201aààF \u201aàßf\u201aäÜx Df , x should be either redundant or discriminative. Obviously, redundant fragment is a relative concept. We provide a simple measure on the degree of redundancy. Let fragments f1, f2, . . . , fn be indexing features. Given a new fragment x, the discriminative power of x can be measured by P r(x|fœï1, . . . , fœïm), fœï i \u201aäÜ x, 1 \u201aâ§ œïi \u201aâ§ n. (3) Eq. (3) shows the presence probability of x given the presence of fœï1, . . . , fœïm in a graph. We denote 1/P r(x|fœï1, . . . , fœïm) by Œ≥, called discriminative ratio. Œ≥ has the following properties: 1. Œ≥ \u201aâ\u2022 1. 2. when Œ≥ = 1, fragment x is completely redundant since the graphs indexed by this fragment can be fully indexed by the combination of fragment fœï i . 3. when Œ≥ \u201aâ´ 1, fragment x is more discriminative than the combination of fragments fœï i . Thus, x becomes a good candidate to index. 4. Œ≥ is related to the fragments which are already in the feature set. The discriminative ratio can be calculated by the following formula: ÔøΩ | i Œ≥ = Dfœï | i , (4) |Dx| where Dx is the set of graphs containing x and ÔøΩ i Dfœï is i the set of graphs which contain the subgraphs of x in the feature set. In order to mine discriminative fragments, we may set a minimum discriminative ratio Œ≥min and retain any fragment whose discriminative ratio is no less than Œ≥min. We shall generate discriminative fragments from small size to large size. C C C (a) C C C C (b) C C C C C C (c) Figure 5: Discriminative Fragments Example 5. Suppose we set œà(l) \u201aâ° 1 and Œ≥min = 1.5 for the sample dataset in Figure 1. Figure 5 lists three of discriminative fragments (usually, we shall also add f\u201aàÖ, a fragment without any vertex and edge, into the feature set as the initial fragment). There are other discriminative fragments in this sample dataset. The discriminative ratio of fragments (a), (b), and (c) is 1.5, 1.5, and 2.0, respectively. The discriminative ratio of fragment (c) in Figure 5 can be computed as follows: suppose fragments (a) and (b) have already been selected as index features. There are \u201aÄùtwo\u201aÄù graphs in the sample dataset containing fragment (b) and \u201aÄùone\u201aÄù graph containing fragment (c). Since fragment (b) is a subgraph of fragment (c), the discriminative ratio of fragment (c) is 2/1 = 2.0. "},{"aspect":"solution","tweet":" 5. GINDEX In this section, we present the gIndex algorithm, examine the data structures storing the index, and discuss the incremental maintenance of index that supports insertion and deletion operations. We illustrate the design and implementation of gIndex in five subsections: (1) discriminative fragment selection, (2) index construction, (3) search, (4) verification, and (5) incremental maintenance. 4 support(x) \u201aâ\u2022 œà(len(x)) and | ÔøΩ i Dfœï i |/|Dx| \u201aâ\u2022 Œ≥min, for fœï i \u201aäÜ x. C Algorithm 1 featureSelection Input: Graph database D, Discriminative ratio Œ≥min, Size-increasing support function œà(l), Maximum fragment size maxL. Output: Feature set F . 1: let F = {f\u201aàÖ}, Df\u201aàÖ = D, and l = 0; 2: while l \u201aâ§ maxL do 3: for each fragment x, whose size is l do 4: if x is frequent and discriminative 4 then 5: F = F \u201aà™ {x}; 6: l = l + 1; 7: return F ; 5.1 Discriminative Fragment Selection Applying the concepts introduced in Sections 3 and 4, gIndex first generates all frequent fragments with the sizeincreasing support constraint. Meanwhile, it distills these fragments to eliminate the redundant ones. This feature selection process proceeds in a level-wise manner, i.e., Breadth- First Search (BFS). Algorithm 1 outlines the pseudo-code of feature selection. 5.2 Index Construction Once discriminative fragments are selected, gIndex has efficient data structures to store and retrieve them. It translates fragments into sequences and holds them in a prefix tree. Each fragment is associated with an id list: the ids of graphs containing this fragment. We present the details of index construction in this section. 5.2.1 Graph Sequentialization Substantial portion of computation involved in index construction and searching is related to graph isomorphism checking. One has to quickly retrieve a given fragment from the index. Considering that graph isomorphism testing is hard (It is suspected to be in neither P nor NP-complete, though it is obviously in NP); it is inefficient to scan the whole feature set to match fragments one by one. An efficient solution is to translate a graph into a sequence, called canonical label. If two fragments are the same, they must share the same canonical label. b a X a X (a) b Z Y b a v0 X (b) a v1 X b v2 v3 Z Y Figure 6: DFS Code Generation A traditional sequentialization method is to concatenate rows or columns of the adjacency matrix of a graph into an integer sequence. Since most graphs in real applications are sparse graphs, the traditional sequentialization method may not work efficiently. There are too many useless 0\u201aÄôs in the integer sequence. Furthermore, it is not space efficient to store adjacency matrices. A novel graph sequentialization method, called DFS coding, was introduced in [20, 21]. DFS coding can translate a graph into a unique edge sequence, which is generated by performing a depth first search (DFS) in a graph. The bold edges in Figure 6(b) constitute a DFS search tree. Each vertex is subscripted by its discovery time in a DFS search. The forward edge set contains all the edges in the DFS tree while the backward edge set contains the remaining edges. For the graph shown in Figure 6(b), the forward edges are discovered in the order of (v0, v1), (v1, v2), (v1, v3). Now we put backward edges into the order as follows. Given a vertex v, all of its backward edges should appear after the forward edge pointing to v. For vertex v2 in Figure 6(b), its backward edge (v2, v0) should appear after (v1, v2). Among the backward edges from the same vertex, we can enforce an order: given vi and its two backward edges, (vi, vj), (vi, vk), if j < k, then edge (vi, vj) will appear before edge (vi, vk). So far, we complete the ordering of the edges in a graph. Based on this order, a complete edge sequence for Figure 6(b) is formed: \u201aå©(v0, v1), (v1, v2), (v2, v0), (v1, v3)\u201aå™. This sequence is called a DFS code. We represent a labeled edge by a 5-tuple, (i, j, li, l(i,j), lj), where li and lj are the labels of vi and vj respectively and l(i,j) is the label of the edge connecting vi and vj. Thus, the above edge sequence can be written \u201aå© (0, 1, X, a, X) (1, 2, X, a, Z) (2, 0, Z, b, X) (1, 3, X, b, Y ) \u201aå™. Since each graph can have many different DFS search trees and each of them has a DFS code, a lexicographic order is designed in [20, 21] to order the DFS codes. For any graph g, the minimum DFS code is chosen among g\u201aÄôs DFS codes as its canonical label, denoted by dfs(g). In the next subsections, we will introduce how to store and search the minimum DFS codes of discriminative fragments. 5.2.2 gIndex Tree Using the above sequentialization method, each fragment can be mapped to an edge sequence (e.g., DFS code). We insert the edge sequences of discriminative fragments in a prefix tree, called gIndex Tree. level 0 level 1 level 2 ... e 3 f 3 f 2 e 2 f 1 e 1 ... Figure 7: gIndex Tree discriminative fragments intermediate node Example 6. Figure 7 shows a gIndex tree, where each node represents a fragment (a DFS code). For example, two discriminative fragments f1 = \u201aå©e1\u201aå™ and f3 = \u201aå©e1 e2 e3\u201aå™ are stored in the gIndex tree (for brevity, we use ei to represent edges in the DFS codes). Although fragment f2 = \u201aå©e1 e2\u201aå™ is not a discriminative fragment, we have to store f2 in order to connect fragments f1 and f3. The gIndex tree records all size-n discriminative fragments in level n (size-0 fragments are graphs with only one vertex and no edge; the root node in the tree is f\u201aàÖ). In this tree, code s is an ancestor of s \u201aÄ≤ if and only if s is a prefix of s \u201aÄ≤ . We use black nodes to denote discriminative fragments. White nodes (redundant fragments) are intermediate nodes which connect the whole gIndex tree. All leaf nodes are discriminative fragments since it is useless to store redundant fragments in leaf nodes. In each black node fi, an id list (Ii), the ids of graphs containing fi, is recorded. White nodes do not have any id list. Assume we want to retrieve graphs which contain both fragments fi and fj, what we need to do is to intersect Ii and Ij. gIndex tree has two advantages over other index structures such as B+ tree. First, gIndex tree records not only discriminative fragments, but also some redundant fragments. This setting makes the Apriori pruning possible (Section 5.3.1). Secondly, gIndex tree can reduce the number of intersection operations conducted on id lists of discriminative fragments by using (approximate) maximum fragments only (Section 5.3.2). In short, the search time Tsearch will be significantly reduced by using gIndex tree. 5.2.3 Remark on gIndex Tree Size Upon examining the size of the gIndex tree, we find that the graph id lists associated with black nodes fill the major part of the tree. We may derive a bound for the number of black nodes on any path from the root to a leaf node. In the following discussion, we do not count the root as a black node. Let the discriminative fragments on a path be f0, f1, . . ., fk\u201aàí1, where fi \u201aäÇ fi+1, 0 \u201aâ§ i \u201aâ§ k \u201aàí 2. According to the def- inition of discriminative fragments, | ÔøΩ j Df j |/|Df i | \u201aâ\u2022 Œ≥min, where 0 \u201aâ§ j < i. Hence |Df0| \u201aâ\u2022 Œ≥min|Df1| \u201aâ\u2022 . . . \u201aâ\u2022 Œ≥ k\u201aàí1 min |Df k\u201aàí1 |. Since |Df0| \u201aâ§ N/Œ≥min and |Df k\u201aàí1 | \u201aâ\u2022 1, we must have k \u201aâ§ log Œ≥min N. Theorem 1. For any path in the gIndex tree, the number of black nodes on the path is O(log Œ≥min N), where N is the size of the graph database. Theorem 1 delivers the upper bound on the number of black nodes on any path from the root to a leaf node. Considering the size-increasing support constraint, we have N/Œ≥ k min \u201aâ\u2022 |Df k\u201aàí1 | \u201aâ\u2022 œà(l), (5) where l is the size of fragment fk\u201aàí1 (l \u201aâ\u2022 k \u201aàí 1). Example 7. Suppose the size-increasing support function l œà(l) is a linear function: √ó 0.01N, where maxL = 10. maxL This means we index discriminative fragments whose size is up to 10. If we set Œ≥min to be 2, from Eq. 5, we know 1 2k \u201aâ\u2022 k\u201aàí1 . It implies the maximum value of k, i.e., the 1000 number of black nodes on any path in the gIndex tree, is less than 8. Are there lots of graph ids recorded in the gIndex tree? For the number of ids recorded on any path from the root to a leaf node, the following bound is obtained: k\u201aàí1 ÔøΩ |Dfi | \u201aâ§ ( 1 i=0 Œ≥min + 1 Œ≥2 . . . + min 1 Œ≥k )N, min where f0, f1, . . . , fk\u201aàí1 are discriminative fragments on the path. If Œ≥min \u201aâ\u2022 2, ÔøΩ k\u201aàí1 i=0 |Df i | \u201aâ§ N. Otherwise, we have more ids to record. In this case, it is space inefficient to record Df i . An alternative solution is to store the differential id list, i.e., \u201añ≥Df i = ÔøΩ x Dfx \u201aàí Df i , where fx \u201aàà F and fx \u201aäÇ fi. Such a solution generalizes a similar idea which was presented in [22], but handles multiple rather than one id list. The scope of our study does not permit a further examination of the differential id list. 5.2.4 gIndex Tree Implementation The gIndex tree is implemented using a hash table to help locating fragments and retrieving their id lists quickly; both black nodes and white nodes are included in the hash table. This is in lieu of a direct implementation of the tree structure. Nonetheless, the gIndex tree concept is crucial in determining the redundant (white) nodes which, as included in the index, will facilitate the pruning of search space. With graph sequentialization, we can map any graph to an integer by hashing its canonical label. Definition 6 (Graphic Hash Code). Given a sequence hash function h and a graph g, h(dfs(g)) is called graphic hash code. We treat the graphic hash code as the hash value of a graph. If two graphs g and g \u201aÄ≤ are isomorphic, then h(dfs(g)) = h(dfs(g \u201aÄ≤ )). Graphic hash code can help quickly locating fragments in the gIndex tree. 5.3 Search Given a query q, gIndex enumerates all its fragments up to a maximum size and locates them in the index. Then it intersects the id lists associated with these fragments. Algorithm 2 outlines the pseudo-code of the search step. Algorithm 2 Search Input: Graph database D, Feature set F , Query q, and Maximum fragment size maxL. Output: Candidate answer set Cq. 1: let Cq = D; 2: for each fragment x \u201aäÜ q and len(x) \u201aâ§ maxL do 3: if x \u201aàà F then 4: Cq = Cq \u201aà© Dx; 5: return Cq; 5.3.1 Apriori Pruning The pseudo-code in Algorithm 2 must be optimized. It is inefficient to generate every fragment in the query graph first and then check whether it belongs to the index. Imagine how many fragments a size-10 complete graph may have. We shall apply the Apriori rule: if a fragment is not in the gIndex tree, we need not check its super-graphs any more. That is why we record some redundant fragments in the gIndex tree. Otherwise, if a fragment is not in the feature set, one cannot conclude that none of its super-graphs will be in the feature set. A hash table H is used to facilitate the Apriori pruning. As explained in Section 5.2.4. It contains all the graphic hash codes of the nodes shown in the gIndex tree including intermediate nodes. Whenever we find a fragment in the query whose hash code does not appear in H, we need not check its super-graphs any more. 5.3.2 Maximum Discriminative Fragments Operation Cq = Cq \u201aà©Dx is done by intersecting the id lists of Cq and Dx. We now consider how to reduce the number of intersection operations. Intuitively, ÔøΩ ÔøΩ if query q ÔøΩ has two fragments, fx \u201aäÇ fy, then Cq Dfx Dfy = Cq Dfy . Thus, it is not necessary to intersect Cq with Dfx. Let F (q) be the set of discriminative fragments (or indexing features) contained in query q, i.e., F (q) = {fx|fx \u201aäÜ q \u201aàß fx \u201aàà F }. Let Fm(q) be the set of fragments in F (q) that are not contained by other fragments in F (q), i.e., Fm(q) = {fx|fx \u201aàà F (q), \u201aàÑfy, s.t., fx \u201aäÇ fy \u201aàß fy \u201aàà F (q)}. The fragments in Fm(q) are called maximum discriminative fragments. In order to calculate Cq, we only need to perform intersection operations on the id lists of maximum discriminative fragments. Sometimes, it is expensive to compute Fm(q) if the subgraph enumeration algorithm does not generate all super-graphs of each fragment. Thus, we may replace Fm(q) with the approximate maximum discriminative fragment set F \u201aÄ≤ m(q) = {fx|fx \u201aàà F (q), \u201aàÑfy, s.t., fy is fx\u201aÄôs descendant in the gIndex tree and fy \u201aàà F (q)}. F \u201aÄ≤ m(q) includes the deepest black nodes that a query can reach in the gIndex tree, which is easy to compute. 5.3.3 Inner Support The previous support definition is only counting the frequency of a fragment in a graph dataset. Actually, one fragment may appear several times even in one graph. Definition 7 (Inner Support). Given a graph g, the inner support of subgraph x is the number of embeddings of x in g, denoted by inner support(x, g). Lemma 1. If g is a subgraph of G and fragment x \u201aäÇ g, then inner support(x, g) \u201aâ§ inner support(x, G). GraphGrep [14] uses the above lemma to improve the filtering power. In order to put the inner support to use, we have to store the inner support of discriminative fragments together with their graph id lists, which means the space cost is doubled. The pruning power of Lemma 1 is related with the size of queries. If a query graph is large, it is pretty efficient using inner support. 5.4 Verification After getting the candidate answer set Cq, we have to verify whether the graphs in Cq really contain the query graph or not. The simplest way to do it is to perform a subgraph isomorphism test on each graph one by one. GraphGrep [14] proposed an alternative approach. It records all the embeddings of paths in the graph database. Rather than doing real subgraph isomorphism testing, it performs join operations on these embeddings to figure out the possible isomorphism mapping between the query graph and the graphs in Cq. Considering there are lots of paths in the index and each path may have tens of embeddings, we find that in some cases it even performs worse than the simplest approach. Thus, we only implement the simple one in our study. 5.5 Insert/Delete Maintenance In this section, we present our index maintenance algorithm to handle insert/delete operations. For each insert or delete operation, we simply update the id lists of involved fragments as shown in Algorithm 3. Algorithm 3 is very efficient and the index quality may be still good if the statistics of old database and new database are similar. Here, the statistics means the frequent graphs and their supports in a graph database. If they do not change, then the discriminative fragments will not change at all. Thus, we only need to update the id lists of those fragments in the index, just as Algorithm 3 does. Fortunately, frequent patterns are relatively stable to database updates. A small number of insert/delete operations will not change their distribution too much. This property becomes one key advantage of using frequent fragments in the index. Algorithm 3 Insert/Delete Input: Graph database D, Feature set F , Inserted (Deleted) graph g and its id gid, Maximum fragment size maxL. 1: for each fragment x \u201aäÜ g and len(x) \u201aâ§ maxL do 2: if x \u201aàà F then 3: Insert: insert gid into the id list of x; 4: Delete: delete gid from the id list of x; 5: return; The incremental update property leads to another interesting result: a single database scan algorithm for the index construction. Rather than mining discriminative fragments from the whole graph database, one can actually first sample a small portion of the original database randomly, load it into the main memory, mine discriminative fragments from this small amount of data and then build the index by scanning the remaining database once. This strategy can significantly reduce the index construction time, especially when the database is large. As long as the sample data reflects the data distribution in the original database, the single scan algorithm works very well, which was confirmed in our experiments. The quality of index may degrade over time after lots of insertions and deletions. Thus, we need a measure to monitor the quality of the discriminative fragments indexed which may be out-of-date after updates. ÔøΩ The effectiveness of | f the gIndex can be measured by Df | , where f \u201aàà F, f \u201aäÜ x, |Dx| over some set of randomly selected query graphs. This is the ratio of the candidate answer set size over the actual answer set size. We monitor the measure based on sampled queries and check whether its average value changes much over time. A sizable increase of the value implies that the effectiveness of the index has deteriorated, probably because some discriminative fragments are missing from the indexing features. In this case, we have to consider recomputing the index from scratch. "},{"aspect":"expcomparison","tweet":" 6.1 AIDS Antiviral Screen Dataset The experiments described in this section use the antiviral screen dataset. We set the following parameters in Graph- Grep and gIndex for index construction. In GraphGrep, the maximum length of indexing paths is 10: GraphGrep enumerates all possible paths with length up to 10 and indexes them. Another parameter in GraphGrep, the fingerprint set size [14], is set as large as possible (10k). The fingerprint set consists of the hash values of indexing features. In our experiments, we do not use the technique of fingerprint since it has the similar effect on GraphGrep and gIndex: the smaller the fingerprint set, the smaller the index size and the worse the performance. In gIndex, the maximum fragment size maxL is also 10; the minimum discriminative ratio Œ≥min is 2.0; and the maximum support Œò is 0.1N. The size-increasing support function œà(l) is 1 if l < 4; in all ÔøΩ l other cases, œà(l) is Œò. This means that all the frag- maxL ments with size less than 4 are indexed. It should be noted that the performance is not sensitive to the selection of œà(l). There are other size-increasing support functions which can be applied, e.g., l maxL Œò, ( l maxL )2Œò, and so on. We choose to have the same maximum size of features in GraphGrep and gIndex so that a fair comparison between them can be done. We first test the index size of GraphGrep and gIndex. As mentioned before, GraphGrep indexes paths while gIndex uses discriminative frequent fragments. The test dataset consists of N graphs, denoted by ŒìN , which are randomly selected from the antiviral screen database. Figure 8 depicts the number of features used in these two algorithms with the test dataset size varied from 1, 000 to 16, 000. The curves clearly show that the index size of gIndex is at least 10 times smaller than that of GraphGrep. They also illustrate two salient properties of gIndex: its index size is small and stable. When the database size increases, the index size of gIndex does not change much. The stability of the index is due to the fact that frequent fragments and discriminative frequent fragments do not change much if the data have similar distribution. In contrast, the index size of GraphGrep may increase significantly because GraphGrep has to index all possible paths existing in a database (up to length-10 in our experiments). Number of features 10 6 10 5 10 4 GraphGrep gIndex 10 3 0 2 4 6 8 10 12 Database size (x1k) 14 16 Figure 8: Index Size Having verified the index size of GraphGrep and gIndex, we now check their performance. In Section 2, we build a query cost model. The cost of a given query is characterized by the number of candidate graphs we have to verify, i.e., the size of candidate answer set Cq. We average the cost in the following way: AV G(|Cq|) = ÔøΩ q\u201aààQ |Cq| |Q| . The smaller the cost, the better the performance. AV G(|Dq|) is the lower bound of AV G(|Cq|). An algorithm achieving this lower bound actually matches the queries in the graph dataset precisely. Candidate answer set size (|Cq|) 100 10 GraphGrep gIndex Actual Match 5 10 15 20 25 Query size Figure 9: Low Support Queries We select Œì10,000 as the performance test dataset. Six query sets are tested, each of which has 1, 000 queries: we randomly draw 1, 000 graphs from the antiviral screen dataset and then extract a connected size-m subgraph from each graph randomly. These 1, 000 subgraphs are taken as a query set, denoted by Qm. We generate Q4, Q8, Q12, Q16, Q20, and Q24. Each query set is then divided into two groups: low support group if its support is less than 50 and high support group if its support is between 50 and 500. We Candidate answer set size (|Cq|) 10 3 10 2 GraphGrep gIndex Actual Match 5 10 15 20 25 Query size Figure 10: High Support Queries make such elaborate partitions to demonstrate that gIndex can handle all kinds of queries very well, no matter whether they are frequent or not and no matter whether they are large or not. Figures 9 and 10 present the performance of GraphGrep and gIndex on low support queries and high support queries, respectively. We also plot the average size of query answer sets: AV G(|Dq|), which is the highest performance that an algorithm can achieve. As shown in the figures, gIndex outperforms GraphGrep nearly in every query set, except the low support queries in query set Q4. GraphGrep works better on Q4 simply because queries in Q4 are more likely path-structured and the exhausted enumeration of paths in GraphGrep favors these queries. Another reason is that the setting of œà(l) in gIndex has a minimum support jump on size-4 fragments (from 1 to 632). Candidate answer set size (|Cq|) 10 4 10 3 10 2 10 GraphGrep gIndex 1 Actual Match 1 10 100 1000 Query answer set size (|Dq|) 10000 Figure 11: Performance on the Chemical Data Figure 11 shows the performance according to the query answer set size (query support), i.e., |Dq|. X axis shows the actual answer set size while Y axis shows the average size of the candidate answer set, |Cq|, returned by these two algorithms. The closer |Cq| to |Dq|, the better the performance. The performance gap between gIndex and Graph- Grep shrinks when query support increases. The underlying reason is that higher support queries usually have simpler and smaller structures, where GraphGrep works well. When |Dq| is close to 10, 000, |Cq| will approach |Dq| since 10, 000 is their upper bound in this test. Overall, gIndex outperforms GraphGrep by 3 to 10 times when the answer set size is below 1, 000. Since gIndex uses frequent fragments, at the first sight, one might suspect that gIndex may not process low support queries well. However, according to the above experiments, gIndex actually performs very well on queries which have low supports or even no match in the database. This phenomena might be a bit counter-intuitive. We find that the size-increasing support constraint and the intersection power of structure-based features in gIndex are the two key factors for this robust result. Candidate answer set size (|Cq|) 350 300 250 200 150 Average of |Cq| Number of features 1 1.5 2 2.5 3 3.5 4 Minimum discriminative ratio Figure 12: Sensitivity of Discriminative Ratio Next, we check the sensitivity of minimum discriminative ratio Œ≥min. The performance and the index size with different Œ≥min are depicted in Figure 12. In this experiment, query set Q12 is processed on dataset Œì10,000. It shows that the query response time gradually improves when Œ≥min decreases. Simultaneously, the index size increases. In practice, we have to make a trade-off between the performance and the space cost. Runtime (in seconds) 400 350 300 250 200 150 100 2000 4000 6000 8000 10000 Database size Figure 13: Scalability The scalability of gIndex is presented in Figure 13. We vary the database size from 2, 000 to 10, 000 and construct the index from scratch for each database. As shown in the figure, the index construction time is proportional to the database size. The linear increasing trend is pretty predicable. We find that the feature set mined by gIndex for each database has around 3, 000 discriminative fragments. This number does not fluctuate a lot across different databases in this experiment, which may explain why the index construction time increases linearly. Since the size-increasing support function œà(l) follows the database size, œà(l) \u201aàù Œò \u201aàù N, the frequent fragment set will be relatively stable if the 10 1 Number of features(x10 3 ) databases have similar distribution. Candidate answer set size (|Cq|) 80 70 60 50 40 30 20 From scratch Incremental 2000 4000 6000 8000 10000 Database Size Figure 14: Incremental Maintenance The stability of frequent fragments leads to the effectiveness of our incremental maintenance algorithm. Assume we have two databases D and D \u201aÄ≤ = D + ÔøΩ i D+ i , where D+ i \u201aÄôs are the updates over the original database D. As long as the graphs in D and D + i are from the same reservoir, we need not build a separate index for D \u201aÄ≤ , instead, the feature set of D may be reused for the whole dataset D \u201aÄ≤ . This remark is confirmed in the following experiment. We first take Œì2,000 as the initial dataset D, and add another 2, 000 graphs into it and update the index using Algorithm 3. We repeat such addition and update four times until the dataset has 10, 000 graphs in total. The performance of the index obtained from incremental maintenance is compared with the index computed from scratch. We select the query set Q16 to test. Figure 14 shows the comparison between these two approaches. It is surprising that the incrementally maintained index exhibits similar performance. Occasionally, it even performs better in these datasets as pointed by the small gap between the two curves in Figure 14. The above experiments also support a potential improvement discussed in Section 5.5: we can construct the index on a small portion of a large database, and then use the incremental maintenance algorithm to build the complete index for the whole database in one scan. 6.2 Synthetic Dataset In this section, we present the performance comparison on synthetic datasets. The synthetic graph dataset is generated as follows: first, a set of S seed fragments are generated randomly, whose size is determined by a Poisson distribution with mean I. The size of each graph is a Poisson random variable with mean T . Seed fragments are then randomly selected and inserted into a graph one by one until the graph reaches its size. More details about the synthetic data generator are available in [10]. A typical dataset may have the following setting: it has 10,000 graphs and uses 1,000 seed fragments with 50 distinct labels. On average, each graph has 20 edges and each seed fragment has 10 edges. This dataset is denoted by D10kI10T 20S1kL50. When the number of distinct labels (L) is large, the synthetic dataset is much different from the AIDS antiviral screen dataset. Although local structural similarity appears in different synthetic graphs, there is little similarity existing among each synthetic graph. This characteristic results in a simpler index structure. We find that maxL only need to be 4 in order to achieve good performance. Both Graph- Grep and gIndex perform very well on such datasets. For example, if no two vertices in one graph share the same label, we only need the vertex labels to index the graphs. This is similar to the inverted index technique (word - document id list) in document retrieval. However, when we reduce the number of distinct labels, more and more vertices share the same label. The dataset becomes more difficult to index and search. We test a synthetic dataset D10kI10T 50S200L4 and size-12 queries (the queries are constructed using a similar method described in the previous section). The maximum size of paths and fragments is set to 5 for GraphGrep and gIndex, respectively. Figure 15 shows the average size of the candidate answer sets with different support queries. Candidate answer set size (|Cq|) 100 10 GraphGrep gIndex Actual Match 1 1 10 100 Query answer set size (|Dq|) Figure 15: Performance on a Synthetic Dataset As shown in Figure 15, gIndex performs much better than GraphGrep. When |Dq| approaches 300, GraphGrep performs well. We also tested other synthetic datasets with different parameters. Similar results are also observed in these experiments. "}]}