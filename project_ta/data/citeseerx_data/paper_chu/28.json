{"user_name":" Keyword Proximity Search in XML Trees ","user_timeline":[{"aspect":"abstract","tweet":" Abstract\u201aÄîRecent works have shown the benefits of keyword proximity search in querying XML documents in addition to text documents. For example, given query keywords over Shakespeare\u201aÄôs plays in XML, the user might be interested in knowing how the keywords cooccur. In this paper, we focus on XML trees and define XML keyword proximity queries to return the (possibly heterogeneous) set of minimum connecting trees (MCTs) of the matches to the individual keywords in the query. We consider efficiently executing keyword proximity queries on labeled trees (XML) in various settings: 1) when the XML database has been preprocessed and 2) when no indices are available on the XML database. We perform a detailed experimental evaluation to study the benefits of our approach and show that our algorithms considerably outperform prior algorithms and other applicable approaches. Index Terms\u201aÄîLowest common ancestor, tree proximity search, XML keyword search. "},{"aspect":"expanalysis","tweet":" 7 CONCLUSIONS AND FUTURE WORK In this paper, we have investigated the problem of XML keyword queries, with the aim of identifying the most specific context elements (i.e., LCAs) that contain all the keywords, along with a compact description of their witnesses (i.e., GDMCTs). We have proposed and evaluated efficient algorithms for a number of variants of this problem and have established that the context of XML keyword queries can indeed be efficiently determined as part of query evaluation. Our work opens the door to a number of different avenues of research in XML keyword queries. What would Information Retrieval style approximate matching look like? Our stack-based algorithms maintain partial GDMCTs during query evaluation; are these the desired answers to approximate keyword queries? What is the analog of tf idf for ranking the results of XML keyword queries? What are appropriate linguistic mechanisms to incorporate our keyword querying primitives into XQuery? We are currently exploring some of these promising directions of research. "},{"aspect":"expdata","tweet":" 5 EXPERIMENTAL EVALUATION We have designed and performed a comprehensive set of experiments to understand the performance of the proposed algorithms. We used both real and synthetic data sets. The synthetic data sets were generated using the XMark benchmark [2] for various database sizes. We also used the DBLP database [1] to explore the performance of our algorithms using more realistic data distributions. The experiments were conducted on a Xeon 2.2GHz computer with 1GB of RAM running Windows 2000 Professional. The algorithms were implemented in Java and the parsing of the XML files is performed using the SAX API of the Xerces Java Parser. 3 The master index is implemented as a Java Hashtable persistent object. "},{"aspect":"background","tweet":"  1 INTRODUCTION KEYWORD search is a user-friendly information discovery technique that has been extensively studied for text documents. Keyword proximity search is well-suited to XML documents as well, which are often modeled as labeled trees [3]. For example, consider a document consisting of (marked up) Shakespeare\u201aÄôs plays in XML. A user might be interested in matching the query keywords \u201aÄúmother, king, brother\u201aÄù and determining where they cooccur and within what context. For example, they may all appear within the same line or it may be that \u201aÄúking\u201aÄù and \u201aÄúbrother\u201aÄù appear in a line of a speech and \u201aÄúmother\u201aÄù appears in another line of the same speech, and so on. In the case of XML trees, the problem of keyword proximity search reduces to the problem of finding the subtrees rooted at the lowest common ancestors (LCAs) of the XML nodes that contain the keywords. Recently, a large corpus of work [18], [14], [19], [20] has been conducted on efficiently finding the LCAs of the query keyword nodes in XML trees. However, these works focus on computing the LCA nodes and not the whole XML subtrees rooted at the LCA nodes. These subtrees are needed in order to rank the results and display them to the user since ranking typically depends on the types of the connections. Furthermore, Xu and Papakonstantinou [20] and Li et al. [18] provide . V. Hristidis is with the School of Computing and Information Sciences, Florida International University, University Park, ECS 384, 11200 S.W. 8th Stree, Miami, FL 33199. E-mail: vagelis@cs.fiu.edu. . N. Koudas is with the Department of Computer Science, Bahen Center for Information, University of Toronto, 40 St. George Street, Rm BA5240, Toronto, ON M5S 2E4. E-mail: koudas@cs.toronto.edu. . Y. Papakonstantinou is with the Department of Computer Science and Engineering, University of California, San Diego, 9500 Gilman Drive, La Jolla CA 92093-0114. E-mail: yannis@cs.ucsd.edu. . D. Srivastava is with AT&T Labs-Research, Room A-115, 180 Park Ave., Bldg. 103, Florham Park, NJ 07932. E-mail: divesh@research.att.com. Manuscript received 17 Feb. 2004; revised 23 Dec. 2004; accepted 17 Oct. 2005; published online 17 Feb. 2006. For information on obtaining reprints of this article, please send e-mail to: tkde@computer.org, and reference IEEECS Log Number TKDE-0052-0204. √¶ efficient algorithms for locating only the Smallest LCAs (see Section 6). This paper presents algorithms to compute the Minimum Connecting Trees (MCTs) of the nodes that contain the keywords, that is, the subtrees rooted at the LCAs of the nodes that contain the keywords. We make the following technical contributions: . We formulate two main problems: 1) identifying and presenting in a compact manner all MCTs which explain how the keywords are connected and 2) identifying only MCTs whose root is not an ancestor of the root of another MCT. . We design and analyze efficient algorithms to compute MCTs in two cases: 1) when the XML data has been preprocessed and relevant indices have been constructed and 2) when the XML data has not been preprocessed, i.e., the XML data can only be processed sequentially. . We perform a detailed experimental evaluation to study the benefits of our approach and show that our algorithms considerably outperform both prior algorithms for keyword proximity on labeled graphs [7], [17], [13] as well as other applicable approaches. Notice that this work only focuses on how to efficiently return the connections between the nodes that contain the keywords. However, similarly to previous LCA works [20], [18], it does not solve the problem of how to rank these connections. Intuitively, the MCT is the basic connecting component between objects of a tree, although the specific strength of this connection has its own merit. The ranking problem has been studied in previous works [14], [7], [12]. The combination of our execution framework with these ranking techniques is left as future work. The rest of this paper is organized as follows: We describe the notation we use and formulate the problems in Section 2. Our algorithms for the case of indexed XML data are presented in Section 3 and, for unindexed data, in Section 4. We present a detailed experimental evaluation of our algorithms in Section 5. Related work is discussed in 1041-4347/06/$20.00 √ü 2006 IEEE Published by the IEEE Computer Society 2 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 18, NO. 4, APRIL 2006 Fig. 1. Input labeled tree used in examples. Section 6 and we conclude with directions for further work in Section 7. "},{"aspect":"expintro","tweet":" There are three main parameters affecting the performance of our algorithms, namely, 1) the value of K denoting the threshold, 2) the number m of keywords, and 3) the size of the data set. To better understand the performance of our algorithms for keywords of different selectivities, we perform experiments using sets of keywords having different frequencies, namely, low, corresponding to keywords with frequency between 1 and 10 in each data collection, medium, corresponding to keywords with frequency 11-200, and high, corresponding to keywords with frequency above 200. The number of keywords in each frequency range in the different data sets used is shown in Table 1. The experiments are divided into three classes. First, we evaluate the proposed algorithm SA and its variants 2. The main drawback of this approach is that the indexing and the execution stages are separated, which means that the entire inverted index entries would have to be stored and then processed. This factor becomes more important when the index entries are too long to fit in memory and are moved to and from secondary storage during the indexing and processing stages. 3. http://xml.apache.org/xerces-j/. 10 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 18, NO. 4, APRIL 2006 TABLE 1 Number of Keywords in Each Frequency Range in the Data Sets Used SALowAll, SALowOne. As a baseline for comparison, we use the algorithm NL, which computes LCAs and GDMCTs using a nested loops approach. We also evaluate an improvement of this basic strategy that uses the optimal algorithm for identifying the LCA of a pair of keywords [15]. This algorithm, NLOpt, still considers all pairs of keywords in a nested loops fashion, but it identifies the LCA of a pair very efficiently, namely, in O√∞1√û time. Next, in Section 5.2, we evaluate our algorithms for the case when no indices are available on the XML data. Each value reported in our graphs is an average collected from 50 repetitions of the experiment. Finally, we compare the SA algorithm against algorithms for keyword proximity search on labeled graphs [16], [17], [4]. However, since the algorithms of the prior work operate on data stored in relational database systems, we also built a version of the SA for XML data stored in a relational database so that the comparison is straightforward.  "},{"aspect":"problemdef","tweet":" 2 FRAMEWORK 2.1 Notation We use the conventional labeled directed tree notation to represent XML documents. Each node v of the tree corresponds to an XML element and is labeled with a tag √∞v√û. Ifv is a leaf node, it also has a string value val√∞v√û that contains a list of keywords. We assume that each node v has a unique id id√∞v√û. Fig. 1 illustrates a tree that will be used in the examples. id√∞v√û is the first component of the 4-tuple associated with each node v. The other three components will be explained in Section 3.2, where we first make use of these components. A keyword query is simply a set of keywords k1; ...;km. It returns a compact representation of the set of trees that connect the nodes that contain the keywords in their value or their tag. The following discussion formally defines and motivates the semantics. Definition 2.1 (MCT and LCA). The minimum connecting tree (MCT) of nodes v1; ...;vm of the input labeled tree T is the minimum size subtree TM of T that connects v1; ...;vm. The root of the tree is called the lowest common ancestor (LCA) of the nodes v1; ...;vm. An MCT of keywords k1; ...;km is an MCT of nodes v1; ...;vm that contain the keywords. For example, the MCTs (1) and (2) are two of the MCTs of the query \u201aÄúTom, Harry\u201aÄù and the MCTs (3), (4), and (5) correspond to the query \u201aÄúTom, Dick, Harry.\u201aÄù a1 p1! a2; √∞1√û a8 p4 s3! p5! a9; √∞2√û According to the typical assumption of keyword proximity systems [7], [13], [17], [16], [4], smaller MCTs are considered better solutions since they provide a closer connection between the keywords. However, our framework and algorithms are not tied to a particular ranking function since we focus on efficiently generating all the MCTs. In our running example, MCT (1) is better than MCT (2) since MCT (1) shows that Tom and Harry are coauthors, while MCT (2) merely shows that they both had papers in the same session of the conference. Similarly, MCT (3) is better than MCT (5) since MCT (5) shows that the three authors are linked through three different papers in the same session, while MCT (3) shows that they are linked through only two different papers in the same session. Indeed, we will later augment our keyword queries to bound the size of the MCTs, since, beyond a size, the result is often uninteresting. The set of MCTs is often overwhelmingly large since it may contain the following form of data redundancy, which leads to a number of MCTs that is exponential in the number of keywords in the query. Consider a list l1 of nodes that contain k1, a list l2 of nodes that contain k2, and so on, up to a list lm of nodes containing km. Suppose node n is the pairwise LCA of the nodes of the m lists and all nodes are at equal distances from n. In our running example, there is such a list¬Ωa2;a3≈\u2020 of \u201aÄúTom\u201aÄù nodes (jl1j¬º2) and a list¬Ωa6;a8≈\u2020 of \u201aÄúHarry\u201aÄù nodes (jl2j¬º2), such that their common LCA is c1 (conference). Then, there arejl1j jl2j ... jlmj MCTs. Notice that if there are i; j such thatjlij > 1 andjljj > 1, then each MCT can be implied (inferred) by the other MCTs and the set of MCTs is redundant. For example, the MCTs a2 p1 s1 c1! s2! p3! a6; √∞6√û a3 p2 s1 c1! s3! p4! a8 of query \u201aÄúTom, Harry\u201aÄù together imply the MCTs √∞7√û a2 p1 s1 c1! s3! p4! a8; √∞8√û a3 p2 s1 c1! s2! p3! a6: √∞9√û The encoding of the set of MCTs in grouped distance trees resolves this problem. We first define distance MCTs. Definition 2.2 (DMCT). Consider nodes v1; ...;vm of the input tree T. The Distance MCT (DMCT) TD¬º d√∞TM√û of the MCT HRISTIDIS ET AL.: KEYWORD PROXIMITY SEARCH IN XML TREES 3 TM of nodes v1; ...;vm is the minimum node-labeled and edgelabeled tree such that: 1. TD contains the nodes v1; ...;vm, 2. TD contains the LCAs u1; ...;uk of any pair of nodes √∞vi;vj√û, where vi;vj2¬Ωv1; ...;vm≈\u2020;i6¬º j, and 3. there is an edge labeled with the number \u201aÄò between any two distinct nodes n; n02fv1; ...;vm;u1; ...;ukg if there is a path of length \u201aÄò from n0 to n in TM and the path does not contain any node n002fu1; ...;umg other than n and n0 . The DMCT (10) corresponds to the MCT (1) and the DMCTs (11)-(14) correspond to the MCTs (6)-(9). a1 1 p1! 1 a2; √∞10√û a2 3 c1! 3 a6; √∞11√û a3 3 c1! 3 a8; √∞12√û a2 3 c1! 3 a8; √∞13√û a3 3 c1! 3 a6: √∞14√û Notice that the exponential explosion in the number of keywords is still present. Grouped DMCTs resolve the problem (if possible) by grouping together DMCTs of the same structure. Definition 2.3 (GDMCT). A Grouped DMCT of a tree T is a labeled tree where edges are labeled with numbers and nodes are labeled with lists of node ids from T. A DMCT D belongs to a GDMCT G if D and G are isomorphic. Assuming that f is the mapping of the nodes of D to the nodes of G, which induces a corresponding mapping, also called f, of the edges of D to the edges of G, the following must hold: 1. If nD is a node of D, nG is a node of G and f√∞nD√û¬ºnG, then the label of nG contains the id of nD. 2. If eD is an edge of D, eG is an edge of G and f√∞eD√û¬ºeG, then the label of eD and the label of eG are the same number. The GDMCT (15) captures DMCTs (11)-(14). The notation u1¬Ωa2;a3≈\u2020 indicates that the label of the node u1 is¬Ωa2;a3≈\u2020. u1¬Ωa2;a3≈\u2020 3 u0¬Ωc1≈\u2020! 3 u2¬Ωa6;a8≈\u2020: √∞15√û Note that each tree that is an instance of a GDMCT and is also a subtree of the XML data tree T is a DMCT of an MCT of T. We define the size of a GDMCT (or DMCT) to be the sum of the weights of its edges. We often eliminate from the solution those trees whose sizes exceed a user-provided size threshold K. 2.2 Problems We consider two closely related keyword search problems in this paper. Problem 1 (All GDMCTs Problem). Given an input labeled tree T, keywords k1; ...;km, and an integer K, find the minimal set of tuples√∞n; G√û, where G is a GDMCT whose root has list label¬Ωn≈\u2020 such that: 1. n is an LCA of k1; ...;km. 2. Each DMCT D of size up to K rooted at node n that is an LCA of k1; ...;km belongs to at least one GDMCT G such that√∞n; G√û is a tuple. 3. If any node id ni is removed from the label ¬Ωn1; ...;ni; ...;nm≈\u2020 of a node n02 G of a tuple √∞n; G√û, then there is at least one DMCT D of size up to K that does not belong to any tuple though it is rooted at the LCA n of k1; ...;km. 4. Every node ni of the label¬Ωn1; ...;ni; ...;nm≈\u2020 of a node n0 contains the same subset S of keywords from k1; ...;km. 1 5. The size of G is no more than K. The query \u201aÄúTom, Harry\u201aÄù with K¬º 5 returns the relation (16), while the same query with K¬º 3 returns (17). f√∞p1; u1 1¬Ωa1≈\u2020 1 u1 0¬Ωp1≈\u2020! 1 u1 2¬Ωa2≈\u2020√û √∞s1; u2 1¬Ωa1≈\u2020 2 u2 0¬Ωs1≈\u2020! 2 u2 2¬Ωa3≈\u2020√û √∞p3; u3 1¬Ωa5≈\u2020 1 u3 0¬Ωp3≈\u2020! 1 u3 2¬Ωa6≈\u2020√û √∞s3; u4 1¬Ωa8≈\u2020 2 u4 0¬Ωs3≈\u2020! 2 u4 2¬Ωa9≈\u2020√û g; f√∞p1; u1 1¬Ωa1≈\u2020 1 u1 0¬Ωp1≈\u2020! 1 u1 2¬Ωa2≈\u2020√û √∞p3; u3 1¬Ωa5≈\u2020 1 u3 0¬Ωp3≈\u2020! 1 u3 2¬Ωa6≈\u2020√û g: √∞16√û √∞17√û A closely related problem to Problem 1, discussed next, is one which returns only GDMCTs whose roots (i.e., the LCAs) are not themselves ancestors of roots of other returned GMDCTs. Problem 2 (Lowest GDMCTs Problem). Given an input labeled tree T, keywords k1; ...;km, and an integer K, find the minimal set of tuples√∞n; G√û such that: 1. √∞n; G√û is a tuple for Problem 1, i.e., the All GDMCTs Problem, and 2. if√∞n0 ;G0√û is also a tuple for Problem 1, then n is not an ancestor of n0 . For Problem 2, the query \u201aÄúTom, Harry,\u201aÄù with K¬º 3 still returns (17), while the same query with K¬º 5 returns (18). Note that the tuple with n¬ºs1 from (16) is no longer a solution for the Lowest GDMCTs Problem since it is an ancestor of node p1 which is part of a solution. f√∞p1; u1 1¬Ωa1≈\u2020 1 u1 0¬Ωp1≈\u2020! 1 u1 2¬Ωa2≈\u2020√û √∞p3; u3 1¬Ωa5≈\u2020 1 u3 0¬Ωp3≈\u2020! 1 u3 2¬Ωa6≈\u2020√û √∞s3; u4 1¬Ωa8≈\u2020 2 u4 0¬Ωs3≈\u2020! 2 u4 2¬Ωa9≈\u2020√û g: √∞18√û In this paper, we focus our attention on these two problems. We also consider variants of Problems 1 and 2, where we are interested in returning only the LCAs (not the complete GDMCTs), provided there is at least one DMCT rooted at the LCA with size no more than K. We refer to 1. This condition ensures that each DMCT D contained in the GDMCT (that is, D is also contained in T) contains all keywords k1; ...;km. 4 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 18, NO. 4, APRIL 2006 these variants as the \u201aÄúAll LCAs Problem\u201aÄù and the \u201aÄúLowest LCAs Problem\u201aÄù in the paper. Notice that, in practice, one may augment GDMCTs with additional information about their nodes. For example, one may ask that the title of the paper is always displayed along with the paper. Schmidt et al. [17] have introduced the \u201aÄútarget objects\u201aÄù concept to handle this requirement. For simplicity, we will neglect such augmentations since they do not affect the performance issues that are the focus of this paper. In the sequel, we design efficient algorithms for these problems and experimentally evaluate them under two cases: 1) when the XML data has been preprocessed and relevant indices have been constructed before the keyword query is evaluated (Section 3) and 2) when the XML data has not been preprocessed, i.e., the XML data can only be processed sequentially (Section 4).  "},{"aspect":"solution","tweet":" 3 ALGORITHMS: INDEXED XML DATA In this section, we first focus on Problem 1 (All GDMCTs) and design two competitive algorithms to solve it: a straightforward, nested-loops algorithm and a more sophisticated stack-based algorithm that is tailored to the XML tree structure in identifying LCAs and GDMCTs. We then discuss the modifications to our stack-based algorithm that are needed to solve the variants (Lowest GDMCTs, All LCAs, and Lowest LCAs) of our core problem. These algorithms are compared experimentally in Section 5. 3.1 All GDMCTs: Nested Loops Algorithm Intuitively, the nested loops algorithm (NL) for the case of indexed XML data operates over separate lists of nodes, L√∞k√û, one for each query keyword, k, to identify the GDMCTs whose sizes are no more than the user-provided threshold, K. The master index for the nested loops algorithm is organized as an inverted index, as follows: A hash table (the keywords are the keys) of all the keywords in the XML data tree T is created and, for each keyword k, we keep a list L√∞k√û (value of hash table) of the nodes n of T that contain k, where each node n is stored with its path-id: the list of node ids along the path from the root of T to n. This choice facilitates the easy identification of the LCA and the GDMCT of a set of nodes, which can be determined by simply examining the path-ids of the respective nodes. This index is built in one pass over T before any query arrives. For example, some entries in the master index for the XML tree of Fig. 1 are shown below. Tom: ¬Ω¬Ωr; c1;s1;p1;a2≈\u2020,¬Ωr; c1;s1;p2;a3≈\u2020,¬Ωr; c1;s2;p3;a5≈\u2020, ¬Ωr; c1;s3;p5;a9≈\u2020≈\u2020 Dick:¬Ω¬Ωr; c1;s1;p2;a4≈\u2020,¬Ωr; c1;s2;p3;a7≈\u2020,¬Ωr; c1;s3;p6;a10≈\u2020≈\u2020 Harry:¬Ω¬Ωr; c1;s1;p1;a1≈\u2020,¬Ωr; c1;s2;p3;a6≈\u2020,¬Ωr; c1;s3;p4;a8≈\u2020≈\u2020 The execution stage of the Nested Loops Algorithm, using this index, is presented in Fig. 2. Essentially, it checks all combinations of nodes from the keyword lists, computes an MCT (minimum connecting tree) for each combination, and then merges the resulting MCT into the list of result GDMCTs, provided its size is within the user-specified threshold. Fig. 2. Nested loops algorithm. For example, given the keyword query \u201aÄúTom, Harry\u201aÄù and a threshold K¬º 3, the Nested Loops algorithm would examine the 12 node-pairs in the cross-product of the index entries for Tom and Harry, compute 12 MCTs, determine that only two of them meet the threshold, and, finally, return two GDMCTs (see relation (17)). There are two main sources of inefficiency in the Nested Loops algorithm. First, as illustrated in the above example, it has to check all the combinations of nodes from the keyword lists, i.e., getMCT(.) is calledjL√∞k1√ûj jL√∞km√ûj times. Second (not illustrated in the above example), the grouping of the results into GDMCTs is not tightly integrated with the algorithm and a lookup to the array R is required for each relevant MCT found. We next present a stack-based algorithm that overcomes both these sources of inefficiency, is tailored to the XML tree structure in identifying GDMCTs, and delivers performance that is considerably better than the Nested Loops Algorithm. 3.2 All GDMCTs: Stack-Based Algorithm Our stack-based algorithm, which we refer to as SA, makes use of a node numbering system, which associates (start, end, depth) numbers with each node in the XML tree, where start and end correspond to the first and the final times the node is visited in a depth-first traversal of the XML tree, and depth is the depth of the node from the root of the tree. In Fig. 1, we depict the (start, end, depth) numbering with each node as the last three components of the 4-tuple. For example, the numbering associated with s1 is√∞3; 16; 2√û. Such a numbering has been repeatedly utilized (see, e.g., [21], [5]), in a variety of XML related algorithms. This numbering permits efficient checking of ancestordescendant (or containment) relationships (by comparing containment of the corresponding (start, end) intervals) and can also be used to determine the distance between an HRISTIDIS ET AL.: KEYWORD PROXIMITY SEARCH IN XML TREES 5 Fig. 3. High-level description of the Stack Algorithm for all GDMCTs problem. ancestor and a descendant node in the XML tree (by computing the difference between corresponding depths). This latter fact (only exploited in [21], [5] to check parentchild relationships) will be very useful for us to efficiently compute sizes of MCTs. For example, one can determine that s1 is an ancestor of a4 (since the interval√∞3; 16√û contains the interval√∞13; 14√û) and also determine that the distance between them is 2 (i.e., 4 2), without knowing the intermediate node between s1 and a4. 3.2.1 Index Structure and Algorithm Intuitively, the stack-based algorithm for computing GDMCTs on indexed XML data operates over lists of nodes, two for each query keyword (these lists are described below). It: . maintains candidate LCA nodes on a stack, . computes and maintains partial GDMCTs at each candidate LCA for subsets of query keywords, and . computes and outputs result GDMCTs when all descendant nodes of a candidate LCA are known to have been examined. In order to do so, the lists associated with each keyword k need to contain, in addition to the nodes of T that contain k, ancestors of these nodes as well. This is because, while the (start, end, depth) numbers suffice to check ancestordescendant relationships, they are insufficient to identify the lowest common ancestors. For example, one would not be able to determine that the lowest common ancestor of a1 (with node numbering√∞5; 6; 4√û) and a3 (with node numbering√∞11; 12; 4√û) iss1 (with node numbering√∞3; 16; 2√û). Indexing by keyword is provided by the master index, which is organized as an inverted index, as follows: A hash table of all the keywords in the XML data tree T is created and, for each keyword k, we keep two lists: . L√∞k√û of the nodes of T that contain k in T and . L a √∞k√û of the ancestors of nodes in L√∞k√û. That is, the (master) index consists of two lists (L√∞k√û and L a √∞k√û) for each keyword. Each node is stored as √∞id; start; end; depth√û and L√∞k√û and L a √∞k√û are sorted in ascending start order. This index is also built in one pass over T before any query arrives. For example, the entries for keywords Tom, Dick, and Harry in the index for the XML tree of Fig. 1 are shown below. Tom: L¬º¬Ω√∞a2; 7; 8; 4√û,√∞a3; 11; 12; 4√û,√∞a5; 19; 20; 4√û, √∞a9; 33; 34; 4√û≈\u2020 La¬º¬Ω√∞r; 1; 42; 0√û,√∞c1; 2; 41; 1√û,√∞s1; 3; 16; 2√û,√∞p1; 4; 9; 3√û, √∞p2; 10; 15; 3√û,√∞s2; 17; 26; 2√û,√∞p3; 18; 25; 3√û, √∞s3; 27; 40; 2√û;√∞p5; 32; 35; 3√û≈\u2020 Dick: L¬º¬Ω√∞a4; 13; 14; 4√û,√∞a7; 23; 24; 4√û,√∞a10; 37; 38; 4√û≈\u2020 La¬º¬Ω√∞r; 1; 42; 0√û,√∞c1; 2; 41; 1√û,√∞s1; 3; 16; 2√û, √∞p2; 10; 15; 3√û,√∞s2; 17; 26; 2√û,√∞p3; 18; 25; 3√û; √∞s3; 27; 40; 2√û,√∞p6; 36; 39; 3√û≈\u2020 Harry: L¬º¬Ω√∞a1; 5; 6; 4√û,√∞a6; 21; 22; 4√û,√∞a8; 29; 30; 4√û≈\u2020 La¬º¬Ω√∞r; 1; 42; 0√û,√∞c1; 2; 41; 1√û,√∞s1; 3; 16; 2√û, √∞p1; 4; 9; 3√û,√∞s2; 17; 26; 2√û,√∞p3; 18; 25; 3√û; √∞s3; 27; 40; 2√û,√∞p4; 28; 31; 3√û≈\u2020 While the La lists in this index are not present in the index for the nested loops algorithm, each entry in the L and La lists is small and of fixed size, unlike in the nested loops index (where the entry size depends on the length of the path from the root of the XML tree). The asymptotic size complexity of the master index for the Stack Algorithm is better than that of the master index for the Nested Loops Algorithm. This is because each ancestor of a node containing keyword k is represented only once in the Stack Algorithm\u201aÄôs master index, whereas each ancestor is represented in the path-ids of the Nested Loops Algorithm\u201aÄôs master index as many times as it has descendants that contain keyword k. Hence, generally deeper (respectively, more shallow) trees require less (respectively, more) storage for the SA master index, compared to the Nested Loops Algorithm index. We shall also show empirically, in Section 5, that the sizes of the master indices for the two algorithms are not substantially different. We next describe the execution stage of the Stack Algorithm in more detail. To clarify the description and point out the novel contributions of the algorithm, we split it into two parts. The first part (Fig. 3) describes how the selected list of nodes is traversed in a depth-first manner and the nodes are pushed and popped from the stack. This type of stack-based traversal has been successfully applied in previous works [5], [10] to efficiently answer XML join queries as we explain in Section 6. The second and novel part (Fig. 4) of the SA algorithm is the processing and bookkeeping performed at each stack operation (i.e., push and pop) in order to maintain a minimum amount of information that allows the efficient and timely output of the GDMCTs. 6 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 18, NO. 4, APRIL 2006 Fig. 4. Operations of the Stack Algorithm for all GDMCTs problem. The stack S consists of entries of the form (s:nodeID, s:GDMCTs), where s:GDMCTs is a list of GDMCTs found so far rooted at the node with id s:nodeID. These GDMCTs may be partial, i.e., contain a subset of the query keywords, and are annotated with the keywords their nodes contain. The algorithm scans the list L consisting of nodes that either contain at least one keyword or are ancestors of at least two nodes that contain the query keywords; these are the only nodes that have the chance of being an LCA or participating in a GDMCT. Nodes of L are being pushed and popped from the stack S as the scanning proceeds. In particular, at the end of each iteration of the main loop (i.e., of the loop of lines 2-6 of Fig. 3), the top entry of S contains the node n with the highest start value seen so far. The other entries of the stack correspond to the ancestors of n. Before n is pushed onto the stack, all the stack entries that do not correspond to ancestors of n are popped from S. This HRISTIDIS ET AL.: KEYWORD PROXIMITY SEARCH IN XML TREES 7 is accomplished by the loop of lines 4-5 of Fig. 3. When an entry h is popped from S, any complete GDMCTs from h:GDMCTs are output (line 5 of Fig. 4). The remaining GDMCTs are partial. Since there is a possibility that the parent of h may have descendants that have the keywords that the partial GDMCTs miss, the partial GDMCTs of h become partial (or complete) GDMCTs of its parent h 0 . Notice that the entry h 0 may already have partial GDMCTs that reflect the keywords found in descendants of h 0 that were inspected before h. The transfer of each partial GDMCT G of h to the set of GDMCTs of h 0 follows the following steps: . Modify G to reflect the new root (lines 10-15) of Fig. 4. . Check to see if G satisfies the pruning condition (line 16 of Fig. 4). Once we have the modified and pruned set of partial GDMCTs of h, we compare them against the GDMCTs of its parent h 0 and create new GDMCTs as is appropriate (line 17 of Fig. 4), which we merge with the GDMCTs of h 0 . In particular, we create a new GDMCT for each pair of GDMCTs from h and h 0 that can be \u201aÄúglued\u201aÄù together to contain a larger subset of the keywords (lines 23-26 of Fig. 4). Finally, we merge (line 18 of Fig. 4) into the same GDMCT every pair of GDMCTs from h and h 0 that are isomorphic to ensure the minimality of the number of produced GDMCTs. Notice that the reason that the result GDMCTs rooted at node h are output when h is popped from the stack (line 5 of Fig. 4) and not when they are initially produced (lines 17, 22-27 of Fig. 4) is because there could be more GDMCTs that are \u201aÄúmergeable\u201aÄù with the GDMCTs already produced (lines 18, 28-33 of Fig. 4). 3.2.2 Illustrative Example We illustrate the execution of our Stack Algorithm, using an example, with two query keywords \u201aÄúTom, Harry,\u201aÄù and a threshold of 3. The master index lists L and L a are shown above for these query keywords. In line 3, the intersection of L a √∞Tom√û and L a √∞Harry√û would produce the list ¬Ω√∞r; 1; 42; 0√û;√∞c1; 2; 41; 1√û;√∞s1; 3; 16; 2√û; √∞p1; 4; 9; 3√û;√∞s2; 17; 26; 2√û;√∞p3; 18; 25; 3√û;√∞s3; 27; 40; 2√û≈\u2020: Notice that the entries √∞p2; 10; 15; 3√û, √∞p4; 28; 31; 3√û, and √∞p5; 32; 35; 3√û are not present in this list since they are ancestors of only one of the query keywords and, hence, can neither be an LCA nor be a part of any GDMCT. The Stack Algorithm then iteratively chooses entries from (the conceptual union of) L√∞Tom√û, L√∞Harry√û, and this intersection. Some of the initial stack states in the execution are depicted below: 1. The first four entries in the intersection of the L a s are pushed on S. 2. The first entry a1 from L√∞Harry√û is pushed on S and a partial GDMCT is created; the superscript of 2 in the GDMCT of a1 indicates a match for the second query keyword \u201aÄúHarry.\u201aÄù 3. When examining the first entry a2 from L√∞Tom√û, the top of stack a1 is popped and a new GDMCT is created at p1. 4. The first entry a2 from L√∞Tom√û is pushed on S and a partial GDMCT is created; the superscript of 1 in the GDMCT of a2 indicates a match for the first query keyword \u201aÄúTom.\u201aÄù 5. When examining the second entry a3 from L√∞Tom√û, the top of stack a2 is popped and new (combined) GDMCTs are created at p1. Note that a solution has been found, but it is not output yet. 6. When examining the second entry a3 from L√∞Tom√û, the top of stack p1 is also popped and the answer √∞p1;a1 2 1 p1! 1 a2 1√û is output. Additional GDMCTs are also associated with the (new) top of stack s1. 8 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 18, NO. 4, APRIL 2006 7. The entry a3 from L√∞Tom√û is then pushed on the stack and a partial GDMCT is created. 8. When examining the next entry s2 from the intersection of L a √∞Tom√û and L a √∞Harry√û, the top of stack a3 is popped, new GDMCTs are created, and merged with the GDMCTs associated with s1. In particular, the GDMCT s1! 2 a 1 3 is created (since a3 is at distance 2 from s1) and merged with s1! 2 a 1 2 resulting in s1! 2 ¬Ωa 1 2 ;a1 3 ≈\u2020. The GDMCT a1 3 2 s1! 2 a 2 1 is not created since its size (of 4) exceeds the user-defined threshold of 3. 9. Entries from the lists continue being examined, new GDMCTs are created and pruned until all the answers are output. 3.3 Lowest GDMCTs: Stack-Based Algorithm We now present a simple modification of the Stack Algorithm of Fig. 3 and Fig. 4 to efficiently answer Problem 2 (the Lowest GDMCTs Problem). This is the case when the user is interested only in the lowest GDMCTs, i.e., those GDMCTs whose roots are not ancestors of other returned GDMCT roots. The key observation is that once we output the GDMCTs of a node u (in line 5 of Fig. 4), none of the ancestors of u in the stack can be LCAs of returned GDMCTs; hence, we can remove all of them from the stack! Specifically, we can add the following lines after line 5 of the Stack Algorithm in Fig. 4. As an example, consider again the query keywords \u201aÄúTom, Harry,\u201aÄù but with a threshold of 5. Once the first √û is output in Step 6 (in the solution √∞p1;a1 2 1 p1! 1 a2 1 illustrative example of Section 3.2.2), the stack is emptied. Thus, no GDMCT with an LCA of c1 or s1 would be returned. (Note that, in the All GDMCTs Problem for this example, the solution √∞s1;a1 3 2 s1! 2 a2 1√û would also be returned.) We refer to this algorithm as SALowAll. 3.4 LCAs: Stack-Based Algorithms The Stack Algorithm can also be easily modified to solve the All LCAs Problem and the Lowest LCAs Problem, where the user is not interested in the GDMCTs, but only in the LCA nodes. Essentially, the algorithms, which modify SA and SALowAll and which we refer to as SAOne and SALowOne, respectively, would still need to maintain GDMCTs with stack nodes, with two simplifications: . Procedure Merge(.) in Fig. 4 could be simplified, no merging of GDMCTs would need to be done, and line 33 could be replaced by: . It is possible to output an LCA early when the first GDMCT (with all keywords) is computed for that node (in Procedure CreateNewGDMCTs(.) in Fig. 4), instead of waiting until the node is popped from the stack. An important point to note is that, while tempting, it does not suffice to simply 1) maintain, with each stack node u, the distance di to the closest descendant ui of u found so far containing keyword ki and 2) produce an output when each distance has been filled in and the sum of the distances is K. This is because, except for the special case of two query keywords, the size of a GDMCT is not simply the sum of the distances from the LCA to each of the nodes containing the m keywords. 3.5 Complexity Analysis This section presents (Section 3.5.3) a worst-case complexity analysis for SA. Before doing so, we perform an analysis of the maximum number of the resulting GDMCTs (Section 3.5.1) and we discuss how individual operations of SA can be performed in linear time on the size of the GDMCTs (Section 3.5.2). 3.5.1 Total Number of GDMCTs We show that, in the worst case, the numbers of DMCTs and of GDMCTs are exponential on the number of keywords. However, under reasonable assumptions explained below, the worst-case number of GDMCTs is smaller than that of DMCTs. Also, notice that, in practice, the number of GDMCTs is typically much smaller than the number of DMCTs due to the grouping. Consider a query with m keywords k1;k2; ...;km. Let L√∞ki√û be the list of the nodes of tree T that contain keyword ki. A DMCT can be obtained by combining one node from each of the m lists L√∞ki√û; 1 i m. Thus, in the worst case, the total number of DMCTs is given by m i¬º1 jL√∞ki√ûj, which is exponential in m. GDMCTs group isomorphic DMCTs to provide a more compact result. But, what is the worst-case total number of GDMCTs? We show that this can also be exponential in m. In particular, consider a node n that has each of the m keywords ki in its subtree and each keyword ki occurs at h different depths d¬º1; ...;h in the subtree rooted at n. It is easy to see that there has to be a different GDMCT for each combination of (keyword, depth). In this case, there are m i¬º1 h¬ºhm GDMCTs, which is exponential in m. HRISTIDIS ET AL.: KEYWORD PROXIMITY SEARCH IN XML TREES 9 However, under reasonable assumptions, the number of GDMCTs is asymptotically smaller than that of DMCTs. Consider the simple case where GDMCTs have no internal nodes, no node contains more than one keyword, and the XML tree has height H. Then, the maximum possible number of DMCTs is m i¬º1 jL√∞ki√ûj as above, but the maximum number of GDMCTs is H m (each of the m keywords can be in depth 1; ...;H). Hence, if H is viewed as a constant, the number of GDMCTs is asymptotically smaller than that of the DMCTs. 3.5.2 Complexity of Finding Isomorphic GDMCTs Deciding when two GDMCTs can be merged in SA is expensive unless we refine the representation of GDMCTs. In this section, we describe a canonical representation of a GDMCT that allows 1) a rapid determination of whether GDMCTs can be glued together in CreateNewGDMCTs (lines 23-25 of Fig. 4) and 2) checking whether two GDMCTs are isomorphic, permitting them to be merged (lines 31-33 of Fig. 4). In this canonical representation: . Each node in the GDMCT is annotated with the keywords in its subtree, in lexicographic ordering, and the size of its subtree. . The children subtrees (rooted at nodes n1; ...nj) of node n are ordered according to lexicographic ordering of the annotations of the roots of these children subtrees. Given this canonical representation, one can linearize the GDMCTs in an XML-like nested representation with start and end tags, obtained from the node annotations. Given this linearized representation: . Checking whether two GDMCTs can be glued together requires checking if their keyword sets are disjoint and, if their combined size does not exceed K, which can be checked using their annotations in the canonical representations; this can be done in a single pass of the GDMCTs, that is, in linear time on the size of the GDMCTs. . Checking whether two GDMCTs are isomorphic can be done by equating the canonical representations; this can be done in linear time on the size of the GDMCTs as well. 3.5.3 Time Complexity of SA In the SA algorithm, each node in L (which is computed in GetList) is pushed on to the stack and popped from the stack, at most once. When a node is popped from the stack, its GDMCTs need to be compared (and possibly merged) with the GDMCTs of its parent node in the stack. Since each operation on a pair of GDMCTs can be done in linear time on the size of the GDMCTs, the total time complexity of SA is a function of the total number of GDMCT comparisons, which is quadratic in the total number of GDMCTs. As a result, in the worst-case, we have: Theorem 1. The time complexity of SA is O√∞jLj√æK √∞ m i¬º1 jL√∞ki√ûj√û 2 √û√û: 4 PROCESSING UNINDEXED XML DATA In this section, we consider the case when no master index is available on the XML data tree and the goal is to efficiently solve the All GDMCTs Problem for a specific keyword query (with a threshold). Both the Nested Loops Algorithm and the Stack Algorithm have straightforward adaptations to work without index lists by doing a single pass over the data tree. In particular, NLStream, which is the streaming version of NL, first traverses in one pass the data tree to create the index lists of the query keywords and then executes the NL algorithm. 2 The streaming version of the Stack Algorithm, which we refer to as SAStream, is realized by making the following changes to the Stack Algorithm of Fig. 3 and Fig. 4. Notice that NLStream makes an additional pass over the data tree, unlike SAStream which just makes a single pass.  "},{"aspect":"expcomparison","tweet":" 5.1 Evaluating SA and Its Variants Our first experiment evaluates the index size requirements of the proposed SA algorithm for different sizes of XML data collections of the XMark benchmark. First, we compare the size of the index required by the Stack Algorithm (SA) compared to the Nested Loops Algorithm (NL) for various XMark data set sizes. We allocate 4 bytes for each node identifier and each start, end value in the depth-first numbering, and 1 byte for the depth number. Since the start value serves as a unique node identifier as well, we take this into account in our space computation for the SA index. Table 2 presents the index size of SA compared with that of NL, for various database sizes generated using the generation tools available in the XMark benchmark. Considering the entries of the table, it is evident that the index size requirements of SA are about 33 percent higher than TABLE 2 Index Size Requirements of SA that of NL. As we will soon demonstrate, SA introduces this small space overhead in order to provide orders of magnitude performance improvements. Fig. 5 presents the performance of the algorithms as K (the distance threshold) increases for a fixed number of keywords (equal to two) for the XMark 100MB and the DBLP data sets. In the rest of the section, due to space considerations, we do not present the graphs for low frequency keywords since we have found that they take constant time (up to 20 msec, which is the disk access time) to execute. For the same reason, we only present results for (the most common in practice) medium frequency keywords for DBLP because we use the larger XMark data set to show how the time scales for frequent keywords (we have found that DBLP scales following the same patterns). It is evident that SA is considerably superior to both NL and NLOpt. SA\u201aÄôs performance benefits are pronounced when high frequency keywords are involved since the number of nodes from the underlying XML tree involved in the operation increases considerably. NL incurs high overhead because it considers all possible pairs of nodes containing the query keywords and groups the results in GDMCTs. NLOpt also considers all pairs, although each pair requires much less time to process (compared to NL) and, thus, its performance is somewhat improved. Disk access appears to be the dominating factor in Fig. 5a and Fig. 5c (because relatively smaller lists of nodes are involved due to medium frequency query keywords), whereas processing time is the dominating performance factor in Fig. 5b. Table 3 presents the average number of GDMCTs for the various keyword frequencies in the 100MB XMark data set, for different threshold values. It is evident that the number of GDMCTs produced in the case of high frequency keywords is much higher, contributing considerably to the increased overhead of NL and NLOpt, in addition to their inherent overhead of considering all node pairs. The trend for all algorithms is to experience a degradation in their performance as K increases for a specific data size and Fig. 5. Varying K. (a) XMark 100MB, medium frequency. (b) XMark 100MB, high frequency. (c) DBLP, medium frequency. HRISTIDIS ET AL.: KEYWORD PROXIMITY SEARCH IN XML TREES 11 TABLE 3 Average Number of GDMCTs for the 100MB Xmark Data Set for Medium and High Frequency Keywords keyword frequency because the expected size of the stack nodes involved in the operation increases. Notice that, for algorithms SALowAll and SALowOne, this degradation in performance is not significant, even compared to algorithm SA, since the output produced by these algorithms is much smaller. In particular, it is interesting to observe that, for the Algorithm SALowOne, which produces the least output, its performance appears almost insensitive to the range of K values tested. In contrast, it only depends on the specific data set and, subsequently, on the corresponding query keyword frequency. Fig. 6 presents the results of an experiment exploring the performance impact of an increasing number of keywords for a fixed threshold K¬º 5. Notice that, for clarity of display, NLOpt is not plotted since its performance is very close to NL. Since NL considers all combinations of keywords, one from each keyword list, its performance deteriorates exponentially to the number of keyword lists. Algorithm SA and its variants are capable of scaling gracefully to an increasing number of keywords since they perform a single pass over the keyword lists and their performance benefits are substantial. Fig. 7 presents the performance of the algorithms for increasing database size, for various values of the distance threshold K; notice the log scale on the Y axis. To isolate the effects of increasing data size, we present the results for keywords selected uniformly at random among the 1,000 keywords with the highest frequency in each data set, respectively. The results, which are shown in Fig. 7, indicate that the proposed algorithms scale gracefully with increasing database size, exhibiting almost linear increase in performance with database size. The scalability limitations of algorithm NL are evident in the figure. Increasing the database size is expected to increase, in effect, the absolute frequencies of the 1,000 most frequent keywords, which is the keyword collection from which our queries are derived. As a result, by increasing the database size, the keyword lists provided as input to each algorithm, respectively, are much larger in size. Table 4 presents some statistics of the distribution of frequencies of the 1,000 most frequent keywords, as the size of the data sets increases. It is evident that the top 1,000 keyword frequencies increase substantially with increasing database size. 5.2 Evaluating the SAStream Algorithm We now present the evaluation of the variants of our algorithms for nonindexed data, where the execution times increase dramatically due to the lack of indexing that leads to reading the whole XML file. Fig. 8 compares algorithms Fig. 6. Varying number of keywords m. (a) XMark 100MB, medium frequency. (b) XMark 100MB, high frequency. (c) DBLP, medium frequency. Fig. 7. Varying database size. (a) XMark, K = 5. (b) XMark, K = 15. 12 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 18, NO. 4, APRIL 2006 TABLE 4 Statistics on the Frequency of 1,000 Most Frequent Keywords for Increasing Database Size for XMark Data NLStream and SAStream for increasing values of the distance threshold K, for two keywords, for medium and high frequency keywords. Notice that NLStream initially parses the XML document, constructing indices, and then operates on those indices. In contrast, Algorithm SAStream can operate immediately in conjunction with document parsing. In Fig. 8a, since we are dealing with not so frequent keywords, NLStream\u201aÄôs performance is dominated by the time to read the document and create the keyword lists and, thus, its performance appears to increase only marginally with increasing values of K. Fig. 8c presents a breakdown of the times spent at the two stages of NLStream\u201aÄôs execution. In effect, SAStream produces the desired result faster than the time required by NLStream to identify the relevant keywords and build indices. The performance advantages of SAStream are pronounced as the frequency of the keywords involved in the operation increases since its performance is linear in the size of the document. Contrasting Fig. 8b and Fig. 8d, we observe that the time required by NLStream to produce the output increases since larger lists of nodes are involved in the operation. The performance advantages SAStream offers in this case are substantial. In Fig. 9a and Fig. 9b, we present the performance of SAStream and NLStream as the number of keywords increases, for a fixed distance threshold K¬º 5. In Fig. 9c and Fig. 9d, we present a breakdown of the times taken by algorithm NLStream at the various stages of its execution. NLStream\u201aÄôs execution time increases exponentially with m, in contrast to SAStream, whose times remain relatively stable since document parsing and identification of relevant answers are interleaved. As observed in Fig. 9c and Fig. 9d, parsing time is the dominating factor in the performance of NLStream, with processing time becoming significant as the number of keywords increases. 5.3 Adaptation of SA Algorithm for DBMS Next, we compare SA against three systems that perform keyword proximity search on labeled graphs: DBXplorer [4], DISCOVER [16], and XKeyword [17] (see Section 6 for a short description of these works). Since all of them operate on data stored in a relational database, in order to have a fair comparison, we implemented a version of SA which operates on data stored in a DBMS. In particular, the exact same indexing method is used as in XKeyword and DISCOVER. That is, Oracle Intermedia Text Index 4 is used to find the nodes that contain the keywords. The nodes of the tree along with their (start, end, depth) triplet are stored in a relation, which we refer to as Master relation, whose text attributes are indexed by Oracle Intermedia. The runtime of the algorithm consists of two stages: reading the text index to get the nodes/tuples that contain the keywords and their ancestors and executing the 4. http://technet.oracle.com/products/text/content.html. SA algorithm on these nodes. Given the nodes that contain the keywords, their ancestors are computed using the (start, end) information on which a B+ index has been built. The index reading stage to find the nodes with the keywords is identical to the one used in XKeyword and DISCOVER. However, these works continue by building a set of intermediate tables (tuple sets) and, finally, executing a set of join queries to produce the results. On the other hand, SA does not need to access the database any more to compute the results. Fig. 10 compares the performance of these algorithms for the DBLP data set. Fig. 10b analyzes the cost of each algorithm into the costs of the consisting stages. Notice that we do not include DBXplorer in the graphs since it is slower than DISCOVER due to the lack of common subexpressions reuse. Finally, notice that the performance of SA decreases considerably when building the master index as described above since two steps are needed to get the keyword lists: First, query the DBMS text index to get the node ids and, second, get the corresponding (start, end, depth) triplets from the Master relation. On the other hand, these triplets are retrieved in a single step using the file-based master index described in Section 3.2.1.  "}]}