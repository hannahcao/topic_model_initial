{"user_name":" ï»¿Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks ","user_timeline":[{"aspect":"abstract","tweet":" Abstract Particle Ãlters (PFs) are powerful samplingbased inference/learning algorithms for dynamic Bayesian networks (DBNs). They allow us to treat, in a principled way, any type of probability distribution, nonlinearity and non-stationarity. They have appeared in several Ãelds under such names as \u201a€œcondensation\u201a€, \u201a€œsequential Monte Carlo\u201a€ and \u201a€œsurvival of the Ãttest\u201a€. In this paper, we show how we can exploit the structure of the DBN to increase the efÃciency of particle Ãltering, using a technique known as Rao- Blackwellisation. Essentially, this samples some of the variables, and marginalizes out the rest exactly, using the Kalman Ãlter, HMM Ãlter, junction tree algorithm, or any other Ãnite dimensional optimal Ãlter. We show that Rao- Blackwellised particle Ãlters (RBPFs) lead to more accurate estimates than standard PFs. We demonstrate RBPFs on two problems, namely non-stationary online regression with radial basis function networks and robot localization and map building. We also discuss other potential application areas and provide references to some Ãnite dimensional optimal Ãlters. "},{"aspect":"expanalysis","tweet":"  5.2 ROBOT LOCALIZATION AND MAP BUILDING Consider a robot that can move on a discrete, twodimensional grid. Suppose the goal is to learn a map of the environment, which, for simplicity, we can think of as a matrix which stores the color of each grid cell, which can be either black or white. The difÃculty is that the color y x 4 4 4 4 M1(2) M2(2) M3(2) M1(1) M2(1) M3(1) L1 L2 L3 Y1 Y2 Y3 Figure 3: A Factorial HMM with 3 hidden chains. Ã… Ã˜ ï¿½ represents the color of grid cell ï¿½ at time Ã˜, Ã„Ã˜ represents the robot\u201a€™s location, and ï¿½Ã˜ the current observation. sensors are not perfect (they may accidentally ÃŸip bits), nor are the motors (the robot may fail to move in the desired direction with some probability due e.g., to wheel slippage). Consequently, it is easy for the robot to get lost. And when the robot is lost, it does not know what part of the matrix to update. So we are faced with a chicken-and-egg situation: the robot needs to know where it is to learn the map, but needs to know the map to Ãgure out where it is. The problem of concurrent localization and map learning for mobile robots has been widely studied. In (Murphy 2000), we adopt a Bayesian approach, in which we maintain a belief state over both the location of the robot, Ã„Ã˜ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½Ã†Ã„ï¿½, and the color of each grid cell, Ã… Ã˜ ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½Ã†ï¿½ï¿½, ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½Ã†Ã„, where Ã†Ã„ is the number of cells, and Ã†ï¿½ is the number of colors. The DBN we are using is shown in Figure 3. The state space has size Ã‡ Ã† Ã†Ã„ ï¿½ . Note that we can easily handle changing environments, since the map is represented as a random variable, unlike the more common approach, which treats the map as a Ãxed parameter. The observation model is ï¿½Ã˜ ï¿½ ï¿½ Ã…Ã˜ Ã„Ã˜ , where ï¿½ Â¡ is a function that ÃŸips its binary argument with some Ãxed probability. In other words, the robot gets to see the color of the cell it is currently at, corrupted by noise: ï¿½ Ã˜ is a noisy multiplexer with Ã„Ã˜ acting as a \u201a€œgate\u201a€ node. Note that this conditional independence is not obvious from the graph structure in Figure 3(a), which suggests that all the nodes in each slice should be correlated by virtue of sharing a common observed child, as in a factorial HMM (Ghahramani and Jordan 1997). The extra independence information is encoded in ï¿½Ã˜\u201a€™s distribution, c.f., (Boutilier, Friedman, Goldszmidt and Koller 1996). The basic idea of the algorithm is to sample Ã„ ï¿½Ã˜ with a PF, and marginalize out the Ã…Ã˜ ï¿½ nodes exactly, which can be done efÃciently since they are conditionally independent given Ã„ ï¿½Ã˜: Ãˆ Ã…Ã˜ ï¿½ï¿½ï¿½ï¿½ ï¿½Ã…Ã˜ Ã†Ã„ ï¿½Ã ï¿½Ã˜ï¿½Ã„ ï¿½Ã˜ ï¿½ Ã‰ Ã† Ã„ ï¿½ï¿½ Ãˆ Ã…Ã˜ ï¿½ ï¿½Ã ï¿½Ã˜ï¿½Ã„ ï¿½Ã˜ Some results on a simple one-dimensional grid world are grid cell i 1 2 3 4 5 6 7 8 Prob. location, i.e., P(L(t)=i | y(1:t)) 2 4 6 8 time t 10 12 14 16 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 grid cell i 1 2 3 4 5 6 7 8 Prob. location, i.e., P(L(t)=i | y(1:t)), 50 particles, seed 1 2 4 6 8 time t 10 12 14 16 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 grid cell i 1 2 3 4 5 6 7 8 BK Prob. location, i.e., P(L(t)=i | y(1:t)) 2 4 6 8 time t 10 12 14 16 a b c Figure 4: Estimated position as the robot moves from cell 1 to 8 and back. The robot \u201a€œgets stuck\u201a€ in cell 4 for two steps in a row on the outgoing leg of the journey (hence the double diagonal), but the robot does not realize this until it reaches the end of the \u201a€œcorridor\u201a€ at step 9, where it is able to relocalise. (a) Exact inference. (b) RBPF with 50 particles. (c) Fully-factorised BK. shown in Figure 4. We compared exact Bayesian inference with the RBPF method, and with the fully-factorised version of the Boyen-Koller (BK) algorithm (Boyen and Koller 1998), which represents the belief state as a product of marginals: Ãˆ Ã„Ã˜ï¿½Ã…Ã˜ ï¿½ï¿½ï¿½ï¿½ ï¿½Ã…Ã˜ Ã†Ã„ ï¿½Ã ï¿½Ã˜ ï¿½Ãˆ Ã„Ã˜ï¿½Ã ï¿½Ã˜ Ã†Ã„ Ãˆ Ã…Ã˜ ï¿½ ï¿½Ã ï¿½Ã˜ We see that the RBPF results are very similar to the exact results, even with only 50 particles, but that BK gets confused because it ignores correlations between the map cells. We have obtained good results learning a Â¢ map (so the state space has size Ã‡ ) using only 100 particles (the observation model in the 2D case is that the robot observes the colors of all the cells in a Â¢ neighborhood centered on its current location). For a more detailed discussion of these results, please see (Murphy 2000). ï¿½ 5.3 CONCLUSIONS AND EXTENSIONS RBPFs have been applied to many problems, mostly in the framework of conditionally linear Gaussian state-space models and conditionally Ãnite state-space HMMs. That is, they have been applied to models that, conditionally upon a set of variables (imputed by the PF algorithm), admit a closed-form Ãltering distribution (Kalman Ãlter in the continuous case and HMM Ãlter in the discrete case). One can also make use of the special structure of the dynamic model under study to perform the calculations efÃciently using the junction tree algorithm. For example, if one had evolving trees, one could sample the root nodes with the PF and compute the leaves using the junction tree algorithm. This would result in a substantial computational gain as one only has to sample the root nodes and apply the juction tree to lower dimensional sub-networks. Although the previoulsy mentioned models are the most ï¿½ï¿½ 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 famous ones, there exist numerous other dynamic systems admitting Ãnite dimensional Ãlters. That is, the Ãltering distribution can be estimated in closed-form at any time Ã˜ using a Ãxed number of sufÃcient statistics. These include Â¯ Dynamic models for counting observations (Smith and Miller 1986). Â¯ Dynamic models with a time-varying unknow covariance matrix for the dynamic noise (West and Harrison 1996, Uhlig 1997). Â¯ Classes of the exponential family state space models (Vidoni 1999). This list is by no means exhaustive. It, however, shows that RBPFs apply to very wide class of dynamic models. Consequently, they have a big role to play in computer vision (where mixtures of Gaussians arise commonly), robotics, speech and dynamic factor analysis.  "},{"aspect":"expdata","tweet":""},{"aspect":"background","tweet":" 1 INTRODUCTION State estimation (online inference) in state-space models is widely used in a variety of computer science and engineering applications. However, the two most famous algorithms for this problem, the Kalman Ãlter and the HMM Ãlter, are only applicable to linear-Gaussian models and models with Ãnite state spaces, respectively. Even when the state space is Ãnite, it can be so large that the HMM or junction tree algorithms become too computationally expensive. This is typically the case for large discrete dynamic Bayesian networks (DBNs) (Dean and Kanazawa 1989): inference requires at each time space and time that is exponential in the Nando de Freitas Ã Kevin Murphy Ã Stuart Russell Ã Ã Computer Science Dept. UC Berkeley ï¿½jfgf,murphyk,russellï¿½@cs.berkeley.edu number of hidden nodes. To handle these problems, sequential Monte Carlo methods, also known as particle Ãlters (PFs), have been introduced (Handschin and Mayne 1969, Akashi and Kumamoto 1977). In the mid 1990s, several PF algorithms were proposed independently under the names of Monte Carlo Ãlters (Kitagawa 1996), sequential importance sampling (SIS) with resampling (SIR) (Doucet 1998), bootstrap Ãlters (Gordon, Salmond and Smith 1993), condensation trackers (Isard and Blake 1996), dynamic mixture models (West 1993), survival of the Ãttest (Kanazawa, Koller and Russell 1995), etc. One of the major innovations during the 1990s was the inclusion of a resampling step to avoid degeneracy problems inherent to the earlier algorithms (Gordon et al. 1993). In the late nineties, several statistical improvements for PFs were proposed, and some important theoretical properties were established. In addition, these algorithms were applied and tested in many domains: see (Doucet, de Freitas and Gordon 2000) for an up-to-date survey of the Ãeld. One of the major drawbacks of PF is that sampling in high-dimensional spaces can be inefÃcient. In some cases, however, the model has \u201a€œtractable substructure\u201a€, which can be analytically marginalized out, conditional on certain other nodes being imputed, c.f., cutset conditioning in static Bayes nets (Pearl 1988). The analytical marginalization can be carried out using standard algorithms, such as the Kalman Ãlter, the HMM Ãlter, the junction tree algorithm for general DBNs (Cowell, Dawid, Lauritzen and Spiegelhalter 1999), or, any other Ãnite-dimensional optimal Ãlters. The advantage of this strategy is that it can drastically reduce the size of the space over which we need to sample. Marginalizing out some of the variables is an example of the technique called Rao-Blackwellisation, because it is related to the Rao-Blackwell formula: see (Casella and Robert 1996) for a general discussion. Rao-Blackwellised particle Ãlters (RBPF) have been applied in speciÃc contexts such as mixtures of Gaussians (Akashi and Kumamoto 1977, Doucet 1998, Doucet, Godsill and Andrieu 2000), Ãxed parameter estimation (Kong, Liu and Wong 1994), HMMs (Doucet 1998, Doucet, Godsill and Andrieu 2000) and Dirichlet process models (MacEachern, Clyde and Liu 1999). In this paper, we develop the general theory of RBPFs, and apply it to several novel types of DBNs. We omit the proofs of the theorems for lack of space: please refer to the technical report (Doucet, Gordon and Krishnamurthy 1999).  "},{"aspect":"expintro","tweet":"  5 EXAMPLES We now illustrate the theory by brieÃŸy describing two applications we have worked on. 5.1 ON-LINE REGRESSION AND MODEL SELECTION WITH NEURAL NETWORKS Consider a function approximation scheme consisting of a mixture of ï¿½ radial basis functions (RBFs) and a linear regression term. The number of basis functions, ï¿½ Ã˜, their centers, ï¿½ Ã˜ , the coefÃcients (weights of the RBF centers plus regression terms), Â«Ã˜, and the variance of the Gaussian noise on the output, ï¿½ Ã˜ , can all vary with time, so we treat them as latent random variables: see Figure 1. For details, see (Andrieu, de Freitas and Doucet 1999a). In (Andrieu et al. 1999a), we show that it is possible to simulate ï¿½ Ã˜, ï¿½Ã˜ and ï¿½Ã˜ with a particle Ãlter and to compute the coefÃcients Â«Ã˜ analytically using Kalman Ãlters. This is possible because the output of the neural network is linear in Â«Ã˜, and hence the system is a conditionally linear Gaussian state-space model (CLGSSM), that is it is a linear Gaussian state-space model conditional upon the location of the bases and the hyper-parameters. This leads to an efÃcient RBPF that can be combined with a reversible jump MCMC algorithm (Green 1995) to select the number k Âµ Î± 0 0 0 Ïƒ 2 0 y x k k1 2 3 4 Âµ Î± 1 1 Ïƒ 2 1 1 1 Âµ Î± Ïƒ 2 2 y x 2 2 2 2 Figure 1: DBN representation of the RBF model. The hyper-parameters have been omitted for clarity. Prediction k Ïƒ 2 2 1 0 \u201aˆ’1 \u201aˆ’2 230 240 250 260 270 280 290 300 310 6 4 2 0 0 50 100 150 200 250 300 350 400 450 500 0.4 0.2 0 k Âµ Î± Ïƒ 2 3 y x 3 3 3 3 k Âµ Î± Ïƒ 2 4 0 50 100 150 200 250 300 350 400 450 Time Figure 2: The top plot shows the one-step-ahead output predictions [\u201a€”] and the true outputs [Â¡Â¡Â¡] for the RBF model. The middle and bottom plots show the true values and estimates of the model order and noise variance respectively. of basis functions online. For example, we generated some data from a mixture of 2 RBFs for Ã˜ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ , and then from a single RBF for Ã˜ ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½ ; the method was able to track this change, as shown in Figure 2. Further experiments on real data sets are described in (Andrieu et al. 1999a).  "},{"aspect":"problemdef","tweet":"  2 PROBLEM FORMULATION Let us consider the following general state space model/DBN with hidden variables ÃÃ˜ and observed variables ÃÃ˜. We assume that ÃÃ˜ is a Markov process of initial distribution Ã” Ã and transition equation Ã” ÃÃ˜ï¿½ÃÃ˜Â\u2020 . The observations Ã ï¿½Ã˜ ï¿½Ã ï¿½ Ã ï¿½ï¿½ï¿½ï¿½ ï¿½ÃÃ˜ï¿½ are assumed to be conditionally independent given the process Ã Ã˜ of marginal distribution Ã” ÃÃ˜ï¿½ÃÃ˜ . Given these observations, the inference of any subset or property of the states Ã ï¿½Ã˜ ï¿½Ã ï¿½ Ã ï¿½ï¿½ï¿½ï¿½ ï¿½ÃÃ˜ï¿½ relies on the joint posterior distribution Ã” Ã ï¿½Ã˜ï¿½Ã ï¿½Ã˜ . Our objective is, therefore, to estimate this distribution, or some of its characteristics such as the Ãltering density Ã” ÃÃ˜ï¿½Ã ï¿½Ã˜ or the minimum mean square error (MMSE) estimate ï¿½ ï¿½ÃÃ˜ï¿½Ã ï¿½Ã˜\u201a„„. The posterior satisÃes the following recursion Ã” Ã ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½Ã” Ã ï¿½Ã˜Â\u2020 ï¿½Ã ï¿½Ã˜Â\u2020 Ã” ÃÃ˜ï¿½ÃÃ˜ Ã” ÃÃ˜ï¿½ÃÃ˜Â\u2020 Ã” ÃÃ˜ï¿½Ã ï¿½Ã˜Â\u2020 If one attempts to solve this problem analytically, one obtains integrals that are not tractable. One, therefore, has to resort to some form of numerical approximation scheme. In this paper, we focus on sampling-based methods. Advantages and disadvantages of other approaches are discussed at length in (de Freitas 1999). The above description assumes that there is no structure within the hidden variables. But suppose we can divide the hidden variables ÃÃ˜ into two groups, Ã–Ã˜ and ÃœÃ˜, such that Ã” ÃÃ˜ï¿½ÃÃ˜Â\u2020 ï¿½ Ã” ÃœÃ˜ï¿½Ã–Ã˜Â\u2020 ï¿½Ã˜ï¿½ ÃœÃ˜Â\u2020 Ã” Ã–Ã˜ï¿½Ã–Ã˜Â\u2020 and, conditional on Ã– ï¿½Ã˜, the conditional posterior distribution Ã” Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ï¿½ Ã– ï¿½Ã˜ is analytically tractable. Then we can easily marginalize out Ãœ ï¿½Ã˜ from the posterior, and only need to focus on estimating Ã” Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ , which lies in a space of reduced dimension. Formally, we are making use of the following decomposition of the posterior, which follows from the chain rule Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½Ã” Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ï¿½ Ã– ï¿½Ã˜ Ã” Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ The marginal posterior distribution Ã” Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ satisÃes The problem of how to automatically identify which variables should be sampled, and which can be handled analytically, is one we are currently working on. We anticipate that algorithms similar to cutset conditioning (Becker, Bar-Yehuda and Geiger 1999) might prove useful. (1) the alternative recursion Ã” Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½ Ã” ÃÃ˜ï¿½Ã ï¿½Ã˜Â\u2020 ï¿½ Ã– ï¿½Ã˜ Ã” Ã–Ã˜ï¿½Ã–Ã˜Â\u2020 Ã” Ã– ï¿½Ã˜Â\u2020 ï¿½Ã ï¿½Ã˜Â\u2020 Ã” ÃÃ˜ï¿½Ã ï¿½Ã˜Â\u2020 If eq. (1) does not admit a closed-form expression, then eq. (2) does not admit one either and sampling-based methods are also required. Since the dimension of Ã” Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ is smaller than the one of Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ , we should expect to obtain better results. In the following section, we review the importance sampling (IS) method, which is the core of PF, and quantify the improvements one can expect by marginalizing out Ãœ ï¿½Ã˜ï¿½ i.e. using the so-called Rao-Blackwellised estimate. Subsequently, in Section 4, we describe a general RBPF algorithm and detail the implementation issues.  "},{"aspect":"solution","tweet":"  3 IMPORTANCE SAMPLING AND RAO-BLACKWELLISATION If we were able to sample ï¿½ Ã† i.i.d. Ã“ random samples (particles), ï¿½ ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½Ã† , according to Ã’ï¿½ ï¿½ ï¿½ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ , then an empirical estimate of this distribution would be given by Ã”Ã† Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½ Ã† Ã†ï¿½ ï¿½ï¿½ Ã†ï¿½ Ã– ï¿½ ï¿½ ï¿½ ï¿½Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ where Ã†ï¿½ Ã– ï¿½ ï¿½ ï¿½ ï¿½Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ denotes the Dirac delta ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ ï¿½ ï¿½ ï¿½ ï¿½ function located at Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ . As a corollary, an estimate of the Ãltering distribution Ã” Ã–Ã˜ï¿½ ÃœÃ˜ï¿½ Ã ï¿½Ã˜ is ÃˆÃ† Ã”Ã† Ã–Ã˜ï¿½ ÃœÃ˜ï¿½ Ã ï¿½Ã˜ ï¿½ Ã† ï¿½ï¿½ Ã†ï¿½ Ã– ï¿½ Ã˜ ï¿½Ãœ ï¿½ ï¿½ ï¿½Ã–Ã˜ï¿½ÃœÃ˜ . Hence Ã˜ one can easily estimate the expected value of any function ï¿½Ã˜ of the hidden variables w.r.t. this distribution, Ã ï¿½ Ã˜ , using ÃÃ† ï¿½Ã˜ ï¿½ ï¿½ Ã† (2) ï¿½ ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ Ã”Ã† Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ Ã†ï¿½ ï¿½ï¿½ ï¿½Ã˜ ï¿½ ï¿½ ï¿½ ï¿½ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ This estimate is unbiased and, from the strong law of large numbers (SLLN), ÃÃ† ï¿½Ã˜ converges almost surely (a.s.) towards Ã ï¿½Ã˜ as Ã† ï¿½ . If ï¿½ ï¿½Ã˜ var Ã” Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ \u201a„„ ï¿½ , then a central limit theorem (CLT) holds Ã” Â¢ Â£ Ã† ÃÃ† ï¿½Ã˜ Â\u2020 Ã ï¿½Ã˜ ï¿½ Ã† Ã†ï¿½ Â\u2020 Â¡ ï¿½ï¿½ï¿½Ã˜ where ï¿½ ï¿½ denotes convergence in distribution. Typically, it is impossible to sample efÃciently from the \u201a€œtarget\u201a€ posterior distribution Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ at any time Ã˜. So we focus on alternative methods. One way to estimate Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ and Ã ï¿½Ã˜ consists of using the well-known importance sampling method (Bernardo and Smith 1994). This method is based on the following observation. Let us introduce an arbitrary importance distribution Ã• Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ , from which it is easy to get samples, and such that Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½ implies Ã• Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½ . Then ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ Ã› Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ Ã ï¿½Ã˜ ï¿½ ï¿½ Ã• Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½ Ã• Ã– Ã› Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ where the importance weight is equal to Ã› Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ ï¿½ Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ Ã• Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ Ã’ï¿½ ï¿½ ï¿½ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ Given Ã† i.i.d. samples ï¿½Ã“ distributed accord- ing to Ã• Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ , a Monte Carlo estimate of Ã ï¿½Ã˜ is given by ï¿½ï¿½ Ã† ï¿½Ã˜ ÃÃ† ï¿½Ã˜ ï¿½ ï¿½ï¿½ Ã† ï¿½Ã˜ ï¿½ ï¿½ ÃˆÃ† ï¿½ï¿½ ï¿½Ã˜ ï¿½ ï¿½ Ã– ï¿½Ã˜ Ã†ï¿½ ï¿½ï¿½ ï¿½ ï¿½ ï¿½ Ã› Ã– ï¿½ ï¿½ ï¿½ Ãœ ï¿½Ã˜ ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ ÃˆÃ† ï¿½ï¿½ Ã› ï¿½ ï¿½ ï¿½ ï¿½ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ ï¿½Ã› ï¿½ ï¿½Ã˜ ï¿½Ã˜ ï¿½ ï¿½ ï¿½ ï¿½ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ where the normalized importance weights ï¿½Ã› ï¿½ ï¿½Ã˜ are equal to ï¿½Ã› ï¿½ ï¿½Ã˜ ï¿½ ï¿½ ï¿½ ï¿½ ï¿½ Ã› Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ ÃˆÃ† ï¿½ï¿½ Ã› ï¿½ ï¿½ ï¿½ Ã– ï¿½Ã˜ ï¿½ Ãœ ï¿½Ã˜ This method is equivalent to the following point mass approximation of Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ Ã”Ã† Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½ Ã†ï¿½ ï¿½ï¿½ ï¿½ ï¿½Ã› ï¿½ ï¿½Ã˜Ã†ï¿½ Ã– ï¿½ ï¿½ ï¿½ ï¿½Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ For \u201a€œperfect\u201a€ simulation, that is Ã• Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½ Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ , we would have ï¿½Ã› ï¿½ ï¿½Ã˜ ï¿½ Ã† Â\u2020 for any ï¿½. In practice, we will try to select the importance distribution as close as possible to the target distribution in a given sense. For Ã† Ãnite, Ã Ã† ï¿½Ã˜ is biased (since it is a ratio of estimates), but according to the SLLN, ÃÃ† ï¿½Ã˜ converges asymptotically a.s. towards Ã ï¿½Ã˜ . Under additional assumptions, a CLT also holds. Now consider the case where one can marginalize out Ãœ ï¿½Ã˜ analytically, then we can propose an alternative estimate for Ã ï¿½Ã˜ with a reduced variance. As Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½ Ã” Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ Ã” Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ï¿½ Ã– ï¿½Ã˜ , where Ã” Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ï¿½ Ã– ï¿½Ã˜ is a distribution that can be computed exactly, then an approximation of Ã” Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ yields straightforwardly an approximation of Ã” Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ . Moreover, if ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ can be evaluated in a ï¿½ Ã” Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ï¿½Ã– ï¿½Ã˜ ï¿½ closed-form expression, then the following alternative importance sampling estimate of Ã ï¿½Ã˜ can be used ï¿½ï¿½ Ã† ï¿½Ã˜ ÃÃ† ï¿½Ã˜ ï¿½ ï¿½ï¿½ Ã† ï¿½Ã˜ ÃˆÃ† ï¿½ï¿½ ï¿½ ï¿½ ï¿½ ï¿½ ï¿½ ï¿½ ï¿½Ã˜ Ã” Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ï¿½Ã– ï¿½Ã˜ ÃˆÃ† ï¿½ï¿½ Ã› ï¿½ ï¿½ Ã– ï¿½Ã˜ where ï¿½ ï¿½ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½ï¿½ ï¿½ ï¿½ ï¿½ ï¿½Ã˜ Ã› Ã– ï¿½Ã˜ Ã› Ã– ï¿½Ã˜ ï¿½ Ã” Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ Ã• Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½ Ã• Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½ Ã• Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½Ãœ ï¿½Ã˜ Intuitively, to reach a given precision, ÃÃ† ï¿½Ã˜ will require a reduced number Ã† of samples over ÃÃ† ï¿½Ã˜ as we only need to sample from a lower-dimensional distribution. This is proven in the following propositions. Proposition 1 The variances of the importance weights, the numerators and the denominators satisfy for any Ã† varÃ• Ã– ï¿½Ã˜ï¿½Ã Ã› Ã– ï¿½Ã˜ ï¿½Ã˜ ï¿½ varÃ• Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ï¿½Ã Ã› Ã– ï¿½Ã˜ ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ ï¿½ ï¿½ ï¿½ ï¿½ ï¿½ï¿½Ã† ï¿½ï¿½Ã† varÃ• Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½ varÃ• ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½Ã˜ ï¿½ ï¿½ ï¿½ ï¿½ ï¿½ï¿½Ã† ï¿½ï¿½Ã† varÃ• Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½ varÃ• ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½Ã˜ A sufÃcient condition for Ã Ã† ï¿½Ã˜ to satisfy a CLT is var Ã” Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ ï¿½ ï¿½ and Ã› Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ ï¿½ for any Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ (Bernardo and Smith 1994). This trivially implies that Ã Ã† ï¿½Ã˜ also satis- Ães a CLT. More precisely, we get the following result. Proposition 2 Under the assumptions given above, ÃÃ† ï¿½Ã˜ and ÃÃ† ï¿½Ã˜ satisfy aCLT Ã” ï¿½ ï¿½ Ã† ÃÃ† ï¿½Ã˜ Â\u2020 Ã ï¿½Ã˜ ï¿½ Ã† Ã†ï¿½ Â\u2020 ï¿½ï¿½ Â¡ Ã” ï¿½ ï¿½ Ã† ÃÃ† ï¿½Ã˜ Â\u2020 Ã ï¿½Ã˜ ï¿½ Ã† Ã†ï¿½ Â\u2020 ï¿½ï¿½ Â¡ where ï¿½ ï¿½ ï¿½ , ï¿½ and ï¿½ being given by ï¿½ ï¿½ ï¿½ Ã• Ã– ï¿½Ã˜ï¿½Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ ï¿½ ï¿½ ï¿½ Ã• Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ Â¢ ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ Â\u2020 Ã ï¿½Ã˜ Ã› Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ Â¢ ï¿½ Ã” Ãœ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ï¿½Ã– ï¿½Ã˜ Â\u2020 Ã ï¿½Ã˜ Ã›Ã˜ Ã– ï¿½Ã˜ Â£ ï¿½ ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ The Rao-Blackwellised estimate ÃÃ† ï¿½Ã˜ is usually computationally more extensive to compute than ÃÃ† ï¿½Ã˜ so it is of interest to know when, for a Ãxed computational complexity, one can expect to achieve variance reduction. One Â£ has ï¿½ Â\u2020 ï¿½ ï¿½ ï¿½ Ã• Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ Â¢ Ãšï¿½Ã–Ã• Ãœ ï¿½Ã˜ ï¿½Ã ï¿½Ã˜ ï¿½Ã– ï¿½Ã˜ Â\u2020 Ã ï¿½Ã˜ Ã› Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ Â¢ ï¿½Ã˜ Ã– ï¿½Ã˜ï¿½ Ãœ ï¿½Ã˜ so that, accordingly to the intuition, it will be worth generally performing Rao-Blackwellisation when the average conditional variance of the variable Ãœ ï¿½Ã˜ is high. 4 RAO-BLACKWELLISED PARTICLE FILTERS Given Ã† particles (samples) ï¿½Ã– ï¿½ ï¿½Ã˜Â\u2020 ï¿½ Ãœ ï¿½ ï¿½Ã˜Â\u2020 ï¿½ at time Ã˜ Â\u2020 , approximately distributed according to the distribution Ã” Ã– ï¿½ ï¿½Ã˜Â\u2020 ï¿½ Ãœ ï¿½ particles Â\u2020 Ã– ï¿½ ï¿½Ã˜ ï¿½Ã˜Â\u2020 ï¿½Ã ï¿½Ã˜Â\u2020 , RBPFs allow us to compute Ã† ï¿½ Ãœ ï¿½ ï¿½Ã˜ to the posterior Ã” Ã– ï¿½ ï¿½Ã˜ Â£Â£ Â¡ approximately distributed according ï¿½ Ãœ ï¿½ ï¿½Ã˜ ï¿½Ã ï¿½Ã˜ , at time Ã˜. This is ac- complished with the algorithm shown below, the details of which will now be explained. Generic RBPF 1. Sequential importance sampling step Â¯ For ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½Ã†, sample: and set: ï¿½ ï¿½Ã– ï¿½ Ã˜ ï¿½ ï¿½ Ã• Ã–Ã˜ï¿½Ã– ï¿½ ï¿½Ã˜Â\u2020 ï¿½ ï¿½ ï¿½ Â\u2020 ï¿½ ï¿½Ã– ï¿½Ã˜ ï¿½Ã– Ã˜ ï¿½ Ã– ï¿½ ï¿½Ã˜Â\u2020 ï¿½ Ã ï¿½Ã˜ Â¯ For ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½Ã†, evaluate the importance weights up to a normalizing constant: Ã› ï¿½ Ã˜ ï¿½ Ã” ï¿½Ã– ï¿½ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ Ã• ï¿½Ã– ï¿½ Ã˜ ï¿½Ã– ï¿½ ï¿½Ã˜Â\u2020 ï¿½ Ã ï¿½Ã˜ Ã” ï¿½Ã– ï¿½ ï¿½Ã˜Â\u2020 ï¿½Ã ï¿½Ã˜Â\u2020 Â¯ For ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½Ã†, normalize the importance weights: 2. Selection step ï¿½Ã› ï¿½ Ã˜ ï¿½ ï¿½ Ã›Ã˜ ï¿½ Ã†ï¿½ ï¿½ï¿½ Ã› ï¿½ Ã˜ Â¯ Multiply/ suppress samples ï¿½Ã– ï¿½ ï¿½Ã˜ 3. MCMC step ï¿½ Â\u2020 Â¡ with high/low importance weights ï¿½Ã› ï¿½ Ã˜ , respectively, to obtain Ã† random samples ï¿½Ã– ï¿½ ï¿½Ã˜ according to Ã” ï¿½Ã– ï¿½ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ . approximately distributed Â¯ Apply a Markov transition kernel with invariant distribution given by Ã” Ã– ï¿½ ï¿½ ï¿½Ã˜ï¿½Ã ï¿½Ã˜ to obtain Ã– ï¿½Ã˜ . Â¤ 4.1 IMPLEMENTATION ISSUES 4.1.1 Sequential importance sampling If we restrict ourselves to importance functions of the following form Ã• Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½Ã• Ã– Ã˜ï¿½ ï¿½ï¿½ Ã• Ã–ï¿½ï¿½ Ã ï¿½ï¿½ï¿½ Ã– ï¿½ï¿½Â\u2020 (3) we can obtain recursive formulas to evaluate Ã› Ã– ï¿½Ã˜ ï¿½ Ã› Ã– ï¿½Ã˜Â\u2020 Ã›Ã˜ and thus ï¿½Ã› ï¿½Ã˜. The \u201a€œincremental weight\u201a€ Ã›Ã˜ is given by ï¿½ ÃˆÃ† Ã›Ã˜ Ã” ÃÃ˜ï¿½ Ã ï¿½Ã˜Â\u2020 ï¿½ Ã– ï¿½Ã˜ Ã” Ã–Ã˜ï¿½ Ã–Ã˜Â\u2020 Ã• Ã–Ã˜ï¿½ Ã ï¿½Ã˜ï¿½ Ã– ï¿½Ã˜Â\u2020 ï¿½Ã›Ã˜ denotes the normalized version of Ã› Ã˜, i.e. ï¿½Ã› ï¿½ ï¿½ï¿½ Ã› ï¿½ Ã˜ ï¿½ Â\u2020 Ã› ï¿½ Ã˜ . Hence we can perform importance sampling online. Choice of the Importance Distribution There are inÃnitely many possible choices for Ã• Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ , the only condition being that its supports must include that of Ã” Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ . The simplest choice is to just sample from the prior, Ã” Ã–Ã˜ï¿½ Ã–Ã˜Â\u2020 , in which case the importance weight is equal to the likelihood, Ã” ÃÃ˜ï¿½ Ã ï¿½Ã˜Â\u2020 ï¿½ Ã– ï¿½Ã˜ . This is the most widely used distribution, since it is simple to compute, but it can be inefÃcient, since it ignores the most recent evidence, ÃÃ˜. Intuitively, many of our samples may end up in a region of the space that has low likelihood, and hence receive low weight; these particles are effectively wasted. We can show that the \u201a€œoptimal\u201a€ proposal distribution, in the sense of minimizing the variance of the importance weights, takes the most recent evidence into account: Proposition 3 The distribution that minimizes the variance of the importance weights conditional upon Ã– ï¿½Ã˜Â\u2020 and Ã ï¿½Ã˜ is Ã” Ã–Ã˜ï¿½ Ã– ï¿½Ã˜Â\u2020 ï¿½ Ã ï¿½Ã˜ ï¿½ Ã” ÃÃ˜ï¿½ Ã ï¿½Ã˜Â\u2020 ï¿½ Ã– ï¿½Ã˜ Ã” Ã–Ã˜ï¿½ Ã–Ã˜Â\u2020 Ã” ÃÃ˜ï¿½ Ã ï¿½Ã˜Â\u2020 ï¿½ Ã– ï¿½Ã˜Â\u2020 and the associated importance weight Ã›Ã˜ is Ã” ÃÃ˜ï¿½ Ã ï¿½Ã˜Â\u2020 ï¿½ Ã– ï¿½Ã˜Â\u2020 ï¿½ Ã˜ ï¿½ ï¿½ Ã” ÃÃ˜ï¿½ Ã ï¿½Ã˜Â\u2020 ï¿½ Ã– ï¿½Ã˜ Ã” Ã–Ã˜ï¿½ Ã–Ã˜Â\u2020 ï¿½Ã–Ã˜ Unfortunately, computing the optimal importance sampling distribution is often too expensive. Several deterministic approximations to the optimal distribution have been proposed, see for example (de Freitas 1999, Doucet 1998). Degeneracy of SIS The following proposition shows that, for importance functions of the form (3), the variance of Ã› Ã– ï¿½Ã˜ can only increase (stochastically) over time. The proof of this proposition is an extension of a Kong-Liu-Wong theorem (Kong et al. 1994, p. 285) to the case of an importance function of the form (3). Proposition 4 The unconditional variance (i.e. with the observations Ã ï¿½Ã˜ being interpreted as random variables) of the importance weights Ã› Ã– ï¿½Ã˜ increases over time. In practice, the degeneracy caused by the variance increase can be observed by monitoring the importance weights. Typically, what we observe is that, after a few iterations, one of the normalized importance weights tends to 1, while the remaining weights tend to zero. 4.1.2 Selection step To avoid the degeneracy of the sequential importance sampling simulation method, a selection (resampling) stage may be used to eliminate samples with low importance ratios and multiply samples with high importance ratios. A a number of offsprings, say Ã†ï¿½ Ã†, such that ÃˆÃ† ï¿½ï¿½ Ã†ï¿½ ï¿½ Ã†. Several selection schemes have been proposed in the lit- Â\u2020 Â¡ ï¿½ erature. These schemes satisfy ï¿½ Ã†ï¿½ ï¿½ Ã† ï¿½Ã› Ã˜ , but their performance varies in terms of the variance of the particles, var Â\u2020 Â¡ Ã†ï¿½ . Recent theoretical results in (Crisan, Del Moral and Lyons 1999) indicate that the restriction Â\u2020 Â¡ ï¿½ ï¿½ Ã†ï¿½ ï¿½ Ã† ï¿½Ã› Ã˜ is unnecessary to obtain convergence results (Doucet et al. 1999). Examples of these selection schemes include multinomial sampling (Doucet 1998, Gordon et al. 1993, Pitt and Shephard 1999), residual resampling (Kitagawa 1996, Liu and Chen 1998) and stratiÃed sampling (Kitagawa 1996). Their computational complexity is Ã‡ Ã† . selection scheme associates to each particle Ã– ï¿½ ï¿½Ã˜ 4.1.3 MCMC step After the selection scheme at time Ã˜, we obtain Ã† particles distributed marginally approximately according to Ã” Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ . As discussed earlier, the discrete nature of the approximation can lead to a skewed importance weights distribution. That is, many particles have no offspring (Ã†ï¿½ ï¿½ ), whereas others have a large number of offspring, the extreme case being Ã†ï¿½ ï¿½ Ã† for a particular value ï¿½. In this case, there is a severe reduction in the diversity of the samples. A strategy for improving the results involves introducing MCMC steps of invariant distribution Ã” Ã– ï¿½Ã˜ï¿½Ã ï¿½Ã˜ on each particle (Andrieu, de Freitas and Doucet 1999b, Gilks and Berzuini 1998, MacEachern et al. 1999). The basic idea is that, by applying a Markov transition kernel, the total variation of the current distribution with respect to the invariant distribution can only decrease. Note, however, that we do not require this kernel to be ergodic. 4.2 CONVERGENCE RESULTS Let ï¿½ ÃŠ Ã’ be the space of bounded, Borel measurable functions on ÃŠ Ã’ . We denote ï¿½ï¿½ï¿½ Ã—Ã™Ã” Ãœ ÃŠÃ’ ï¿½ï¿½ Ãœ ï¿½. The following theorem is a straightforward consequence of Theorem 1 in (Crisan and Doucet 2000) which is an extension of previous results in (Crisan et al. 1999). Theorem 5 If the importance weights Ã›Ã˜ are upper bounded and if one uses one of the selection schemes described previously, then, for all Ã˜ ï¿½ , there ï¿½ existsï¿½ Ã˜ inde- Ã’Ã Ã˜ pendent of Ã† such that for any ï¿½Ã˜ ï¿½ ÃŠ ï¿½ ï¿½ï¿½ Ã† Ã†ï¿½ ï¿½ï¿½ ï¿½Ã˜ ï¿½ ï¿½ ï¿½ ï¿½ Ã– ï¿½Ã˜ Â\u2020 ï¿½Ã˜ Ã– ï¿½Ã˜ Ã” Ã– ï¿½Ã˜ï¿½ Ã ï¿½Ã˜ ï¿½Ã– ï¿½Ã˜ ï¿½ ï¿½ï¿½Ã˜ï¿½ ï¿½ï¿½ Ã˜ Ã† where the expectation is taken w.r.t. to the randomness introduced by the PF algorithm. This results shows that, under very lose assumptions, convergence of this general particle Ãltering method is ensured and that the convergence rate of the method is independent of the dimension of the state-space. However, Ã˜ usually increases exponentially with time. If additional assumptions on the dynamic system under study are made (e.g. discrete state spaces), it is possible to get uniform convergence results ( Ã˜ ï¿½ for any Ã˜) for the Ãltering distribution Ã” ÃœÃ˜ï¿½ Ã ï¿½Ã˜ . We do not pursue this here.  "},{"aspect":"expcomparison","tweet":""}]}