{"user_name":" DISCOVER: Keyword Search in Relational Databases ","user_timeline":[{"aspect":"abstract","tweet":" Abstract DISCOVER operates on relational databases and facilitates information discovery on them by allowing its user to issue keyword queries without any knowledge of the database schema or of SQL. DISCOVER returns qualified joining networks of tuples, that is, sets of tuples that are associated because they join on their primary and foreign keys and collectively contain all the keywords of the query. DISCOVER proceeds in two steps. First the Candidate Network Generator generates all candidate networks of relations, that is, join expressions that generate the joining networks of tuples. Then the Plan Generator builds plans for the efficient evaluation of the set of candidate networks, exploiting the opportunities to reuse common subexpressions of the candidate networks. We prove that DISCOVER finds without redundancy all relevant candidate networks, whose size can be data bound, by exploiting the structure of the schema. We prove that the selection of the optimal execution plan (way to reuse common subexpressions) is NP-complete. We provide a greedy algorithm and we show that it provides near-optimal plan execution time cost. Our experimentation also provides hints on tuning the greedy algorithm. "},{"aspect":"expanalysis","tweet":" 7 Conclusion and Future Work As the amount of information stored in databases increases, so does the need for efficient information discovery. Keyword search enables information discovery without requiring from the user to know the schema of the database, SQL or some QBE-like interface, and the roles of the various entities and terms used in the query. in databases that do not require knowledge of the database schema or of a querying language. We presented DISCOVER, a system that performs keyword search in relational databases. It proceeds in three step. First it generates the smallest set of candidate networks that guarantee that all MTJNT\u201aÄôs will be produced. Then the greedy algorithm creates a near-optimal execution plan to evaluate the set of candidate networks. Finally, the execution plan is executed by the DBMS. In this work, we defined two keywords to be associated if they are contained in two tuples connected through primary to foreign key relationships. This is an intuitive and challenging association criterion as we have shown. In the future, we plan to extend DISCOVER to handle more association criteria such as: First, the keywords may be part of the metadata of the database. For example the keyword query \u201aÄúcustomer, Lou\u201aÄù would return tuple c 1 in Figure 2. Second, we could define two keywords, which are contained in the same attribute of two tuples of a relation, to msecs 10000000 1000000 100000 10000 1000 100 10 1 1 2 3 CN's size 4 5 a=0, b=1 a=1, b=0 a=1, b=0.3 Naive Optimal (a) Fix number of keywords to 2 msecs 10000000 1000000 100000 10000 1000 100 10 1 1 2 3 4 5 CN's size a=0, b=1 a=1, b=0 a=1, b=0.3 Naive Optimal (b) Fix number of keywords to 3 Figure 12: Execution times be associated. For example, the tuples o1ÔøΩo2 are a solution to the keyword query \u201aÄúSmith, Miller\u201aÄù, by this criterion. We plan to apply new optimization techniques to DIS- COVER. For example we plan to apply dynamic optimization techniques in the evaluation of the candidate networks. Currently, DISCOVER uses static optimization methods. That is, the whole execution plan is generated before its evaluation begins. Furthermore, we plan to experiment with new cost models that access the DBMS\u201aÄôs optimizer. We are also building from scratch a more efficient master index. Finally, we are working on building polynomial time algorithms that generate an optimal execution plan for special cases of database schemas. "},{"aspect":"expdata","tweet":""},{"aspect":"background","tweet":" 1 Introduction Keyword search is the most popular information discovery method because the user does not need to know either a query language or the underlying structure of the data. The search engines available today provide keyword search on top of sets of documents. When a set of keywords is Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 28th VLDB Conference, Hong Kong, China, 2002 Yannis Papakonstantinou University of California, San Diego yannis@cs.ucsd.edu provided by the user, the search engine returns all documents that are associated with these keywords. Typically, two keywords and a document are associated when the keywords are contained in the document and their degree of associativity is often their distance from each other. In addition to documents, a huge amount of information is stored in relational databases, but information discovery on relational databases is not well supported. The user of a relational database needs to know the schema of the database, SQL or some QBE-like interface, and the roles of the various entities and terms used in the query. The user of DISCOVER does not need knowledge of any of the above. Instead, DISCOVER enables information discovery by providing a straightforward keyword search interface to the database. For example, consider the TPC-H schema shown in Figure 1 and the instance in Figure 2. The arrows in Figure 1 point in the direction of the primary to foreign key (oneto-many) relationships between tables. Consider a user searching for information on the association of the keywords \u201aÄúSmith\u201aÄù and \u201aÄúMiller\u201aÄù. DISCOVER provides a simple interface where the user simply types the keywords \u201aÄì as he would do on a search engine. According to DISCOVER, an association exists between two keywords if they are contained in two associated tuples, i.e., two tuples that join through foreign key to primary key relationships, which potentially involve more tuples. This form of association is particularly useful and challenging. (We comment on other association criteria at the end.) DISCOVER does not require from the user to know the relations and the attributes where the keywords are found. The solution to the query are the two minimal joining sequences that contain the keywords \u201aÄúSmith\u201aÄù and \u201aÄúMiller\u201aÄù, namely o1 c1 o2 and o1 c1 n1 c2 o3. They are minimal in the sense that no tuple can be excluded and still have a sequence that contains the keywords. We use the notation a b to denote that tuple a joins with tuple b on their primary key to foreign key relationship. The first joining sequence shows that both \u201aÄúSmith\u201aÄù and \u201aÄúMiller\u201aÄù are clerks that have served customer Brad Lou, whereas the second merely says that the clerks have served customers Brad Lou and George Walters respectively, who both come from the USA. Intuitively, the first joining sequence is more useful than the second because it shows a closer association Figure 1: The TPC-H schema (copied from www.tpc.org) Figure 2: Sample TPC-H database instance between \u201aÄúSmith\u201aÄù and \u201aÄúMiller\u201aÄù. Based on the generalization of this intuition we rank join sequences according to the number of joins they involve. DISCOVER outputs the shorter sequences first. When more than two keywords are involved, a minimal joining sequence may not be sufficient to represent a solution. Hence we introduce minimal joining networks, that are trees of tuples where any two adjacent tuples join through a primary key to foreign key relationship. A high level representation of the architecture DIS- COVER uses to find the joining networks is shown in Figure 3. First, the user gives a set of keywords k1ÔøΩÔøΩÔøΩÔøΩÔøΩkm to the system. These keywords are looked up in the master index, which returns the tuple sets R k1 i ÔøΩÔøΩÔøΩÔøΩÔøΩRkm i for each relation Ri. Every tuple of R k j i contains keyword k j as part of an attribute value. Then DISCOVER calculates all candidate networks, i.e., join expressions on foreign to primary key relationships of relations or tuple sets, as shown in Figure 3. The set of candidate networks is guaranteed to produce all Keywords \"Smith\",\"Miller\" Basic Tuple Sets Master Index Tuple Set Post-Processor Tuple Sets ORDERS Candidate Network Generator Smith ={o } 1 ORDERSMiller ={o ,o } 2 3 Database Schema Candidate Networks Execution Plan Joining Networks of tuples SQL queries Plan Generator Plan Execution Database User CREATE TABLE T1 AS SELECT * FROM ORDERS Smith , CUSTOMERS WHERE ... SELECT * FROM T 1 , ORDERS Miller WHERE ... SELECT * FROM T 1 , NATION, CUSTOMERS, ORDERS Miller WHERE ... Figure 3: Architecture of DISCOVER the minimal joining networks. Then DISCOVER evaluates the candidate networks. Due to the nature of the problem, the candidate networks share join expressions. This offers an opportunity to build a set of intermediate results and use them in the computation of multiple candidate networks. The Plan Generator produces an execution plan that calculates and uses intermediate results in evaluating the candidate networks. Finally an SQL statement is produced for each line of the execution plan and these statements are passed to the DBMS. The DBMS returns the joining networks of tuples that are the solutions to the problem. Notice that the candidate networks may have a number of joins that is only bound by the dataset as it is explained later. In these cases the user supplies a maximum number T of joins and DISCOVER incrementally outputs all candidate networks up to size T . The challenges involved in the above process and the contributions of this paper are the following: ¬Ø We formalize keyword search on relational databases and provide intuitive semantics. ¬Ø We propose a modular architecture and have implemented DISCOVER based on it. ¬Ø We present an efficient candidate network generation algorithm. The naive approach would be to generate all join expressions up to size T that contain all keywords and then evaluate them. However, we prune out many of them by exploiting the properties of the schema of the database and the information returned by the master index. For example in the keyword query \u201aÄúSmith, Miller\u201aÄù, the candidate network ORDERS Smith CUSTOMER ÔøΩÔøΩ ORDERS Miller LINEIT EM ÔøΩÔøΩ is pruned out because LINEIT EM ÔøΩÔøΩ has no keywords and since it is in the end of the joining sequence\u201aÄôs chain, it cannot help in joining any tuple that could lead to a keyword. For more complex reasons, pertaining to the structure of the primary key to foreign key relationships as discussed later, candidate networks such as ORDERS Smith LINEIT EM ÔøΩÔøΩ ORDERS Miller are also excluded. ¬Ø We prove that the candidate network generation algorithm creates a complete and non-redundant set of candidate networks, where \u201aÄúcomplete\u201aÄù means that the set of candidate networks produces all minimal joining networks of tuples (up to a given size T ) and \u201aÄúnonredundant\u201aÄù means that if any candidate network of the set is excluded then there are database instances where there are minimal joining networks of tuples that are not discovered. It is also shown that the results of the candidate networks are always minimal joining networks of tuples. ¬Ø We specify when the maximum size of the candidate networks is bound by the size of the database schema and when it is bound only by the size of the database instance. For the former case, we provide theorems that specify the maximum size Tmax of the minimal joining networks of tuples, as a function of the database schema. ¬Ø We propose a cost model. The Plan Generator module uses intermediate results to minimize the total cost of the evaluation of all candidate networks. We show that the problem of selecting the optimal set of intermediate results is NP-complete on the size of the candidate networks. We then present a tunable greedy algorithm that discovers near-optimal plans, without suffering from the unacceptable optimization time cost incurred by the optimal planning algorithm. ¬Ø DISCOVER has been implemented on top of Oracle 8i. We present a detailed experimental evaluation of the modules of DISCOVER and of the overall system. It is shown that a large percentage of the generated candidate networks are pruned. Furthermore, we show how to tune the greedy algorithm to achieve the best possible performance and we show that the overall performance beats by far the performance of the obvious straightforward approaches. In Section 2 we compare DISCOVER to other related efforts. Sections 4 and 5 present the Candidate Network Generator and the Plan Generator module respectively. In Section 6 we evaluate experimentally the performance of DISCOVER. Finally, in Section 7 we conclude and discuss future extensions and improvements of DISCOVER. 2 Related Work A framework for keyword search on databases when the schema is not known to the user is presented in [MV00b, MV00a]. An extension of SQL called Reflective SQL (RSQL) is introduced, which treats data and queries uniformly. The main limitation of this work is that all keywords must be contained in the same tuple. That is, the re- lationships between tuples from different relations are not taken into consideration. In [GSVGM98] and [BNH 02], a database is viewed as a graph with objects/tuples as nodes and relationships as edges. Relationships are defined based on the properties of each application. For example an edge may denote a primary to foreign key relationship. In [GSVGM98], the user query specifies two sets of objects, the Find and the Near objects. These objects may be generated from two corresponding sets of keywords. The system ranks the objects in Find according to their distance from the objects in Near. An algorithm is presented that efficiently calculates these distances by building hub indices. In [BNH 02], answers to keyword queries are provided by searching for Steiner trees [Ple81] that contain all keywords. Heuristics are used to approximate the Steiner tree problem. A drawback of these approaches is that a graph of the tuples must be created and maintained for the database. Furthermore, the important structural information provided by the database schema is ignored and their algorithms work on huge data graphs. In contrast, DISCOVER is tuned to keyword search on relational databases and uses the properties of the schema of the database. Its key algorithms work on the schema graph, which is much smaller than the data graph, and does not need to keep any extra data representations. It exploits the properties of the database schema to produce the minimum number of SQL queries needed to answer to the keyword query. Furthermore, DISCOVER operates directly on the databases, so it does not have a main memory space limitation. The work of the Candidate Network Generator reminds of algorithms for answering queries on universal relations [Ull82]. However there are many important differences between universal relations and DISCOVER: First, there is the obvious difference that the user of a Universal Relation (UR) needs to know the attributes where the keywords are, in contrast to the user of DISCOVER. Second, DISCOVER creates efficient queries that find all connections between the tuples that contain the keywords. In doing so, DIS- COVER, unlike the UR, has to find connections whose size may not be schema bound and many of them are pruned by DISCOVER\u201aÄôs Candidate Network Generator. Finally, in addition to finding the useful connections, DISCOVER exploits the fact that the connections are \u201aÄúcorrelated\u201aÄù, in the sense that they share join expressions. This leads to a special query optimization algorithm, which is tuned to the specifics of our problem. DBXplorer [ACD02] describes a multi-step system to answer keyword queries in relational databases and frees the user from the first limitation of the universal relations. However it does not consider solutions that include two tuples from the same relation. Furthermore they only consider exact matches, where a keyword must match exactly an attribute value and they do not exploit the reusability opportunities of the join trees, which is a simplified notion close to the candidate networks of DISCOVER. Oracle 9i Text ([Ora01]) and IBM DB2 Text Informa- tion Extender ([DB201]) use standard SQL to create full text indices on text attributes of relations. Microsoft SQL Server 2000 ([MSD01]) also provides tools to generate full text indices, which are stored in files outside the database. In all three systems, the user creates full text indices on single attributes and then performs keyword queries, which return the tuples that contain a keyword. Furthermore, keyword proximity queries are supported within a single attribute of a tuple, but not across different attributes or tuples. As we discuss, generalizing keyword search to work across tuples is very challenging and the issues are different from the text indexing issues that those systems address. One of the criteria that we use to decide that a join expression J is not a candidate network is whether the joining networks of tuples produced by J contain more than one occurrences of the same tuple. Our approach for deciding this property can be viewed as a special case of the chase technique with inclusion dependencies presented in [AHV95]. Our algorithm is simpler, faster and decidable, since it focuses on primary to foreign key relationships. Keyword search has been well studied for document databases ([Sal89]). For example [BP98] presents the Google search engine. [ACGM 01] offers an overview of current Web search engine design. It also introduces a generic search engine architecture and covers crawling and indexing issues. In [TWW 00], algorithms , data structures, and software are presented that approach the speed of keyword-based document search engines for queries on structural databases like parse trees, molecular diagrams and XML documents. [FKM99] tackles the keyword search problem in XML databases. They propose an extension to XML query languages that enables keyword search at the granularity of XML elements, which helps novice users formulate queries, but do not consider keyword proximity search. The use of common subexpressions by the Plan Generator is a form of multi-query optimization [Sel88, Fin82, RSSB00]. However the candidate networks in DISCOVER have special properties that allow us to develop a more straightforward and efficient algorithm. The first property is that the candidate networks have small relations [Ull82] as leaves, which dramatically prunes the space of useful common subexpressions when applying the Wong-Yusefi algorithm [Ull82]. Second, the candidate networks are not random queries, but share common subexpressions by the nature of their generation as we see in Section 4. The techniques of [Fin82] cannot be applied to DISCOVER since they concentrate on finding common subexpressions as a post-phase to query optimization and DISCOVER does not have access to the DBMS optimizer. "},{"aspect":"expintro","tweet":" We evaluate the algorithms of DISCOVER with detailed performance evaluation on a TPC-H database. First we measure the pruning efficiency of the candidate network generator. In particular, we measured how many joining networks of tuple sets are ruled out based on the pruning conditions of the candidate network generator. Then we compare the plans produced by the greedy to the ones produced by the optimal, where the optimal execution plan is computed using an exhaustive algorithm. We also compare the speedup in runtime performance for generating and executing the execution plan using the greedy and the optimal algorithm compared to the naive method, where no intermediate results are built. Finally, we compare the overall execution times of DISCOVER for some typical #keyw JNTS K JNTS L CNs neTS\u201aÄôs 2 25 5.355 4.485 2.96 3 55.22 13.86 9.27 4.35 4 85.69 33.88 24.03 5.91 5 101 37.3 26 7.12 (a) Fix maximum candidate networks\u201aÄô size to 3 MaxCNsize JNTS K JNTS L CNs neTS\u201aÄôs 1 0.95 0.95 0.95 2.96 2 3.72 2.36 2.12 2.96 3 29.22 4.74 3.7 2.96 4 422.88 10.36 6.4 2.96 5 6941 24.75 11.45 2.96 (b) Fix number of keywords to 2 MaxCNsize JNTS K JNTS L CNs neTS\u201aÄôs 1 0.59 0.59 0.59 4.35 2 5.01 3.91 3.35 4.35 3 55.22 13.86 9.27 4.35 4 639.61 50.49 29.51 4.35 5 7532 223 103.66 4.35 (c) Fix number of keywords to 3 Figure 9: Evaluation of the candidate network generator keyword queries to the naive method and to the optimal method. We use the TPC-H database to conduct the experiments. The size of the database is 100MB. We use Oracle 9i, running on a Xeon 2.2GHz PC with 1GB of RAM. DIS- COVER has been implemented in Java and connects to the DBMS through JDBC. The master index is implemented using the full-text Oracle9i interMedia Text extension. The basic tuple set of relation R for keyword k is produced by merging the tuples returned by the full-text index on each attribute of R. We found out that each keyword is contained on the average in 3ÔøΩ5 relations, that is, 3ÔøΩ5 non-empty basic tuple sets are created for each keyword. The tuple sets and the intermediate results are stored in tables in the KEEP buffer pool of Oracle 9i, which retains objects in memory, thus avoiding I/O operations. We dedicated 70MB to the KEEP buffer pool. The display time is not included in the measured execution time. The naive method does not produce any intermediate results \u201aÄì it simply executes each candidate network. The execution times for both the naive method and DISCOVER\u201aÄôs evaluation method, which builds and reuses intermediate results, depend on the status of the cache of the DBMS. In order to eliminate this factor we warm-up the cache before executing the experiments. The warm-up is done by executing the SQL queries corresponding to the candidate networks produced by the candidate network generator. Hence, we are certain that the warm-up does not favor DISCOVER more than the naive method. "},{"aspect":"problemdef","tweet":""},{"aspect":"solution","tweet":" 3 Framework 3.1 Data Model and Keyword Queries We consider a database that has n relations R1ÔøΩÔøΩÔøΩÔøΩÔøΩRn. Each relation Ri has mi attributes ai 1ÔøΩÔøΩÔøΩÔøΩÔøΩaimi . The schema graph G is a directed graph that captures the primary key to for- eign key relationships in the database schema. It has a node Ri for each relation Ri of the database and an edge Ri ÔøΩ R j for each primary key to foreign key relationship from a set of attributes a i b1 ÔøΩÔøΩÔøΩÔøΩÔøΩai b l of Ri to a set of attributes a j b1 ÔøΩÔøΩÔøΩÔøΩÔøΩa j b l of R j, where a i b k ÔøΩ a j b k for k ÔøΩ 1ÔøΩÔøΩÔøΩÔøΩÔøΩl. We define the graph Gu to be the undirected version of G. For notational simplicity, we assume that the attributes of a primary to foreign key relationship have the same name and that there are no self loops or parallel edges in the schema graph. So an edge Ri ÔøΩ R j uniquely identifies the corresponding primary and foreign key attributes. We also assume that no set of attributes of any relation is both a primary key and a foreign key for two other relations, which is a reasonable assumption for any realistic database schema design. The generalization of the problem and the solution when these assumptions do not hold is trivial. We denote the primary key of a tuple t R as p t and its foreign key that references relation S as f S t . Definition 1 (Joining network of tuples) A joining network of tuples j is a tree of tuples where for each pair of adjacent tuples tiÔøΩt j j, where ti RiÔøΩt j R j, there is an edge RiÔøΩRj in Gu and t i t j Ri R j . The size of a joining network is the number of joins that it involves, which is one less than the tree\u201aÄôs size. An exam- c1 ple of a joining network of tuples in Figure 2 is o o n , 1 2 1 which can be written in line notation as c1ÔøΩo1ÔøΩo2ÔøΩn1\u201aÑÑ or o1ÔøΩc1ÔøΩo2ÔøΩn1\u201aÑÑ\u201aÑÑ. Its size is 3. A joining sequence of tuples is a special case of a joining network of tuples, where each internal node of the tree has exactly two adjacent nodes. An example of a joining sequence of tuples in Figure 2 is c1ÔøΩo1ÔøΩo2\u201aÑÑ, also denoted as o1 c1 o2. Definition 2 (Keyword Query) A keyword query is a set of keywords k1ÔøΩÔøΩÔøΩÔøΩÔøΩkm. The result of the keyword query is the set of all possible joining networks of tuples that are both: ¬Ø Total: every keyword is contained in at least one tuple of the joining network. ¬Ø Minimal: we can not remove any tuple from the joining network and still have a total joining network of tuples. We call such joining networks Minimal Total Joining Networks of Tuples (MTJNT) of the keywords k1ÔøΩÔøΩÔøΩÔøΩÔøΩkm or simply MTJNT\u201aÄôs when the corresponding set of keywords is obvious from the context. It is obvious from the definition that the result of a keyword query is unique. A keyword query may also be given the maximum size T of the result MTJNT\u201aÄôs. The answers to keyword queries with two keywords are always joining sequences of tuples. On the other hand, when we have more than two keywords then the answer most often cannot be expressed as a joining sequence, so we need a joining network. Consider for example the keyword query \u201aÄúSmith, Miller, USA\u201aÄù. The best (smallest) answer to this query is MTJNT c1ÔøΩo1ÔøΩo2ÔøΩn1\u201aÑÑ. Q R S R A C Q A B S B D r 1 r 2 r 3 ... r n a 1 a 2 a 3 c 1 c 2 c 3 ... an cn q1 q2 q3 q4 q5 a1 a2 a2 a3 a3 ... an an b1 b1 b2 b2 b3 bn-1 bn (a) (b) Figure 4: A many-to-many relationship ... q2n-2 q2n-1 If there is a many-to-many relationship between two relations of a database, then the MTJNT\u201aÄôs could have an arbitrarily big size, which is only data bound. Figure 4 shows an extreme case where there is a many-to-many relationship between two relations RÔøΩS. There is a foreign to primary key relationship from Q to R and from Q to S on the homonymous attributes. Suppose that attribute values c 1 and dn contain the two keywords of a query. The MTJNT r1 q1 s1 q2 r2 ÔøΩÔøΩÔøΩ rk q2k¬\u2020 1 sk q2k ÔøΩÔøΩÔøΩ rn q2n¬\u2020 1 sn uses all tuples from all three relations, as shown by the arrows in Figure 4. So we see that the size of the joining sequence can only be bound by the dataset when there are many-to-many relationships. Keep in mind that a keyword may be in more than one tuples of the same relation or in different relations. An example of the first case is the \u201aÄúMiller\u201aÄù keyword that appears in two tuples (o2 and o3) of the ORDERS relation. For the second case, consider the keyword query \u201aÄúJohn, USA\u201aÄù, where the keyword \u201aÄúJohn\u201aÄù is contained in both tuples o 1 and c3. Two joining sequences for this keyword query are c3 n1 and o1 c1 n1. Notice that the joining sequences in the result in this case are heterogeneous. 3.2 Architecture In this section we walk through the components of DIS- COVER (see Figure 3) and formally define the structure of their inputs and outputs. The Master Index inputs a set of keywords k1ÔøΩÔøΩÔøΩÔøΩÔøΩkm and outputs a set of basic tuple sets ¬ØR k j i for i ÔøΩ 1ÔøΩÔøΩÔøΩÔøΩÔøΩn and j ÔøΩ 1ÔøΩÔøΩÔøΩÔøΩÔøΩm. The basic tuple set ¬ØR k j i consists of all tuples of relation Ri that contain the keyword k j. The master index has been implemented using the Oracle8i interMedia Text 8.1.5 extension, which builds full text indices on single attributes of relations. Then the master index inspects the index of each attribute and combines the results. 1 Then the Tuple Set Post-Processor takes the basic tuple sets and produces tuple sets R K i for all subsets K of 1 We are currently building from scratch a more efficient master index using an inverted index that has one entry for each keyword k and the entry has references to all tuples that contain k. However, the master index choice does not affect the key challenges and tradeoffs discussed in this paper. s 1 s 2 s 3 ... s n b 1 b 2 b 3 ... b n d 1 d 2 d 3 d n ÔøΩk1ÔøΩÔøΩÔøΩÔøΩÔøΩkmÔøΩ, where R K i ÔøΩ ÔøΩtÔøΩt Ri ÔøΩÔøΩk KÔøΩt contains k ÔøΩ ÔøΩk ÔøΩk1ÔøΩÔøΩÔøΩÔøΩÔøΩkmÔøΩ¬\u2020 KÔøΩt does not contain kÔøΩ (1) i.e., RK i contains the tuples of Ri that contain all keywords of K and no other keywords. The tuple sets are obtained from the basic tuple sets using the following formula. ÔøΩ ¬ØR k i ¬\u2020 ÔøΩ (2) R K i ÔøΩ k K k ÔøΩk1 ÔøΩÔøΩÔøΩÔøΩÔøΩkmÔøΩ¬\u2020 K The non-empty tuple sets along with the schema graph of the database are passed to the Candidate Network Generator. For brevity reasons that become clear below, we will call the database relations, which appear in the schema graph, free tuple sets. They are denoted as R ÔøΩÔøΩ . Definition 3 (Joining Network of Tuple Sets) A joining network of tuple sets J is a tree of tuple sets where for each pair of adjacent tuple sets R K i ÔøΩRM j in J there is an an edge RiÔøΩRj in Gu. For example a joining network of tuple sets for the database of Figures 1, 2 is CUSTOMER ÔøΩÔøΩ ÔøΩORDERS Smith ÔøΩORDERS Miller ÔøΩ NATION ÔøΩÔøΩ \u201aÑÑ. A joining sequence of tuple sets is a special case of joining networks of tuples, where each intermediate node of the tree has exactly two adjacent nodes and it is denoted as TS1 ÔøΩÔøΩÔøΩ TSl. We say that a joining network of tuples j belongs to a joining network of tuple sets J ( j J) if there is a tree isomorphism mapping h from the tuples of j to the tuple sets of J, such that for each tuple t jÔøΩ t h t . For example, in the instance of 2, c1ÔøΩo1ÔøΩo2ÔøΩn1\u201aÑÑ CUSTOMER ÔøΩÔøΩ ÔøΩORDERS Smith ÔøΩORDERS Miller ÔøΩ NATION ÔøΩÔøΩ \u201aÑÑ. DISCOVER does not generate any joining networks of tuple sets that are redundant or cannot produce any MTJNT\u201aÄôs. We call the joining networks of tuple sets generated by DISCOVER candidate networks. Definition 4 (Candidate Network) Given a set of keywords k1ÔøΩÔøΩÔøΩÔøΩÔøΩkm, a candidate network C is a joining network of tuple sets, such that there is an instance I of the database that has a MT JNT M C and no tuple t M that maps to a free tuple set F C contains any keywords. We need the last condition to make sure that no keywords are accidentally added to M. Such a MTJNT will also belong to a candidate network that has a non-empty tuple set instead of F, so C is redundant. For example, consider the database instance of Figure 2 and the keyword query \u201aÄúSmith, Miller\u201aÄù. J ÔøΩ ORDERSSmith CUSTOMER ÔøΩÔøΩ ORDERSÔøΩÔøΩ is not a candidate network even though the MTJNT o 1 c1 o2 belongs to J. J is subsumed by ORDERSSmith CUSTOMER ÔøΩÔøΩ ORDERSMiller . There are many joining networks of tuple sets that are not candidate networks. For example, the network J ÔøΩ ORDERSSmith LINEIT EM ÔøΩÔøΩ ORDERSMiller is not a ¬ØR k i candidate network because there is no joining network of tuples j ÔøΩ o S l o M where j J and o S ÔøΩÔøΩ o M . We will analyze the conditions that promote a network into a candidate network in Section 4. Each candidate network of size N will produce zero or more MTJNT\u201aÄôs of size N. The result of the keyword search is the union of the MTJNT\u201aÄôs produced by all possible candidate networks. The set of candidate networks is passed to the Plan Generator, which optimizes the evaluation of the candidate networks. Definition 5 (Execution Plan) Given a set C1ÔøΩÔøΩÔøΩÔøΩÔøΩCr of candidate networks, an execution plan is a list A1ÔøΩÔøΩÔøΩÔøΩÔøΩAs of assignments of the form Hi ÔøΩ Bi1 ÔøΩÔøΩÔøΩ Bit where: ¬Ø Each Bi j is either a tuple set or an intermediate result defined in a previous assignment. The latter requires that there is an index k ÔøΩ i, such that Hk ÔøΩ Bi j . ¬Ø For each candidate network C there is an assignment Ai, that computes C. For example, an execution plan for the keyword query shown in Figure 3 is T1 ÔøΩ ORDERS Smith CUSTOMER ÔøΩÔøΩ ÔøΩ C1 ÔøΩ T1 ORDERS Miller ÔøΩ C2 ÔøΩ T1 NATION ÔøΩÔøΩ CUSTOMER ÔøΩÔøΩ ORDERS Miller where T1 is an intermediate result. The number of joins of this plan is 5, whereas the number of joins to evaluate the two candidate networks without building any intermediate results would be 6. As the number of candidate networks increases the difference in the number of joins increases dramatically. Finally the execution plan is passed to the Plan Execution module, which translates the assigments of the plan to SQL statements. The assignments that build intermediate results are translated to \u201aÄúCREATE TABLE\u201aÄù statements and the candidate network evaluation assigmnents to \u201aÄúSELECT-FROM-WHERE\u201aÄù statements. The union of the results of these \u201aÄúSELECT-FROM-WHERE\u201aÄù statements is the result of the keyword search and it is returned to the user. The smaller MTJNT\u201aÄôs are returned first. 4 Candidate Network Generation The Candidate Network Generator inputs the set of keywords k1ÔøΩÔøΩÔøΩÔøΩÔøΩkm, the non-empty tuple sets RK i and the maximum candidate networks\u201aÄô size T and outputs a complete and non-redundant set of candidate networks. The key challenge is to avoid the generation of redundant joining networks of tuple sets. The solution to this problem requires an analysis of the conditions that force a joining network of tuples to be non-minimal - the condition for the totality of the network is straightforward. Then the candidate networks generation algorithm is presented and we present theorems that show that it is i complete, ie., every MTJNT is produced by a candidate network output by the algorithm, and ii it does not produce any redundant candidate networks. Finally we give an example of the algorithm\u201aÄôs execution steps. We must ensure that the joining networks of tuples that belong to a candidate network are total and minimal. The condition that a joining network of tuple sets J must satisfy in order to ensure totality of the produced joining networks of tuples j J is to contain all keywords. That is, ÔøΩk ÔøΩk1ÔøΩÔøΩÔøΩÔøΩÔøΩkmÔøΩÔøΩÔøΩR K i JÔøΩk K (3) For example ORDERSSmith CUSTOMER ÔøΩÔøΩ ORDERSÔøΩÔøΩ is not total with respect to the keyword query \u201aÄúSmith, Miller\u201aÄù. Equation 3 does not ensure minimality. There are two cases when a joining network of tuples j is not minimal. 1. A joining network of tuples j is not minimal if it has a tuple with no keywords as a leaf. In this case we can simply remove this leaf. We carry this condition to joining networks of tuple sets by not allowing free tuple sets as leaves. For example ORDERSSmith CUSTOMER ÔøΩÔøΩ ORDERSMiller CUSTOMER ÔøΩÔøΩ is rejected since it has the free tuple set CUSTOMER ÔøΩÔøΩ as a leaf. 2. j is not minimal if it contains the same tuple t twice. In this case we can collapse the two occurrences of t. We carry this condition to joining networks of tuple sets by detecting networks that are bound to produce non-minimal joining networks of tuples, regardless of the database instance. According to this condition, the joining network of tuple sets J ÔøΩ ORDERS Smith LINEIT EM ÔøΩÔøΩ ORDERSMiller is ruled out because the structure of J ensures that all the produced joining networks of tuples j ÔøΩ oS l oM will contain the same tuple twice. To see this suppose that oS has primary key p oS . It is joined with l, sol has foreign key fORDERS l ÔøΩp oS . l will also join with oM ORDERSMiller . So, it is p oM ÔøΩ fORDERS l ÔøΩp oS . Hence oM ÔøΩ oS ÔøΩ oMÔøΩS and j cannot be minimal. Theorem 1 presents a criterion that determines when the joining networks of tuples produced by a joining network of tuple sets J have more than one occurrences of a tuple. Theorem 1 A joining network of tuples j produced by a joining network of tuple sets J has more than one occurrences of the same tuple for every instance of the database if and only if J contains a subgraph of the form R K \u201aÄîS L \u201aÄî R M , where RÔøΩS are relations and there is an edge R ÔøΩ Sin the schema graph. Hence, we conclude to the following criterion. Criterion 1 (Pruning Condition) A candidate network does not contain a subtree of the form R K \u201aÄîS L \u201aÄîR M , where R and S are relations and the schema graph has an edge R ÔøΩ S. ÔøΩ√êÔøΩ√ì√ñÔøΩ√òÔøΩ√ë ÔøΩÔøΩ√íÔøΩÔøΩÔøΩÔøΩ√òÔøΩ √ÜÔøΩ√ò√õ√ì√ñÔøΩ√ó ÔøΩÔøΩ√íÔøΩ√ñÔøΩ√ò√ì√ñ Input: tuple set graph GTS, T, k1ÔøΩÔøΩÔøΩÔøΩÔøΩkm Output: set of candidate networks with size up to T ÔøΩ √âÔøΩ √ï√ôÔøΩ√ôÔøΩ √ìÔøΩ ÔøΩ√ìÔøΩ√íÔøΩ√íÔøΩ √íÔøΩ√ò√õ√ì√ñÔøΩ√ó √ìÔøΩ √ò√ô√î√êÔøΩ √óÔøΩ√ò√ó √àÔøΩ ÔøΩ ÔøΩ ÔøΩÔøΩ√ù√õ√ì√ñÔøΩ kt ÔøΩk1ÔøΩÔøΩÔøΩÔøΩÔøΩkmÔøΩ ÔøΩ√ì√ñ ÔøΩÔøΩ ÔøΩ √ò√ô√î√êÔøΩ √óÔøΩ√ò RK i √õÔøΩÔøΩ√ñÔøΩ i ÔøΩ 1ÔøΩÔøΩÔøΩÔøΩÔøΩn ÔøΩ√íÔøΩ kt K ÔøΩ√ì ÔøΩÔøΩÔøΩ ÔøΩ√ìÔøΩ√íÔøΩ√íÔøΩ √íÔøΩ√ò√õ√ì√ñÔøΩ√ó √ìÔøΩ √ò√ô√î√êÔøΩ √óÔøΩ√ò√ó RK i √ò√ì Q √õÔøΩÔøΩ√êÔøΩ Q √í√ì√ò ÔøΩ√ë√î√ò√ù ÔøΩ√ì ÔøΩ ÔøΩÔøΩ√ò ÔøΩÔøΩÔøΩÔøΩ C ÔøΩ√ñ√ì√ë Q ÔøΩÔøΩ C √óÔøΩ√òÔøΩ√óÔøΩÔøΩÔøΩ√ó √òÔøΩÔøΩ √î√ñ√ô√íÔøΩ√íÔøΩ √ì√íÔøΩÔøΩ√òÔøΩ√ì√í √òÔøΩÔøΩ√í ÔøΩÔøΩ√í√ì√ñÔøΩ C ÔøΩ√ê√óÔøΩ ÔøΩÔøΩ C √óÔøΩ√òÔøΩ√óÔøΩÔøΩÔøΩ√ó √òÔøΩÔøΩ ÔøΩ ÔøΩ√î√òÔøΩ√í ÔøΩ √ì√íÔøΩÔøΩ√òÔøΩ√ì√í√ó √òÔøΩÔøΩ√í √ì√ô√ò√î√ô√ò C √åÔøΩÔøΩ√ñÔøΩ ÔøΩ√ó √í√ì √ñÔøΩÔøΩ√ó√ì√í √ò√ì ÔøΩ√ú√òÔøΩ√íÔøΩ ÔøΩ ÔøΩ√ê√óÔøΩ ÔøΩ√î√òÔøΩÔøΩ ÔøΩ√ìÔøΩ√íÔøΩ√íÔøΩ √íÔøΩ√ò√õ√ì√ñÔøΩ√ó √ìÔøΩ √ò√ô√î√êÔøΩ √óÔøΩ√ò√ó ÔøΩ√ì√ñ ÔøΩÔøΩ ÔøΩ √ò√ô√î√êÔøΩ √óÔøΩ√ò RK i ÔøΩÔøΩÔøΩÔøΩ ÔøΩ√í√ò ÔøΩ√í GTS ÔøΩ ÔøΩÔøΩ K ÔøΩ ÔøΩÔøΩ √á√ä ÔøΩR ÔøΩÔøΩ√í√ì√ñÔøΩ√íÔøΩ ÔøΩÔøΩÔøΩÔøΩ ÔøΩÔøΩ√ñÔøΩ √òÔøΩ√ì√í √ò√ì ÔøΩ √í√ìÔøΩÔøΩ √ìÔøΩ C M j C ÔøΩ RK i ÔøΩM ÔøΩÔøΩ ÔøΩÔøΩ ÔøΩ keywords C ÔøΩ RK i ÔøΩkeywords C ÔøΩ RKi ¬\u2020 RM ÔøΩ√ú√îÔøΩ√í√óÔøΩ√ì√í √ñ√ô√êÔøΩ j ÔøΩ√íÔøΩ √óÔøΩ√ûÔøΩ √ìÔøΩ C ÔøΩ T √òÔøΩÔøΩ√í ÔøΩ ÔøΩÔøΩ RK i ÔøΩ√ó ÔøΩÔøΩÔøΩÔøΩ ÔøΩ√í√ò √ò√ì RMj ÔøΩ√í C ÔøΩ RMj ÔøΩÔøΩÔøΩÔøΩ\u201aÑÑ √òÔøΩÔøΩ√í C ÔøΩ RKi ÔøΩRMj ÔøΩÔøΩÔøΩÔøΩ\u201aÑÑ\u201aÑÑ √à√ô√ò C ÔøΩ√í Q ÔøΩ ÔøΩ√ê√óÔøΩ ÔøΩÔøΩ√í√ì√ñÔøΩ RK i ÔøΩ ÔøΩ 4.1 Candidate Networks Generation Algorithm The candidate network generation algorithm is shown in Figure 5. First, we create the tuple set graph GTS. A node RK i is created for each non-empty tuple set RK i , including the free tuple sets. An edge RK i ÔøΩ RMj is added if the schema graph G has an edge Ri ÔøΩ R j. The algorithm is based on a breadth-first traversal of GTS. We keep a queue Q of \u201aÄúactive\u201aÄù joining networks of tuple sets. In each round we pick from Q an active joining network of tuple sets J and either i discard J because of the pruning condition (Criterion 1) or ii output J as a candidate network or iii expand J into larger joining networks of tuple sets (and place them in Q). We start the traversal from all tuple sets that contain a randomly selected keyword kt ÔøΩk1ÔøΩÔøΩÔøΩÔøΩÔøΩkmÔøΩ. An active joining network of tuple sets C is expanded according to the following expansion rule: A new active joining network of tuple sets is generated for each tuple set RK i , adjacent to C in GTS, if either RK i is a free tuple set (K ÔøΩ ÔøΩÔøΩ) or after the addition of RK i to C every nonfree tuple set of C (including RK i ) contributes at least one keyword that no other non-free tuple set contributes, i.e., ÔøΩ ÔøΩR M j C ÔøΩ R K i ÔøΩM ÔøΩÔøΩ ÔøΩÔøΩÔøΩ keywords C ÔøΩ R K i ÔøΩkeywords C ÔøΩ RK i ¬\u2020 R M j where keywords J returns the union of keywords in the tuple sets of the joining network of tuple sets J, i.e., keywords J ÔøΩ √ã RK i J K. A free tuple set may be visited more than once. Each non-free tuple set is used at most once in each candidate network. The reason is that, for all database instances, the result of a joining network of tuple sets J with two occurrences of the same non-free tuple set Figure 5: Algorithm for generating the candidate networks RK i is subsumed by the result of a joining network of tuple sets J , generated by the algorithm, that is identical to J but has R ÔøΩÔøΩ i instead of the second occurrence of RK i . In addition, the implementation never places in Q a joining network of tuples sets J that has more than m leaves, where m is the number of keywords in the query. For example, if the keywords are two then only joining sequences are placed in Q. Indeed, even if this rule were excluded the output of the algorithm would be the same, since such a network J can neither meet the acceptance conditions listed next nor be expanded into a network J that meets the acceptance conditions. Nevertheless, the rule leads to cleaner traces and better running time. The algorithm outputs a joining network of tuple sets J if it satisfies the following acceptance conditions: ¬Ø The tuple sets of J contain all keywords, i.e., keywords J ÔøΩÔøΩk1ÔøΩÔøΩÔøΩÔøΩÔøΩkmÔøΩ. ¬Ø J does not contain any free tuple sets as leaves. An important property of the algorithm is that it outputs the candidate networks with increasing size. That is, the smaller candidate networks, which are the better solutions to the keyword search problem, are output first. Theorems 2 and 3 prove the completeness and the minimality of the results of the algorithm. Theorem 2 (Completeness) Every solution of size T to the keyword query is produced by a candidate network of size T , output by the candidate network generator. Theorem 3 (No Redundancy) For each candidate network C output by the algorithm, given the tuple set graph PART (P {} ) ORDERS (O {} PARTSUPP (PS ) {} ) LINEITEM (L {} ) SUPPLIER (S {} ) CUSTOMER (C {} ) NATION (N {} ) Figure 6: Tuple set graph ORDERS Smith (O Smith ) ORDERS Miller (O Miller ) REGION (R {} ) # Queue/from/candidate networks output 1a O Smith 2a O Smith L ÔøΩÔøΩ /1a b O Smith C ÔøΩÔøΩ /1a 3a O Smith L ÔøΩÔøΩ O ÔøΩÔøΩ (pruned)/2a b O Smith L ÔøΩÔøΩ O Miller (pruned)/2a c O Smith L ÔøΩÔøΩ PS ÔøΩÔøΩ /2a d O Smith C ÔøΩÔøΩ O ÔøΩÔøΩ /2b e O Smith C ÔøΩÔøΩ O Miller /2b f O Smith C ÔøΩÔøΩ N ÔøΩÔøΩ /2b 4a O Smith L ÔøΩÔøΩ PS ÔøΩÔøΩ P ÔøΩÔøΩ /3c/ O Smith C ÔøΩÔøΩ O Miller b O Smith L ÔøΩÔøΩ PS ÔøΩÔøΩ L ÔøΩÔøΩ /3c c O Smith C ÔøΩÔøΩ O ÔøΩÔøΩ C ÔøΩÔøΩ (pruned)/3d d O Smith C ÔøΩÔøΩ N ÔøΩÔøΩ C ÔøΩÔøΩ /3f ÔøΩÔøΩÔøΩ 5a O Smith L ÔøΩÔøΩ PS ÔøΩÔøΩ P ÔøΩÔøΩ PS ÔøΩÔøΩ (pruned)/4a b O Smith L ÔøΩÔøΩ PS ÔøΩÔøΩ L ÔøΩÔøΩ O Miller /4b c O Smith C ÔøΩÔøΩ N ÔøΩÔøΩ C ÔøΩÔøΩ O Miller /4d d O Smith C ÔøΩÔøΩ N ÔøΩÔøΩ C ÔøΩÔøΩ O ÔøΩÔøΩ /4d e O Smith C ÔøΩÔøΩ N ÔøΩÔøΩ C ÔøΩÔøΩ N ÔøΩÔøΩ (pruned)/4d ÔøΩÔøΩÔøΩ 6a O Smith C ÔøΩÔøΩ N ÔøΩÔøΩ C ÔøΩÔøΩ O ÔøΩÔøΩ C ÔøΩÔøΩ (pruned)/5d/ O Smith C ÔøΩÔøΩ N ÔøΩÔøΩ C ÔøΩÔøΩ O Miller ÔøΩÔøΩÔøΩ//O Smith L ÔøΩÔøΩ PS ÔøΩÔøΩ L ÔøΩÔøΩ O Miller 7 ÔøΩÔøΩÔøΩ Figure 7: Example GTS 2 , there is an instance I of the database that produces the same tuple set graph GTS, contains a MTJNT j C and j does not belong to any other candidate network. Example. We present the execution of the candidate network generator algorithm for the keyword query \u201aÄúSmith, Miller\u201aÄù on the TPC-H schema and the database instance in Figure 2, for T ÔøΩ 5. That is, we consider candidate networks having at most 5 joins. The tuple set graph is shown in Figure 6. Suppose we pick \u201aÄúSmith\u201aÄù as the kt of the algorithm. Hence we put ORDERS Smith into the queue. The state of the queue and the candidate networks output in each iteration are shown in Figure 7. We use the obvious abbreviated names for the relations. Since the query has only two keywords, only joining sequences are generated and eventually output. Maximum size of candidate networks. Depending on the form of the database schema, the maximum size Tmax 2 Notice that the candidate network generator does not examine the tuples of a specific tuple set, but only whether it is empty or not. of the candidate networks may be bounded or unbounded by the database schema. Theorem 4 Tmax is unbounded if and only if G has one of the following properties: ¬Ø There is a node of G that has at least two incoming edges. ¬Ø G has a directed cycle. 5 Evaluation of Candidate Networks The Plan Generator module of DISCOVER inputs a set of candidate networks and creates an execution plan to evaluate them as defined in Section 3.2. The key optimization opportunity is that typically the candidate networks share join subexpressions. Efficient execution plans store the common join expressions as intermediate results and reuse them in evaluating the candidate networks. For example, in Figure 3 we calculate and store the join expression ORDERS Smith CUSTOMER ÔøΩÔøΩ . CUSTOMER ÔøΩÔøΩ ORDERS Miller is also a common join expression but it will not help to store both, as we explain below. The space of execution plans that can be generated for a set of candidate networks is huge. We prune it by the following two assumptions: First, we define every non-free tuple set to be a small relation, since its tuples are restricted to contain specific keywords. The result of a join that involves a small relation is also a small relation. Those assumptions lead to the conclusion that every join expression of the plan must contain a small relation and, hence, all intermediate results are small. Note that both the assumptions and the conclusion follow directly the Wong-Yousefi algorithm ([Ull82]) of INGRES. Indeed, in practice, the intermediate results are sufficiently small to be stored in main memory as we discuss in Section 6. Second, the plan generator only considers plans where the right hand side of the assignments Hi ÔøΩ Bi1 ÔøΩÔøΩÔøΩ Bit of Definition 5 in Section 3.2 are joins of exactly two arguments, i.e., t ÔøΩ 2. This policy is based on the assumption that the cost of calculating and storing the results of both A B and A B C is essentially the same with the cost for just calculating and storing the result of A B C, if the DBMS optimizer selects to first calculate A B and then the result of A B C. Hence we can store and possibly reuse later A B \u201aÄúfor free\u201aÄù. This assumption is very precise when there are indices on the primary and foreign key attributes. Then the joins (and, in particular, the most expensive ones) are executed in a series of index-based 2-way joins. The assumption always held for the Oracle 8i DBMS that we used in our TPC-H-based experimentation. (The assumption deviates from reality when there are no indices and the database chooses multi-way merge-sort joins.) In summary, the plan generator considers and evaluates the space of plans where the joins have exactly two arguments. Note that once a plan P is selected from the restricted space we outlined, the plan generator eliminates non-reused intermediate results by inlining their definition into the single point where they are used. That is, given two assignments T ÔøΩ A B T ÔøΩ T C if T is not used at any other place than the computation of T , the two assignments will be merged into T ÔøΩ A B C Cost Model. The theoretical study of the complexity of selecting the optimal execution plan is based on a simple cost model of execution plans: We assign a cost of 1 to each join. We use this theoretical cost model in proving that the selection of the optimal execution plan is NP-complete (Theorem 5). It is easy to see that the problem is also NPhard for the actual cost model of DISCOVER. The actual cost model of DISCOVER exploits the fact that we can get the sizes of the non-free tuple sets from the master index. We also assume that we know the selectivity of the primary to foreign key joins, which can be calculated from the sizes of the relations. The actual cost model defines the cost of a join to be the size of its result in number of tuples. (The cost model can easily be modified to work for the size in bytes instead of the number of tuples.) The cost of the execution plan is the sum of the costs of its joins. Notice that since there are indices on the primary and foreign keys, the cost of a join is proportional to the size of its result, since the joins will typically be index-based joins. The problem of deciding which intermediate results to build and store can be formalized as follows: Problem 1 (Choice of intermediate results) Given a set of candidate networks, find the intermediate results that should be built, so that the overall cost of building these results and evaluating the candidate networks is minimum. Theorem 5 shows that Problem 1 is NP-complete on the size of the candidate networks with respect to the theoretical cost model defined above. Theorem 5 Problem 1 is NP-complete. 5.1 Greedy algorithm Figure 8 shows a greedy algorithm that produces a nearoptimal execution plan, with respect to the actual cost model defined above, for a set of candidate networks by choosing in each step the join m between two tuple sets or f requencya intermediate results that maximizes the quantity logb size , where f requency is the number of occurences of m in the candidate networks, size is the estimated number of tuples of m and aÔøΩb are constants. The f requencya term of the quantity maximizes the reusability of the intermediate results, while the logb size term minimizes the size of the intermediate results that are computed first. We have experimented with multiple combinations of values for a and b and found that the optimal solution is closer approximated ÔøΩ√êÔøΩ√ì√ñÔøΩ√òÔøΩ√ë √ãÔøΩ√êÔøΩ √ò √êÔøΩ√ó√ò √ìÔøΩ ÔøΩ√í√òÔøΩ√ñ√ëÔøΩÔøΩÔøΩÔøΩ√òÔøΩ √ñÔøΩ√ó√ô√ê√ò√ó Input: set S of candidate networks of size ÔøΩ T Output: list L of intermediate results to build ÔøΩ √õÔøΩÔøΩ√êÔøΩ √í√ì√ò ÔøΩ√ê√ê ÔøΩ√íÔøΩÔøΩÔøΩÔøΩ√òÔøΩ √íÔøΩ√ò√õ√ì√ñÔøΩ√ó ÔøΩ√í S ÔøΩÔøΩ√öÔøΩ ÔøΩÔøΩÔøΩ√í ÔøΩÔøΩÔøΩÔøΩÔøΩ √ò√ì L ÔøΩ√ì ÔøΩ √ÑÔøΩ√ò Z ÔøΩÔøΩ √òÔøΩÔøΩ √óÔøΩ√ò √ìÔøΩ ÔøΩ√ê√ê √ó√ëÔøΩ√ê√ê ÔøΩ√ìÔøΩ√í √ó√ôÔøΩÔøΩ√ú√î√ñÔøΩ√ó√óÔøΩ√ì√í√ó √ìÔøΩ 1 ÔøΩ√ìÔøΩ√í √ì√í√òÔøΩÔøΩ√íÔøΩÔøΩ ÔøΩ√í ÔøΩ√ò √êÔøΩÔøΩ√ó√ò √ì√íÔøΩ ÔøΩ√íÔøΩÔøΩÔøΩÔøΩ√òÔøΩ √íÔøΩ√ò√õ√ì√ñÔøΩ ÔøΩ√í SÔøΩ ÔøΩÔøΩÔøΩ √òÔøΩÔøΩ ÔøΩ√í√òÔøΩ√ñ√ëÔøΩÔøΩÔøΩÔøΩ√òÔøΩ √ñÔøΩ√ó√ô√ê√ò m √õÔøΩ√òÔøΩ √òÔøΩÔøΩ f requencya √ëÔøΩ√úÔøΩ√ëÔøΩ√ë√ô√ë √öÔøΩ√ê√ôÔøΩ ÔøΩ√í Z √ò√ì LÔøΩ ÔøΩ ÔøΩ log b size √äÔøΩ√õ√ñÔøΩ√òÔøΩ ÔøΩ√ê√ê ÔøΩ√íÔøΩÔøΩÔøΩÔøΩ√òÔøΩ √íÔøΩ√ò√õ√ì√ñÔøΩ√ó ÔøΩ√í S √ò√ì √ô√óÔøΩ m √õÔøΩÔøΩ√ñÔøΩ √î√ì√ó√óÔøΩÔøΩ√êÔøΩÔøΩ Figure 8: Greedy algorithm for selecting a list of intermediate results to build for ÔøΩaÔøΩbÔøΩ ÔøΩ ÔøΩ1ÔøΩ0ÔøΩ, when the size of the candidate networks (and the reusability) increases. We perform a worst case time analysis of the greedy algorithm. The while loop is executed at most ÔøΩSÔøΩ¬°T times if every join has a frequency of 1, where ÔøΩSÔøΩ is the number of candidate networks. The calculation of Z takes time ÔøΩSÔøΩ¬°T. We assume that we traverse a candidate network of size T1 in time O T1 . In each step, we keep a hash table H with each intermediate result in Z and its frequency. Hence we check if an intermediate result is already in H and increase its frequency in O 1 . Finding the intermediate result in H that maximizes takes time ÔøΩSÔøΩ¬°T. The rewriting f requencya logb size step also takes time ÔøΩSÔøΩ¬°T. Hence the total execution time takes in the worst case time O ÔøΩSÔøΩ¬°T 2 . The greedy algorithm may output a non optimal list of intermediate results. However, in special cases the greedy is guaranteed to produce the optimal plan. One such case is described by the theorem below: Theorem 6 The greedy algorithm for aÔøΩb ÔøΩ 1ÔøΩ0 is optimal for m ÔøΩ 2 keywords, when each of them is contained in exactly one relation. "},{"aspect":"expcomparison","tweet":""}]}