{"user_name":" Efficient Keyword Search for Smallest LCAs in XML Databases Â\u2020 ","user_timeline":[{"aspect":"abstract","tweet":" ABSTRACT Keyword search is a proven, user-friendly way to query HTML documents in the World Wide Web. We propose keyword search in XML documents, modeled as labeled trees, and describe corresponding efficient algorithms. The proposed keyword search returns the set of smallest trees containing all keywords, where a tree is designated as \u201a€œsmallest\u201a€ if it contains no tree that also contains all keywords. Our core contribution, the Indexed Lookup Eager algorithm, exploits key properties of smallest trees in order to outperform prior algorithms by orders of magnitude when the query contains keywords with significantly different frequencies. The Scan Eager variant is tuned for the case where the keywords have similar frequencies. We analytically and experimentally evaluate two variants of the Eager algorithm, along with the Stack algorithm [13]. We also present the XKSearch system, which utilizes the Indexed Lookup Eager, Scan Eager and Stack algorithms and a demo of which on DBLP data is available at http://www.db.ucsd.edu/projects/xksearch. Finally, we extend the Indexed Lookup Eager algorithm to answer Lowest Common Ancestor (LCA) queries. "},{"aspect":"expanalysis","tweet":" 8. CONCLUSIONS The XKSearch system inputs a list of keywords and returns the set of Smallest Lowest Common Ancestor nodes, i.e., the list of nodes that are roots of trees that contain the keywords and contain no node that is also the root of a tree that contains the keywords. For each keyword the system maintains a list of nodes that contain the keyword, in the form of a tree sorted by the id\u201a€™s of the nodes. The key property of SLCA search is that, given two keywords ï¿½ï¿½ and ï¿½ï¿½ and a node Â¤ that contains keyword ï¿½ï¿½, one need not inspect the whole node list of keyword ï¿½ï¿½ in order to discover potential solutions. Instead, one only needs to find the left and right match of Â¤ in the list of ï¿½ï¿½, where the left (right) match is the node with the greatest (least) id that is smaller (greater) than or equal to the id of Â¤. The property generalizes to more than two keywords and leads to the Indexed Lookup Eager algorithm, whose main memory complexity is ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ï¿½Â\u2022Â¦Â§ Â¨ï¿½Â¨Â§ where ï¿½ is the maximum depth of the tree, ï¿½ is the number of keywords in the query, and Â¨ï¿½ï¿½Â¨ (Â¨ï¿½Â¨) is the minimum (maximum) size of keyword lists ï¿½ï¿½ through ï¿½ï¿½. Assuming a B-tree disk-based structure, where the non-leaf nodes of the B-tree are cached in main memory the number of disk accesses needed is ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§. The analytical results, as well as the experimental evaluation, show that the Indexed Lookup Eager algorithm outperforms, often by orders of magnitude, other algorithms when the keywords have different frequencies. We provide the Scan Eager algorithm as the best variant for the case where the keywords have similar frequencies. The experimental evaluation compares the Indexed Lookup Eager, Scan Eager and Stack (described in [13]) algorithms. The XKSearch system is implemented, using the BerkeleyDB [4] B-tree indices and a demo of it on DBLP data is available at http://www.db.ucsd.edu/projects/xksearch. "},{"aspect":"expdata","tweet":" We have run XKSearch on the DBLP data 7 . We filter out citation and other information only related to the DBLP website and group first by journal/conference names, then by years.  "},{"aspect":"background","tweet":" 1. INTRODUCTION Keyword search is a proven user-friendly way of querying HTML documents in the World Wide Web. Keyword search is well-suited to XML trees as well. It allows users to find the information they are interested in without having to learn a complex query language or needing prior knowledge of the structure of the underlying data [1, 5, 12, 15, 16, 18]. For example, assume an XML document named \u201a€œSchool.xml\u201a€, modeled using the conventional labeled tree model in Figure 1, that contains information including classes, projects, etc. A user interested in finding the relationships between \u201a€œJohn\u201a€ and \u201a€œBen\u201a€ issues a keyword search \u201a€œJohn, Ben\u201a€ and the search system returns the most specific relevant answers - the subtrees rooted at nodes Â¡Â¢Â£Â¢Â£ , Â¡Â¢Â£Â¢Â¤ and Â¡Â¢Â¤Â¢Â¡Â¢Â¡ . The meaning of the answers is obvious to the user: \u201a€œBen\u201a€ is a TA for \u201a€œJohn\u201a€ for the CS2A class, \u201a€œBen\u201a€ is a student in the CS3A class taught by \u201a€œJohn\u201a€, both \u201a€œJohn\u201a€ Â\u2020 Work supported by NSF ITR 313384 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGMOD June 14-16, 2005, Baltimore, Maryland, USA Copyright 2005 ACM 1-59593-060-4/05/06 ...$5.00. Yannis Papakonstantinou Department of Computer Science & Engineering University of California, San Diego yannis@cs.ucsd.edu and \u201a€œBen\u201a€ are participants in a project. According to the Smallest Lowest Common Ancestor (SLCA) semantics, the result of a keyword query is the set of nodes that (i) contain the keywords either in their labels or in the labels of their descendant nodes and (ii) they have no descendant node that also contains all keywords. The answer to the keyword search \u201a€œJohn, Ben\u201a€ is the node list [ Â¡Â¢Â£Â¢Â£ , Â¡Â¢Â£Â¢Â¤ , Â¡Â¢Â¤Â¢Â¡Â¢Â¡ ]. The subtree rooted at the Class node with id Â¡Â¢Â£Â¢Â£ is a better answer than the subtrees rooted at \u201a€œClasses\u201a€ or \u201a€œSchool\u201a€ because it connects \u201a€œJohn\u201a€ and \u201a€œBen\u201a€ more closely than the \u201a€œClasses\u201a€ or \u201a€œSchool\u201a€ elements. We can use an XML query language such as XQuery to search on \u201a€œJohn, Ben\u201a€ to find the most specific elements. One possible query is shown in Figure 2. It is complex and difficult to be executed efficiently. We could write a query that is schema specific and more efficient. However it would require existence and knowledge of the schema of School.xml, knowledge of the \u201a€œroles\u201a€ John and Ben may play in the document and knowledge of the relationships they may have. We make the following technical contributions in the paper: We propose two efficient algorithms, Indexed Lookup Eager Â\u2022 and Scan Eager, for keyword search in XML documents according to the SLCA semantics. Both algorithms produce part of the answers quickly so that users do not have to wait long to see the first few answers. The Indexed Lookup Eager algorithm outperforms known al- Â\u2022 gorithms and Scan Eager by orders of magnitude when the keyword search includes at least one low frequency keyword along with high frequency keywords. In particular, the performance of the algorithm primarily depends on the number of occurrences of the least frequent keyword and the number of keywords in the query; it does not depend significantly on the frequencies of the more frequent keywords of the query (the precise worst-case complexity for a main memory version and a disk-based version is provided). The Indexed Lookup Eager algorithm is important in practice since the frequencies of keywords typically vary significantly. In contrast Scan Eager is tuned for the case where the occurrences of the query\u201a€™s keywords do not vary significantly. Â\u2022 We experimentally evaluate the Indexed Lookup Eager algorithm, the Scan Eager algorithm and the prior work Stack algorithm [13]. The algorithms are incorporated into the XK- Search system (XML Keyword Search), which utilizes Btree indices provided by BerkeleyDB [4]. A demo of the XKSearch system, running on DBLP data, is available at http://www.db.ucsd.edu/projects/xksearch. The experiments show that the Indexed Lookup Eager algorithm outperforms the Scan Eager and the Stack algorithms John 0.0.0 Instructor 0.1.0.0 John 0.1.0.0.0 Dean 0.0 Class 0.1.0 Title 0.1.1.0 CS2A 0.1.1.0.0 Class 0.1.1 Instructor 0.1.1.1 John 0.1.1.1.0 TA 0.1.1.2 Ben 0.1.1.2.0 Classes 0.1 Instructor 0.1.2.0 John 0.1.2.0.0 Class 0.1.2 Students 0.1.2.1 Ben 0.1.2.1.0 answerÂ¡ Â¢ Â\u2020 for $a in document(\u201a€˜\u201a€˜School.xml\u201a€™\u201a€™)//* where empty(for $b in $a/* where some $c in $b//* satisfies $c=\u201a€˜\u201a€˜John\u201a€™\u201a€™ and some $c in $b//* satisfies $c=\u201a€˜\u201a€˜Ben\u201a€™\u201a€™ return $b) and some $d in $a//* satisfies $d=\u201a€˜\u201a€˜John\u201a€™\u201a€™ and some $d in $a//* satisfies $d=\u201a€˜\u201a€˜Ben\u201a€™\u201a€™ return Â£ Â\u2020 $a /answerÂ¡ School 0 Title 0.1.2.2 CS3A 0.1.2.2.0 Class 0.1.3 Title 0.1.3.0 CS4A 0.1.3.0.0 Class 0.1.4 Title 0.1.4.0 CS5A 0.1.4.0.0 Projects 0.2 Autonet 0.2.0 Participants 0.2.0.0 John 0.2.0.0.0 Figure 1: School.xml (each node is associated with its Dewey number) Figure 2: XQuery: find answers for \u201a€œJohn, Ben\u201a€ often by orders of magnitude when the keywords in the query have different frequencies, and loses only by a small margin when the keywords have similar frequencies. Indeed in the DBLP demo, only the Indexed Lookup Eager algorithm is used. In Section 2 we introduce the notation and definitions used in the paper. Section 3 presents the SLCA problem and its solutions. We discuss the Indexed Lookup Eager and the Scan Eager algorithms, and the sort-merge based Stack algorithm [13]. Section 3 also provides the complexity of the main memory implementations of the algorithms. In Section 4, we discuss the XKSearch implementation of the Indexed Lookup Eager, Scan Eager and Stack algorithms and provide their complexity in terms of number of disk accesses. In Section 5, we discuss the All Lowest Common Ancestor (LCA) problem and extend the SLCA\u201a€™s Indexed Lookup algorithm to efficiently find LCAs in \u201a€œshallow\u201a€ trees. Our experimental results are discussed in Section 6. We discuss related work in Section 7 and conclude in Section 8.  "},{"aspect":"expintro","tweet":" The experiments have been done on a 1.2GHz laptop with 512MB of RAM. An online demo, which enables keyword search in the same grouped 83MB DBLP data used in the experiments is provided at http://www.db.ucsd.edu/projects/xksearch. The demo runs as a Java Servlet using Apache Jakarta Tomcat server. The Xalan engine is used to translate XML results to HTML. "},{"aspect":"problemdef","tweet":"  2. NOTATION We use the conventional labeled ordered tree model to represent XML trees. Each node Â¤ of the tree corresponds to an XML element and is labeled with a tag Â\u2022Â¦Â¤Â§. We assign to each node a numerical idÂ¨Â©ï¿½Â¦Â¤Â§ that is compatible with preorder numbering, in Ben 0.2.0.0.1 P2P 0.3.0 Participants 0.3.0.0 Ben 0.3.0.0.0 SportsClub 0.3 OSP 0.3.1 Participants 0.3.1.0 Ben 0.3.1.0.0 the sense that if a Â¤ï¿½ node precedes a Â¤ï¿½ node in the preorder leftto-right depth-first traversal of the tree Â¨Â©ï¿½Â¦Â¤ï¿½Â§ ï¿½ then Â¨Â©ï¿½Â¦Â¤ï¿½Â§. The XKSearch implementation uses Dewey numbers as the id\u201a€™s. Prior work has shown that Dewey numbers are a good id choice [23]. In addition, Dewey numbers provide a straightforward solution to locating the LCA of two nodes. The ï¿½ usual relationship is assumed between any two Dewey numbers. For Â¡Â¢Â£Â¢Â¡Â¢Â¡Â¢Â¡ example, Â¡Â¢Â£Â¢Â£Â¢Â£ . Obviously the ï¿½ relationship on Dewey num- ï¿½ bers is compatible with the requirement for preorder numbering. Given a list ï¿½ of ï¿½ï¿½ï¿½ keywords Â¢ Â¢ Â¢ and an input XML treeï¿½, ï¿½ï¿½ï¿½ an answer subtree of ï¿½ï¿½ï¿½ keywords Â¢ Â¢ Â¢ is a subtree of ï¿½ such ï¿½ï¿½ï¿½ that it contains at least one instance of each ï¿½ï¿½ï¿½ keyword Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½. A smallest answer subtree of ï¿½ï¿½ï¿½ keywords Â¢ Â¢ Â¢ is an answer ï¿½ï¿½ï¿½ subtree (of ï¿½ï¿½ï¿½ keywords Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½) such that none of its subtrees is an answer subtree (of ï¿½ï¿½ï¿½ keywords Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½). The ï¿½ï¿½ï¿½ï¿½ result Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½ï¿½ï¿½ Â§ of a keyword search ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½ on an input Â¦ï¿½ï¿½ï¿½ XML ï¿½ tree , is the set of the roots of all smallest answer subtrees ï¿½ï¿½ï¿½ of Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½. For presentation brevity, we do not explicitly refer to the input XML ï¿½ tree and simply write ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ when ï¿½ï¿½ï¿½Â§ is obvious. ï¿½ Given a list ï¿½ of ï¿½ï¿½ï¿½ keywords Â¢ Â¢ Â¢ and an input XML treeï¿½, ï¿½ï¿½ï¿½ we ï¿½ï¿½ assume denotes the keyword list of ï¿½ï¿½, i.e., the list of nodes whose label directly ï¿½ï¿½ contains sorted by Â¤ ï¿½ Â¤ï¿½ id. denotes that Â¤ node is an ancestor of node Â¤ ï¿½ Â¤ï¿½ Â¤ï¿½; denotes Â¤ ï¿½ Â¤ï¿½ that or ï¿½ Â¤ï¿½. Given a node Â¤ ï¿½ ï¿½, Â¤ is called an ancestor node in ï¿½ Â¤ if there exists a Â¤ï¿½ node ï¿½ in such Â¤ ï¿½ that Â¤ï¿½. When the ï¿½ set is implied by the context, we simply Â¤ say is an ancestor node. Notice that Â¤ ï¿½ Â¤ï¿½ thenÂ¨Â©ï¿½Â¦Â¤Â§ ï¿½ if Â¨Â©ï¿½Â¦Â¤ï¿½Â§, and the other direction is not always true. The function ï¿½ï¿½ï¿½ Â¦Â¤ï¿½ï¿½ Â¢ Â¢ Â¢ computes the lowest common an- ï¿½Â¤ï¿½Â§ cestor or LCA of Â¤ï¿½ï¿½ nodes Â¢ Â¢ Â¢ and returns null if any of the ï¿½Â¤ï¿½ arguments is null. Given two nodes Â¤ï¿½ Â¤ï¿½, and their Dewey numbers Â¨ï¿½,Â¨ï¿½, ï¿½ï¿½ï¿½ is the node with the Dewey number that is Â¦Â¤ï¿½ï¿½Â¤ï¿½Â§ the longest common prefix Â¨ï¿½ of Â¨ï¿½ and and the cost of computing ï¿½ï¿½ï¿½ is ï¿½Â¦ï¿½Â§ where ï¿½ is the maximum depth of the tree. Â¦Â¤ï¿½ï¿½Â¤ï¿½Â§ For example, the LCA of nodes Â¡Â¢Â£Â¢Â£Â¢Â£Â¢Â¡ and Â¡Â¢Â£Â¢Â£Â¢Â¤Â¢Â¡ is the Â¡Â¢Â£Â¢Â£ node in Figure 1. Given sets of ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ nodes ï¿½ï¿½ï¿½, a Â¤ node belongs to ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ if there exist Â¤ï¿½ ï¿½ ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½Â§ Â¢ Â¢ Â¢ ï¿½ ï¿½ï¿½ such that ï¿½Â¤ï¿½ ï¿½ Â¤ ï¿½ï¿½ï¿½ Â¦Â¤ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½Â¤ï¿½Â§. Â¤ Then is called an LCA of ï¿½ï¿½ï¿½ sets Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½. A Â¤ node belongs to the smallest lowest common ancestor (SLCA) Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ of ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½ if Â¤ ï¿½ ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ and ï¿½ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ Â¤ ï¿½ ï¿½. Â¤ is called a SLCA of sets ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½ if ï¿½ï¿½ï¿½ Notice that the query result ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ is ï¿½ï¿½ï¿½Â§ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ and that ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ Â©ï¿½Â\u2020Â¡Â¤ï¿½ ï¿½ï¿½ï¿½Â§= Â¢Â£ï¿½ ï¿½Â¤Â¡Â©Â¦ ï¿½ ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§Â§ Â©ï¿½Â\u2020Â¡Â¤ï¿½ where Â¢Â£ï¿½ ï¿½Â¤Â¡Â© removes ancestor nodes from its input. ï¿½ The Â©Â\u2020 Â¦Â¤ï¿½ï¿½Â§ function computes the right match Â¤ of in a set ï¿½, that is the node ï¿½ of that has the smallest id that is greater than or equal to Â¨Â©ï¿½Â¦Â¤Â§; ï¿½Â\u2020 computes the left match of Â¤ in a set ï¿½, Â¦Â¤ï¿½ï¿½Â§ that is the node ï¿½ of that has the biggest id that is less than or equal toÂ¨Â©ï¿½Â¦Â¤Â§ 1 Â©Â\u2020Â¦Â¤ï¿½ï¿½Â§ . ( ï¿½Â\u2020 Â¦Â¤ï¿½ï¿½Â§) returns null when there is no right Â¤ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§. (left) match node. The cost of ï¿½Â\u2020 (Â©Â\u2020 Â¦Â¤ï¿½ï¿½Â§) is ï¿½Â¦ï¿½Â\u2022Â¦Â§ Â¨ï¿½Â¨Â§ Â¦Â¤ï¿½ï¿½Â§ since it ï¿½Â¦Â\u2022Â¦Â§ Â¨ï¿½Â¨Â§ takes steps (Dewey number comparisons) to find the right (left) match node and the cost of comparing two Dewey numbers is ï¿½Â¦ï¿½Â§. The ï¿½ï¿½ function ï¿½ï¿½ï¿½ Â£ ï¿½ï¿½Â£Â¤ returns the Â¦Â¤ï¿½ï¿½Â¤ï¿½Â§ other argument when one argument is null and returns the descendant node Â¤ï¿½ when Â¤ï¿½ and have ancestor-descendant relationship. The cost of the ï¿½ï¿½ function ï¿½ï¿½ï¿½ Â£ ï¿½ï¿½Â£Â¤ is ï¿½Â¦ï¿½Â§. "},{"aspect":"solution","tweet":" 3. ALGORITHMS FOR FINDING THE SLCA OF KEYWORD LISTS This section presents the core Indexed Lookup Eager algorithm, its Scan Eager variation and the prior work Stack algorithm [13]. A brute-force solution to the SLCA problem computes the LCAs of all node combinations and then removes ancestor nodes. Its complexity is ï¿½Â¦ï¿½ï¿½Â¨ï¿½ï¿½Â¨ Â¢ Â¢ Â¢ Â¨ï¿½ï¿½Â¨Â§. Besides being inefficient the brute-force approach is blocking. After it computes an LCA Â¤ ï¿½ Â¦Â¤ï¿½ï¿½ Â¢ ï¿½Â¤ï¿½Â§ Â¢ Â¤ï¿½ ï¿½ Â¢ Â¢ Â¢ Â¢ for Â¤ï¿½ ï¿½ some ï¿½ï¿½, , ï¿½ï¿½, Â¤ ï¿½ï¿½ï¿½ it cannot report as an answer since there might ï¿½ be ï¿½ï¿½ï¿½ another set of nodes Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½ such that Â¤ ï¿½ ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§. The complexity analysis given in this section is for main memory cases. We will give disk access complexity in Section 4 after we discuss the implementation details of how we compress and store keyword lists on disk. In ï¿½ï¿½ the sequel we choose to be the smallest keyword list since ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½Â©ï¿½ Â¢ Â¢ Â¢ Â¢Â¢ ï¿½ï¿½ï¿½ï¿½Â§, ï¿½ where Â£ is any permutation of ï¿½ Â¤ ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½, and there is a benefit ï¿½ï¿½ ï¿½ ï¿½ ï¿½ in using ï¿½ï¿½ the smallest list as as we will see in the complexity analysis of the algorithms. 3.1 The Indexed Lookup Eager Algorithm (IL) The Indexed Lookup Eager algorithm is based on four properties of SLCAs, which we explain starting from the simplest case where ï¿½ ï¿½ Â¤ and ï¿½ï¿½ is a singleton Â¢Â¤Â£. Â©Â¡Â¨ï¿½Â©Â¤ï¿½ Â¦ Â£ Â§ ï¿½ Â¦Â¢Â¤Â£ï¿½ï¿½Â§ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¢ï¿½ï¿½ï¿½ï¿½ ï¿½ Â£ ï¿½ï¿½Â£Â¤ ï¿½ï¿½ï¿½ Â¦Â¤ï¿½ ï¿½Â\u2020Â¦Â¤ï¿½ï¿½Â§Â§ï¿½ Â¦ ï¿½ï¿½ï¿½ Â¦Â¤ï¿½ï¿½Â§Â§Â§Â£ Â¦Â¤ï¿½Â©Â\u2020 According to the above Property (1), we compute the LCA Â¤ of and its left match in ï¿½, the LCA Â¤ of and its right match in ï¿½, and the singleton formed from the deeper node from the two LCAs ï¿½ï¿½ï¿½ï¿½ is . Property (1) is based on the following two observa- Â¦Â¢Â¤Â£ï¿½ï¿½Â§ tions. For any two Â¤ï¿½ï¿½Â¤ï¿½ nodes to the right (according to preorder) of a node Â¤, Â¨Â©ï¿½Â¦Â¤Â§ ï¿½ Â¨Â©ï¿½Â¦Â¤ï¿½Â§ ï¿½ if Â¨Â©ï¿½Â¦Â¤ï¿½Â§, then ï¿½ï¿½ï¿½ ï¿½ Â¦Â¤ï¿½Â¤ï¿½Â§ Â¦Â¤ï¿½Â¤ï¿½Â§; similarly, for any two nodes Â¤ï¿½ï¿½Â¤ï¿½ to the left of a node ï¿½ï¿½ï¿½ ifÂ¨Â©ï¿½Â¦Â¤ï¿½Â§ ï¿½ Â¨Â©ï¿½Â¦Â¤ï¿½Â§ ï¿½ Â¤, Â¨Â©ï¿½Â¦Â¤Â§, then ï¿½ï¿½ï¿½ ï¿½ Â¦Â¤ï¿½Â¤ï¿½Â§ ï¿½ï¿½ï¿½ Â¦Â¤ï¿½Â¤ï¿½Â§ 2 . We generalize to ï¿½ arbitrary when the first set is a singleton. Notice the recursiveness in Property (2). Â©Â¡Â¨ï¿½Â©Â¤ï¿½ Â¦ Â¤ Â§ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤Â£ï¿½ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ ï¿½ ï¿½ Â¦ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤Â£ï¿½ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½ï¿½ï¿½Â§ï¿½ï¿½ï¿½Â§ ï¿½Â¡Â© ï¿½ ï¿½ Â¤ ï¿½ï¿½ï¿½ï¿½ 1 The right or left match of a Â¤ node ï¿½ in is itself Â¤ ï¿½ if ï¿½. This may happen when a node\u201a€™s label contains multiple keywords. 2 The two observations apply to inorder and postorder as well. Next we generalize to arbitrary ï¿½ï¿½. Â©Â¡Â¨ï¿½Â©Â¤ï¿½ Â¦ï¿½Â§ ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½Â©ï¿½ï¿½Â© ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½ï¿½ï¿½ Â¢Â¢ ï¿½ï¿½ï¿½Â§Â§ Property (3) straightforwardly leads to an algorithm to compute Â©ï¿½Â\u2020Â¡Â¤ï¿½ Â¢Â£ï¿½ ï¿½ ï¿½Â¤Â¡Â©Â¦ ï¿½ Â¦ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§: first computes Â¢ï¿½ï¿½Â£ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½ï¿½ï¿½ Â¢Â¢ ï¿½ï¿½ï¿½Â§ ï¿½ï¿½ï¿½ï¿½ for Â¤ï¿½ ï¿½ ï¿½ï¿½ each ( Â£ ï¿½ ï¿½ ï¿½ Â£ Â©ï¿½Â\u2020Â¡Â¤ï¿½ ), Â¢Â£ï¿½ ï¿½Â¤Â¡Â©Â¦Â¢ï¿½ï¿½ï¿½ ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â£Â§ is the Eachï¿½ï¿½ answer. is computed by using Properties (2) and (1). The benefit of the above algorithm over the brute force approach is that for each ï¿½ï¿½ node in ï¿½ï¿½, the algorithm does not ï¿½ï¿½ï¿½ compute Â¢ Â¢ Â¢ ï¿½Â¤ï¿½Â§ for all Â¤ï¿½ ï¿½ ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½Â¤ï¿½ ï¿½ ï¿½ï¿½, but computes a Â¦ï¿½ï¿½ï¿½Â¤ï¿½ï¿½ single ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½Â¤ï¿½ï¿½ Â¢ Â¢ Â¢ where each Â¤ï¿½ ( ï¿½Â¤ï¿½Â§ Â¤ ï¿½ ï¿½ ï¿½ ï¿½) is computed by the match functions ( ï¿½Â\u2020 Â©Â\u2020 and ). The complexity of the algorithm ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ is ï¿½ ï¿½Â\u2022Â¦Â§ Â¨ï¿½ï¿½Â¨ï¿½ Â¨ï¿½ï¿½Â¨ ï¿½ï¿½ï¿½ ï¿½ or ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ï¿½ Â§ ï¿½Â¡ï¿½Â¨ï¿½Â¨ï¿½ Â¨ï¿½ï¿½Â¨ï¿½ where Â¨ï¿½ï¿½Â¨ (Â¨ï¿½Â¨) is the minimum (maximum) size of key- Â§ word ï¿½ï¿½ lists ï¿½ï¿½ through because for nodeï¿½ï¿½ each ï¿½ï¿½ in the algorithm needs to find a left and a right match in each one of the other ï¿½ ï¿½ Â£ keyword lists. Finding a match in ï¿½ï¿½ list ï¿½Â¦ï¿½Â\u2022Â¦Â§ costs Â¨ï¿½ï¿½Â¨Â§. Hence the total cost of match operations ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ï¿½ is ï¿½ Â¨ï¿½ï¿½Â¨Â§. The total cost of the ï¿½ï¿½ï¿½Â\u2022Â¦Â§ ï¿½ï¿½ï¿½ ï¿½ï¿½ and ï¿½ï¿½ï¿½ Â£ ï¿½ï¿½Â£Â¤ operations ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ï¿½Â§ is and hence is dominated by the cost of the match operations. Â¨ï¿½ï¿½Â¨ The ï¿½ factor is attributed to the cost of removing ancestors opera- tion. The subroutine ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ , based on the following two lemmas, computes ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ï¿½ï¿½Â§ efficiently by removing ancestor nodes on the fly. LEMMA 1. Given any two nodes Â¤ï¿½ï¿½Â¤ï¿½ and a set ï¿½, ifÂ¨Â©ï¿½Â¦Â¤ï¿½Â§ ï¿½ andÂ¨Â©ï¿½Â¦ Â¨Â©ï¿½Â¦Â¤ï¿½Â§ ï¿½ï¿½ï¿½ï¿½ ï¿½ Â¨Â©ï¿½Â¦ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½Â§Â§ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½Â§Â§, then ï¿½ï¿½ï¿½ï¿½ Â£ï¿½ï¿½Â§ ï¿½ Â¦Â¢Â¤ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½Â§. LEMMA 2. For any two nodes Â¤ï¿½ï¿½Â¤ï¿½ and a set ï¿½ such that Â¨Â©ï¿½Â¦Â¤ï¿½Â§ ï¿½ Â¨Â©ï¿½Â¦Â¤ï¿½ Â§ andÂ¨Â©ï¿½Â¦ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½Â§Â§ ï¿½ Â¨Â©ï¿½Â¦ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½ Â£ï¿½ï¿½Â§Â§, if ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½Â§ is not an ancestor of ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½ Â£ï¿½ï¿½Â§, then for any Â¤ such thatÂ¨Â©ï¿½Â¦Â¤Â§ ï¿½ Â¨Â©ï¿½Â¦Â¤ï¿½Â§, ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½Â§ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤Â£ï¿½ï¿½Â§. Consider ï¿½ï¿½ï¿½ï¿½ï¿½ sorted by id, where ï¿½ï¿½ ï¿½ ï¿½Â¤ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½Â¤ï¿½ï¿½. Letï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½ï¿½ whereï¿½ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½ï¿½Â§, Â¢ Â¢ Â¢ ,ï¿½ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦Â¢Â¤ï¿½Â£ï¿½ï¿½ï¿½Â§. According to Lemma 1, if Â¨Â©ï¿½Â¦ï¿½ï¿½Â§ ï¿½ Â¨Â©ï¿½Â¦ï¿½ï¿½Â§ where nodeï¿½ï¿½ appears afterï¿½ï¿½ inï¿½ (that is,ï¿½ ï¿½ ï¿½ ), thenï¿½ï¿½ is an ancestor node. Thus when computing the listï¿½, we can discard the out-of-order nodes such asï¿½ï¿½ . The resulting listï¿½ï¿½ is in order and contains the nodes of ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ï¿½ï¿½Â§. Howeverï¿½ï¿½ is not necessarily ancestor node free. Consider any two adjacent nodes ï¿½, ï¿½ï¿½ in ï¿½ï¿½ where ï¿½ï¿½ is after ï¿½. If ï¿½ is not an ancestor of ï¿½ï¿½, then ï¿½ cannot be an ancestor of any node ï¿½ï¿½ï¿½ that is afterï¿½ï¿½ in ï¿½ï¿½ (according to Lemma 2), which meansï¿½ is a ï¿½ï¿½ï¿½ Â¢ of ï¿½ï¿½, ï¿½ï¿½. Lemma 1 and 2 together lead to the subroutine ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ that computes ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ï¿½ï¿½Â§ efficiently. Line #5 inï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ applies Lemma 1 to remove out-of-order nodes, and lines #6-8 apply Lemma 2 to identify a SLCA as early as possible. As can be seen fromï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ , at any time only three nodes (ï¿½, Â¤, ï¿½) are needed in memory. Consider ï¿½ï¿½=[ Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢Â£Â¢Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢Â£Â¢Â£Â¢Â£Â¢Â¡ , Â¡Â¢Â£Â¢Â¤Â¢Â¡Â¢Â¡ , Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ ], ï¿½ï¿½=[ Â¡Â¢Â£Â¢Â£Â¢Â¤Â¢Â¡ , Â¡Â¢Â£Â¢Â¤Â¢Â£Â¢Â¡ , Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â£ , Â¡Â¢ ï¿½ Â¢Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢ ï¿½ Â¢Â£Â¢Â¡Â¢Â¡ ] (the keyword lists for \u201a€œJohn\u201a€ and \u201a€œBen\u201a€ respectively). In the first iteration of the loop at line #3, ï¿½ ï¿½ Â¡ , Â¤ ï¿½ Â¡Â¢Â¡Â¢Â¡ , ï¿½=0 (line #4). At the end of the first iteration ï¿½ ï¿½ Â¡ (line #8). In the second iteration, Â¤ ï¿½ Â¡Â¢Â£Â¢Â¡Â¢Â¡Â¢Â¡ , ï¿½ ï¿½ Â¡Â¢Â£ , ï¿½ ï¿½ Â¡Â¢Â£ . In the third iteration, Â¤ ï¿½ Â¡Â¢Â£Â¢Â£Â¢Â£Â¢Â¡ , ï¿½ ï¿½ Â¡Â¢Â£Â¢Â£ , ï¿½ ï¿½ Â¡Â¢Â£Â¢Â£ . In the fourth iteration, Â¤ ï¿½ Â¡Â¢Â£Â¢Â¤Â¢Â¡Â¢Â¡ , ï¿½ ï¿½ Â¡Â¢Â£Â¢Â¤ (line #4). Notice that the condition at line #6 is true in the fourth iteration, ï¿½ and (node Â¡Â¢Â£Â¢Â£ ) is determined to be a SLCA (line #7). ï¿½ ï¿½ Then Â¡Â¢Â£Â¢Â¤ (line #8). In the last Â¤ ï¿½ iteration, Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ ï¿½ ï¿½ , Â¡Â¢Â¤Â¢Â¡Â¢Â¡ , and node Â¡Â¢Â£Â¢Â¤ is determined to be a SLCA (line #7). Finally node Â¡Â¢Â¤Â¢Â¡Â¢Â¡ is returned as a SLCA (line #10). Thus the answer to \u201a€œJohn Ben\u201a€ is [ Â¡Â¢Â£Â¢Â£ , Â¡Â¢Â£Â¢Â¤ Â¡Â¢Â¤Â¢Â¡Â¢Â¡ , ]. ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ï¿½ï¿½Â§ 1 Â\u2020ï¿½ subroutineï¿½ï¿½Â¤ ï¿½ï¿½ï¿½Â¤ Â¢Â£ ï¿½ 2 ï¿½ ï¿½ Â¡ 3 for each Â¤ ï¿½ ï¿½ï¿½ Â¢ node ï¿½ ï¿½ ï¿½ï¿½ 4 ï¿½ï¿½ï¿½ Â£ ï¿½ï¿½Â£Â¤ ï¿½ï¿½ï¿½ Â¦Â¤ï¿½ ï¿½Â\u2020 Â¦Â¤ï¿½ï¿½ï¿½Â§, Â¦ ï¿½ï¿½ï¿½ Â¦Â¤ï¿½ï¿½ï¿½Â§Â§Â§ 5 if (Â¨Â©ï¿½Â¦ï¿½Â§ Â¦Â¤ï¿½Â©Â\u2020 ï¿½ Â¨Â©ï¿½Â¦ï¿½Â§) 6 (ï¿½ Â¡ if ï¿½) Â\u2020ï¿½ 7 ï¿½ï¿½ï¿½Â¤ Â\u2020ï¿½ ï¿½ ï¿½ï¿½ï¿½Â¤ Â¢ Â¢ï¿½Â£; ï¿½ ï¿½ 8 ï¿½; Â£ 9 10 Â\u2020ï¿½ return ï¿½ï¿½ï¿½Â¤ Â¢ Â¢ï¿½Â£ //ï¿½ ï¿½ Â©Â¡Â¡Â¤ initially We can derive an algorithm fromï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ to compute ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ efficiently: Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½ï¿½ï¿½Â§ï¿½ï¿½ï¿½Â§ ï¿½Â¡Â© ï¿½ ï¿½ Â¤ ï¿½ï¿½Â¤ based on the following Property (4), Â©Â¡Â¨ï¿½Â©Â¤ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¢ Â¢ ï¿½ ï¿½ Â¦Â£Â§ Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ ï¿½Â¡Â© ï¿½ ï¿½ Â¤ ï¿½ï¿½ï¿½ï¿½ Â¦ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½Â§ï¿½ï¿½ï¿½Â§ An ï¿½ï¿½ algorithm ï¿½ï¿½ based accesses and first, then ï¿½Â¤, ï¿½ï¿½ï¿½ï¿½ onï¿½ï¿½Â¤ ï¿½Â\u2022, Â¢ Â¢ Â¢ , in ï¿½ order. It accesses the keyword lists ï¿½ï¿½ in just one round. It is a blocking algorithm since it only processes the last keyword list after ï¿½ ï¿½ it completely processes the first Â£ keyword lists and then starts to produce answers. Obviously the algorithm based on Property (3) is also a blocking algorithm. The Indexed Lookup Eager Algorithm ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ improves the algorithm based on by adding \u201a€œeagerness\u201a€- it returns the first part of the answers without having to completely go through any of the keyword lists and it pipelines the delivery of SLCAs. Assume there is a memory buffer size ofï¿½ nodes. The Indexed Lookup Eager algorithm first computes Â¦ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ where ï¿½ Â¦Â¦ï¿½ï¿½ï¿½ï¿½Â§ is Â¦ï¿½ the first nodes Â¦Â¤ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦Â¦ï¿½ï¿½ï¿½Â¤Â§ of ï¿½ï¿½. Then it computes and so on, until it computes Â¦ï¿½ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦ Â¢ Â¢ Â¢ï¿½ï¿½ï¿½ï¿½ Â¢ Â¢ Â¦Â¦ï¿½ï¿½ï¿½ï¿½Â§ Â¢ ï¿½ï¿½Â§. All nodes in except the last node are guaranteed to be Â¦ï¿½ SLCAs because of Lemma 1 and 2 and are Â¦ï¿½ (Â¤ returned. The last node of in line #10) is carried on to the next operation (lines #6-9) to be ï¿½ï¿½ï¿½ determined whether it is a Â¢ or not. The above operation is repeated for the next ï¿½ nodes of ï¿½ï¿½ until all nodes in have ï¿½ï¿½ been processed. The smallerï¿½ is, the faster the algorithm produces the first SLCA. Ifï¿½ ï¿½ Â£ , again only three nodes are needed to be kept in memory in the whole process. However, a smallerï¿½ may delay the computation of all SLCAs when considering disk accesses. Ifï¿½ Â§ Â¨ï¿½ï¿½Â¨, the Indexed Lookup Eager algorithm is exactly the same onï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ as the algorithm based . The complexity analysis of the Indexed Lookup Eager algorithm is the same as that of the algorithm based on Property (3) except that there is no operation to remove ancestor nodes from a set. Thus the complexity of the Indexed Lookup Eager algorithm ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ï¿½ is ï¿½Â¡ï¿½Â¨ï¿½Â¨Â§ where (Â¨ï¿½Â¨) is the minimum (maximum) ï¿½ï¿½ size of keyword lists Â¨ï¿½ï¿½Â¨ through ï¿½ï¿½. Consider the query \u201a€œJohn Ben Class\u201a€ applied on the data of Figure 1. The keyword lists for \u201a€œJohn\u201a€, \u201a€œBen\u201a€, \u201a€œClass\u201a€ are ï¿½ï¿½=[ Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢Â£Â¢Â¡Â¢Â¡Â¢Â¡ Â¡Â¢Â£Â¢Â£Â¢Â£Â¢Â¡ Â¡Â¢Â£Â¢Â£Â¢Â¤Â¢Â¡ Â¡Â¢Â£Â¢Â¤Â¢Â£Â¢Â¡ , Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â£ Â¡Â¢Â£Â¢Â¤Â¢Â¡Â¢Â¡ Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ , , Â¡Â¢ ï¿½ Â¢Â¡Â¢Â¡Â¢Â¡ ], Â¡Â¢ ï¿½ Â¢Â£Â¢Â¡Â¢Â¡ Â¡Â¢Â£Â¢Â¡ ï¿½ï¿½=[ Â¡Â¢Â£Â¢Â£ , Â¡Â¢Â£Â¢Â¤ , Â¡Â¢Â£Â¢ Â¡Â¢Â£Â¢ , , ] and ï¿½Â¤=[ , , , ï¿½, Â£] respectively. Assumeï¿½ ï¿½. In the first iteration of ï¿½ the loop at line #2, =[ Â¨ Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢Â£Â¢Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢Â£Â¢Â£Â¢Â£Â¢Â¡ ] (line #3). After the computation at line #4-5,Â¨ =ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ (ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ ([ Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢Â£Â¢Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢Â£Â¢Â£Â¢Â£Â¢Â¡ ],ï¿½ï¿½) ,ï¿½Â¤), which isÂ¨ =ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ (ï¿½ Â¡Â¢Â£Â¢Â£ ï¿½,ï¿½Â¤ )=ï¿½ Â¡Â¢Â£Â¢Â£ ï¿½. Initially Â¤ ï¿½ Â£ ï¿½ ï¿½ï¿½ . Line #6-9 has no effect. As mentioned before, every node in Â¨ except the last one is a SLCA and returned (line #10, #11). In the first iteration, line #11 outputs nothing and Â¤ (node Â¡Â¢Â£Â¢Â£ ) is carried to the next iteration to be determined whether it is a SLCA or not. In the second iteration of loop at line #2, the rest nodes of ï¿½ï¿½ is read, Â¨ =[ Â¡Â¢Â£Â¢Â¤Â¢Â¡Â¢Â¡ , Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ ] (line #3). After executing line #4 and #5, Â¨ ï¿½ ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½0.1.2.0.0ï¿½0.2.0.0.0ï¿½ï¿½ï¿½ï¿½Â§ï¿½ï¿½Â¤Â§, which is Â¨ ï¿½ ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ Â¦ï¿½ Â¡Â¢Â£Â¢Â¤ ï¿½ Â¡Â¢Â¤Â¢Â¡Â¢Â¡ ï¿½ï¿½ ï¿½Â¤Â§ = ï¿½ Â¡Â¢Â£Â¢Â¤ ï¿½. The condition at line #8 is true, thus Â¤ (node Â¡Â¢Â£Â¢Â£ ) carried from the first iteration is determined to be a SLCA and returned (line #9). Then Â¤ ï¿½ Â¡Â¢Â£Â¢Â¤ at line #10. Line #11 outputs nothing in this iteration again. Since there are no more nodes in ï¿½ï¿½, line #13 is executed. Thus the Indexed Lookup Algorithm returns ï¿½ Â¡Â¢Â£Â¢Â£ ï¿½ Â¡Â¢Â£Â¢Â¤ ï¿½ for \u201a€œJohn Ben Class\u201a€. ALGORITHM 1 (INDEXED LOOKUP EAGER ALGORITHM). Assume we have a memory buffer Â¨ of size ï¿½ nodes 1 Â¤ ï¿½ Â£ ï¿½ ï¿½ï¿½ 2 while( there are more nodes in ï¿½ï¿½) Â¢ 3 Read P nodes of ï¿½ï¿½ into buffer Â¨ . 4 for ï¿½ ï¿½ Â¤ Â© ï¿½ 5 Â¨ ï¿½ ï¿½ï¿½Â¤ ï¿½ï¿½ï¿½ï¿½ Â¦Â¨ ï¿½ï¿½ï¿½Â§ 6 if (Â¤ ï¿½ï¿½ Â£ ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½Â¤ï¿½ï¿½ Â© ï¿½Â¤ï¿½Â¡ï¿½ï¿½Â¦Â¨Â§ ï¿½ Â¤) 7 removeFirstNode(B) 8 if ( Â¤ ï¿½ï¿½ Â£ ï¿½ ï¿½ï¿½ ï¿½ï¿½ Â¤ ï¿½ ï¿½ï¿½Â¤ï¿½ï¿½ Â© ï¿½Â¤ï¿½Â¡ï¿½ï¿½Â¦Â¨Â§) 9 output Â¤ 10 Â¤ ï¿½ Â©ï¿½Â\u2020Â¡Â¤ï¿½ï¿½ ï¿½ï¿½Â¤ï¿½Â¡ï¿½ï¿½Â¦Â¨Â§ 11 output Â¨ ; Â¨ =Â¢Â£ 12 Â£ 13 output Â¤ 3.2 Scan Eager Algorithm When the occurrences of keywords do not differ significantly, the total cost of finding matches by lookups may exceed the total cost of finding matches by scanning the keyword lists. We implement a variant of the Indexed Lookup Eager Algorithm, named Scan Eager Algorithm, to take advantage of the fact that the accesses to any keyword list are strictly in increasing order in the Indexed Lookup Eager algorithm. The Scan Eager algorithm is exactly the same as the Indexed Lookup Eager algorithm except that its ï¿½Â\u2020 and Â©Â\u2020 implementations scan keyword lists to find matches by maintaining a cursor for each keyword list. In order to find the left and right match of a given node with id Â¨ in a list ï¿½ï¿½ , the Scan Eager algorithm advances the cursor of ï¿½ï¿½ until it finds the node that is closest toÂ¨ from the left or the right side. Notice that nodes from different lists may not be accessed in order, though nodes from the same list are accessed in order. The complexity of the Scan Eager algorithm is ï¿½(ï¿½Â¨ï¿½ï¿½Â¨+ ï¿½ï¿½ ï¿½ ï¿½ Â¨ï¿½ï¿½Â¨), or ï¿½Â¦ï¿½ï¿½Â¨ï¿½Â¨Â§ because there are ï¿½Â¦ï¿½ ï¿½ ï¿½ Â¨ï¿½ï¿½Â¨Â§ Dewey number comparisons, ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§ ï¿½ï¿½ï¿½ and ï¿½ï¿½ ï¿½ï¿½ ï¿½ Â£ ï¿½ ï¿½Â£Â¤ operations. 3.3 The Stack Algorithm The stack based sort-merge algorithm (DIL) in XRANK [13], which also uses Dewey numbers, is modified to find SLCAs and is called the Stack Algorithm here. Each stack entry has a pair of components Â¦ ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½Â¡Â©ï¿½ ï¿½ Â§. Assume the ï¿½ ï¿½ components from the bottom entry to a stack entry ï¿½ Â£ are ï¿½ ï¿½ï¿½ï¿½ ï¿½ ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ ï¿½ ï¿½ï¿½ respectively. Then the stack entry ï¿½ Â£ denotes the node with the Dewey number ï¿½ ï¿½ï¿½ Â¢ï¿½ ï¿½ï¿½ Â¢ Â¢ Â¢ Â¢ Â¢ï¿½ ï¿½ï¿½ . ï¿½ï¿½ï¿½ ï¿½Â¡Â©ï¿½ ï¿½ is an array of length ï¿½ of boolean values where ï¿½ï¿½ï¿½ ï¿½Â¡Â©ï¿½ ï¿½ï¿½ ï¿½ ï¿½ ï¿½ ï¿½ means that the subtree rooted at the node denoted by the stack entry directly or indirectly J B C 0 T F F 0 F F F 0 F F F (a) node Â¡Â¢Â¡Â¢Â¡ 1 F F T 1 T F T 0 T F T (d) node Â¡Â¢Â£Â¢Â£ J B C 0 F F T 1 F F F 0 T F F (b) node Â¡Â¢Â£Â¢Â¡ 0 T F F 1 F F F 1 F F T 1 T F T 0 T F T (e) node Â¡Â¢Â£Â¢Â£Â¢Â£Â¢Â¡ 0 T F F 0 F F F 0 F F T 1 F F F 0 T F F (c) node Â¡Â¢Â£Â¢Â¡Â¢Â¡Â¢Â¡ 0 F T F 2 F F F 1 T F T 1 F F F 0 T F T (f) node Â¡Â¢Â£Â¢Â£Â¢Â¤Â¢Â¡ 2 F F T 1 F F F 0 F F F (g) node Â¡Â¢Â£Â¢Â¤ , report Â¡Â¢Â£Â¢Â£ as a SLCA Figure 3: States of stack, where J stands for \u201a€œJohn\u201a€, B stands for \u201a€œBen\u201a€ and C stands for \u201a€œClass\u201a€ contains the keyword ï¿½ï¿½. For example, the top entry of the stack in Figure 3(b) denotes the node Â¡Â¢Â£Â¢Â¡ , and the middle entry denotes the node Â¡Â¢Â£ . The Stack algorithm merges all keyword lists and computes the longest common prefix of the node with the smallest Dewey number from the input lists and the node denoted by the top entry of the stack. Then it pops out all top entries containing Dewey components that are not part of the common prefix. If a popped entry ï¿½ Â£ contains all keywords, then the node denoted by ï¿½ Â£ is a SLCA. Otherwise the information about which keywords ï¿½ Â£ contains is used to update entry\u201a€™sï¿½ï¿½ï¿½ ï¿½Â¡Â©ï¿½ ï¿½ its parent array. Also a stack entry is created for each Dewey component of the smallest node which is not part of the common prefix, effectively pushing the smallest node onto the stack. The above action is repeated for every node from the sort merged input lists. Consider again the query \u201a€œJohn, Ben, Class\u201a€ applied on the data of Figure 1. The keyword lists for \u201a€œJohn, Ben, Class\u201a€ are [0.0.0, 0.1.0.0.0, 0.1.1.1.0, 0.1.2.0.0, 0.2.0.0.0], [0.1.1.2.0, 0.1.2.1.0, 0.2.0.0.1, 0.3.0.0.0, 0.3.1.0.0] and [0.1.0, 0.1.1, 0.1.2, 0.1.3., 0.1.4] respectively. Initially, the smallest node is Â¡Â¢Â¡Â¢Â¡ and Figure 3(a) shows the initial state of the ï¿½ï¿½ï¿½ ï¿½Â¡Â©ï¿½ ï¿½ï¿½ stack where Â£ ï¿½ in ï¿½ the top entry denotes that the node ï¿½ ( Â¡Â¢Â¡Â¢Â¡ ) represented by the top entry contains the first keyword \u201a€œJohn\u201a€. The next smallest node is the \u201a€œClass\u201a€ node Â¡Â¢Â£Â¢Â¡ . Since the longest common Â¡Â¢Â¡Â¢Â¡ prefix Â¡Â¢Â£Â¢Â¡ Â¡ of and is (line #4), the top two entries are popped out (line #6). Â¡Â¢Â¡Â¢Â¡ contains \u201a€œJohn\u201a€ and this information is passed to the current top entry (lines #12-13). Then two new entries from the two components of node Â¡Â¢Â£Â¢Â¡ that are not among the longest common prefix are pushed into the stack (line #16). Notice that 3(b)ï¿½ï¿½ï¿½ in ï¿½ï¿½ Figure ï¿½Â¡Â©ï¿½ Â£ ï¿½ in the bottom entry denotes that the ï¿½ ï¿½ node Â¡ (School) contains the keyword \u201a€œJohn\u201a€. Each figure in Figure 3 shows the state of the stack after processing the node shown in the caption. For example, when the algorithm Â¡Â¢Â£Â¢Â¤ processes node , the initial stack is shown in Figure 3(f) and the stack after processing Â¡Â¢Â£Â¢Â¤ is shown in Figure 3(g). The longest common prefix of Â¡Â¢Â£Â¢Â¤ and the stack ( Â¡Â¢Â£Â¢Â£Â¢Â¤Â¢Â¡ ) is Â¡Â¢Â£ (line #4). Thus the top three entries are popped out (line #6). When popping out the third entry, the algorithm reports Â¡Â¢Â£Â¢Â£ as a SLCA ï¿½ï¿½ï¿½ ï¿½Â¡Â©ï¿½ ï¿½ since its array ï¿½ contains all (line #7). Notice ï¿½ that the for \u201a€œBen\u201a€ from the top entry in Figure 3(f) is used in the decision that the third entry is a SLCA. The complexity of Stack is ï¿½Â¦ï¿½ï¿½ ï¿½ ï¿½ï¿½ï¿½Â¨ï¿½ï¿½Â¨Â§ since both the number of ï¿½ï¿½ï¿½ operations and the number of Dewey number comparisons are ï¿½ ï¿½ ï¿½ï¿½ï¿½Â¨ï¿½ï¿½Â¨. The Scan Eager algorithm has several ad- vantages over the Stack algorithm. First, the Scan Eager algorithm starts from the smallest keyword list, does not have to scan to the end of every keyword list and may terminate much earlier than the Stack algorithm as we will see in an example soon. Second, the number of ï¿½ï¿½ï¿½ operations of the Scan Eager algorithm (ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§) is usually much less than that of the Stack algorithm (ï¿½Â¦ï¿½ ï¿½ ï¿½ï¿½ï¿½ Â¨ï¿½ï¿½Â¨Â§). Third, the Stack algorithm operates on a stack whose depth is bounded by the depth of the input tree while the Scan Eager algorithm with ï¿½ ï¿½ Â£ only needs to keep three nodes in the whole process and no push/pop operations are involved. ALGORITHM 2 (STACK ALGORITHM). Â¢ 1 stack=empty 2 while (has not reached the end of all keyword lists) Â¢ 3 Â¤ ï¿½ ï¿½ï¿½Â¤ ï¿½Â\u2020 ï¿½ï¿½ï¿½ ï¿½ ï¿½Â¤ï¿½Â¡ï¿½ï¿½Â¦Â§ //find the largest p such that ï¿½Â¤ï¿½ï¿½ ï¿½ï¿½ ï¿½ ï¿½ ï¿½ Â¤ï¿½ ï¿½ ï¿½ï¿½ Â£ ï¿½ ï¿½ ï¿½ Â¨ 4 Â¨ ï¿½ ï¿½ï¿½ï¿½ Â¦ ï¿½Â¤ï¿½ï¿½ ï¿½ï¿½Â¤Â§ 5 while ( ï¿½Â¤ï¿½ï¿½ ï¿½ Â¢ï¿½ï¿½Â\u2020 ï¿½ ï¿½ Â¨ ) Â¢ 6 stackEntry=stack.pop() 7 if (isSLCA(stackEntry)) Â¢ //Any other stack entry cannot represent a SLCA 8 output stackEntry as a SLCA 9 set all entries of the Keywords array of any stack entry all falses 10 Â£ 11 else Â¢ //pass keyword witness information to the top entry 12 ï¿½Â¡Â© Â¦ï¿½ ï¿½ Â£ Â© ï¿½Â§ 13 if (stackEntry.Keywords[j]=true) stack.top.Keywords[j]=true 14 Â£ 15 Â£ //add non-matching components of Â¤ to stack 16 ï¿½Â¡Â© Â¦Â¨ ï¿½ï¿½ ï¿½ Â¤ Â¢ï¿½ ï¿½ Â£ ï¿½Â¤Â¡ Â§ stack.push(v[j],[]) stack.top.Keywords[i]=true 17 18 Â£ 19 check entries of the stack and return any SLCA if exists Â£ Â¢ isSLCA(stackEntry) if (stackEntry.Keywords[i]=true for Â£ ï¿½ ï¿½ ï¿½ ï¿½) return true else return Â£ false Â¢ getSmallestNode /* returns the Â¤ node with the smallest Dewey number from all keyword lists and advances the cursor of the list Â¤ where is from. Â¤ Assume is an array consisting of its Dewey number components. For Â¤ example is 0 1 3 if its Dewey number is 0.1.3 Â£ */ We consider again the query \u201a€œJohn, Ben, Class\u201a€ applied on the data of Figure 1 and assume the tree does not have the \u201a€œBen\u201a€ node with id Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â£ to show the first advantage of the Scan Eager algorithm over the Stack algorithm. Hence ï¿½ï¿½=[ Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢Â£Â¢Â¡Â¢Â¡Â¢Â¡ Â¡Â¢Â£Â¢Â£Â¢Â£Â¢Â¡ Â¡Â¢Â£Â¢Â£Â¢Â¤Â¢Â¡ Â¡Â¢Â£Â¢Â¤Â¢Â£Â¢Â¡ , Â¡Â¢ Â¡Â¢Â£Â¢Â¤Â¢Â¡Â¢Â¡ Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ , ï¿½ Â¢Â¡Â¢Â¡Â¢Â¡ , Â¡Â¢ ï¿½ Â¢Â£Â¢Â¡Â¢Â¡ ], ï¿½ï¿½=[ Â¡Â¢Â£Â¢Â¡ , Â¡Â¢Â£Â¢Â£ , Â¡Â¢Â£Â¢Â¤ , Â¡Â¢Â£Â¢ Â¡Â¢Â£Â¢ 3 ] , and ï¿½Â¤=[ , , , ï¿½, Â£]. For node Â¡Â¢Â£Â¢Â¤Â¢Â¡Â¢Â¡ in the Scan Eager Â¡Â¢Â£Â¢Â¤Â¢Â£Â¢Â¡ algorithm Â¡Â¢Â£Â¢Â¤ ï¿½ï¿½ finds its match in ï¿½ï¿½, and computes their LCA ; then it finds the match Â¡Â¢Â£Â¢Â¤Â¢Â£Â¢Â¡ for Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ in ï¿½ï¿½, and computes their LCA Â¡ . Since node Â¡ is an ancestor of node Â¡Â¢Â£Â¢Â¤ , node Â¡ is discarded and no further access to is needed. ï¿½Â¤ The last node in accessed by ï¿½Â¤ the Scan Eager algorithm is node Â¡Â¢Â£Â¢Â¤ . The Stack algorithm has to visit all nodes because it cannot tell whether ï¿½Â¤ the last node 3 For the sake of this example, we neglect that Â¨ï¿½ï¿½Â¨ ï¿½ Â¨ï¿½ï¿½Â¨. 0.2.0 0.1.1.2.0 0.1.2.1.0 0.2.0.0.1 0.3.0.0.0 0.3.1.0.0 Autonet Ben Class Classes CS2A CS3A CS4A CS5A 0.1.0 0.1.1 0.1.2 0.1.3 0.1.4 0.1.1.0.0 0.1 0.1.2.2.0 0.1.3.0.0 0.1.4.0.0 0.0 0.1.0.0 0.1.1.1 0.1.2.0 CS2A Dean Participants SportsClub Instruc Partici Dean John OSP P2P tor pants 0.0.0 0.1.0.0.0 0.1.1.1.0 0.1.2.0.0 0.2.0.0.0 0.3.1 0.2.0.0 0.3.0.0 0.3.1.0 Proje cts Scho ol 0.3.0 0.2 0 0.3 Figure 4: B+ tree from the data of Figure 1 for Scan Eager and Stack algorithms Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ may lead to a SLCA or not until it comes to process Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ node and it has to repeatedly compute the longest common ancestor of ï¿½Â¤ each node with the node represented by the top entry of the stack. Notice that the \u201a€œClass\u201a€ list may have arbitrarily many nodes after node Â¡Â¢Â£Â¢Â¤ and before node Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ 4 that Stack has to access but Scan Eager does not need to. 4. XKSEARCH SYSTEM IMPLEMENTATION In this section we present the architecture of the XKSearch implementation, then discuss how the keyword lists are compressed and stored on disk-based B tree index structures, and finally provide disk access complexity analysis summarized in Table 1 for the three algorithms discussed in Section 3 - Indexed Lookup Eager, Scan Eager and Stack. We implemented the Indexed Lookup Eager, Scan Eager and Stack algorithms in Java using the Apache Xerces XML parser and Berkeley DB [4]. The architecture of the implementation (XK- Search) is shown in Figure 6. The LevelTableBuilder reads an input XML document ï¿½ and outputs a level tableï¿½ï¿½ . The inverted index builder reads in the level tableï¿½ï¿½ and outputs a keyword list ï¿½ ï¿½ for each keyword ï¿½ in ï¿½ . Those keyword lists are stored in a B-tree structure that allows efficient implementation of the match operations. The index builder also generates a frequency table, which records the frequencies of keywords in ï¿½ , is read into memory by the initializer, and is stored as a hash table. The query engine accepts a keyword search, uses the frequency hash table to locate the smallest keyword list, executes the Indexed Lookup Eager, Scan Eager and the Stack algorithms and returns all SLCAs. For performance reasons, Dewey numbers are compressed. We introduce a level table ï¿½ï¿½ with ï¿½ entries where ï¿½ is the depth of the input tree. The entry ï¿½ï¿½ Â¦ ï¿½ Â§ denotes the maximum number of bits needed to store the ï¿½ -th component in a Dewey number, i.e., ï¿½ï¿½ Â¦ ï¿½ Â§ ï¿½ Â\u2020Â\u2022Â¦Â§Â¦ ï¿½ Â§Â¡, where ï¿½ is the number of children of the node at the level of ï¿½ ï¿½ Â£ that has the maximum number of children among all nodes at the same level. The root is at level Â£ ,ï¿½ï¿½ Â¦ Â£ Â§ ï¿½ Â£ 5 . In Â\u2020Â¢Â£Â©Â¤Â\u2022Â¦ï¿½Â§ Â¨ Â¡ general bytes are needed to store the Dewey number of a node at levelï¿½ . The tableï¿½ï¿½ level for Figure 1 is i 1 2 3 4 5 LT(i) 1 2 3 2 1 There are two types of B tree structures implemented in XK- Search; the first is for the Indexed Lookup Eager algorithm, the second is for the Scan Eager and the Stack algorithms. In the implementation of the Indexed Lookup Eager algorithm, we put all keyword lists in a single B+ tree where keywords are the primary key and Dewey numbers are the secondary key (See Figure 5 where 4 Of course the Dewey number of the node Â¡Â¢Â¤Â¢Â¡Â¢Â¡Â¢Â¡ would be changed accordingly. 5 We could have ï¿½ï¿½ Â¦ Â£ Â§ ï¿½ Â¡ . However, the root is conveniently represented by Â¡ . 0.1.2.1 Sports Club 0.1.1.2 Stud ents T A 0.1.1.0 0.1.2.2 0.1.3.0 0.1.4.0 each block can store up to four entries). No data values are associated with keys since the keys contain both keywords and Dewey numbers. Given a keyword ï¿½ and a Dewey number Â¨ , it takes a single range scan operation [11] to find the right and left match of Â¨ in the keyword list of ï¿½. Since B+ tree implementations usually buffer top level nodes of the B+ tree in memory, we assume the number of disk accesses for finding a match in a keyword list does not include the accesses to the non-leaf nodes in the B+ tree and is ï¿½Â¦ Â£ Â§. The number of disk accesses of the Indexed Lookup Eager is ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§ because for each nodeï¿½ï¿½ in ï¿½ï¿½ the IL algorithm needs to find a left and a right match in each one of the other ï¿½ ï¿½ Â£ keyword lists. Notice that the number of disk accesses of IL cannot be more than ï¿½ ï¿½ ï¿½ï¿½ï¿½Â¨ï¿½ where Â¨ï¿½ is the number of blocks of the keyword list ï¿½ï¿½. This is because the IL algorithm accesses all keyword lists strictly in order. In the implementation of the Scan Eager algorithm and the ï¿½Â¤ï¿½ï¿½ ï¿½ algorithm, the keys in the B+ tree are simply keywords. The data associated with each key ï¿½ is the list of Dewey numbers of the nodes directly containing the keyword ï¿½ (See Figure 4). All key- word lists are clustered. The number of disk accesses of Scan Eager or Stack ï¿½Â¦ï¿½ is ï¿½ where Â¨ï¿½ ï¿½ Â©ï¿½ Â£Â© ï¿½ ï¿½ï¿½ï¿½Â¨ï¿½Â§ . ï¿½ï¿½ is the average number of nodes in a disk block of ï¿½ï¿½ and Â¨ï¿½ï¿½Â¨ is the number of nodes Â£ in the keyword list ï¿½ï¿½ ï¿½ï¿½. depends on the page ï¿½ size , the depth of the XML tree ï¿½, and the maximum out-degrees of nodes at each ï¿½ï¿½ level. is at ï¿½ least ï¿½Â¦ Â© Â¢ï¿½Â£ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Â£ ï¿½Â§ï¿½Â¨ï¿½ Â¡ï¿½ where is the maximum out-degree of nodes at levelï¿½ . In our experiments, using the DBLP dataset, ï¿½ ï¿½ on average is around Â¤Â¡Â¡ . The full size keyword lists are not needed to compute SLCAs according to the following property Â¦ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½ï¿½Â§ ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¦ ï¿½Â¡Â©ï¿½Â¦ï¿½ï¿½Â§ï¿½ ï¿½ï¿½ï¿½ï¿½ Â¢ Â¢ Â¢ ï¿½ï¿½Â¡Â©ï¿½Â¦ï¿½ï¿½Â§Â§ where ï¿½Â¡Â©ï¿½Â¦ï¿½Â§ Â©ï¿½Â\u2020Â¡Â¤ï¿½ ï¿½ Â¢Â£ï¿½ ï¿½Â¤Â¡Â©Â¦ï¿½Â§. ï¿½ ï¿½Â¡Â©ï¿½Â¦ï¿½ï¿½Â§ is called the core-keyword list of the keyword ï¿½ï¿½. To turn a keyword ï¿½ list into a core-keyword list, the brute-force algorithm compares each node to every other node. Given any two Â¤ï¿½ï¿½Â¤ï¿½ nodes such Â¨Â©ï¿½Â¦Â¤ï¿½Â§ ï¿½ that Â¨Â©ï¿½Â¦Â¤ï¿½Â§, if is not an ancestor of Â¤ï¿½, then for any Â¤ such that Â¨Â©ï¿½Â¦Â¤Â§ ï¿½ Â¤ï¿½ Â¤ï¿½ Â¨Â©ï¿½Â¦Â¤ï¿½Â§, cannot be an ancestor of Â¤. IndexBuilder (Figure 6) uses an algorithm that produces all core-keyword lists in one pass of parsing an input XML document based on the above fact. The description of the algorithm is omitted to save space. 5. THE ALL LOWEST COMMON ANCES- TOR PROBLEM (ALCA) We can use the Indexed Lookup Eager algorithm to derive an efficient algorithm to find all LCAs, that is, LCAs for each combination of nodes in ï¿½ï¿½ through ï¿½ï¿½. Because an LCA is either an ancestor of a SLCA or is a SLCA itself, we can find all LCAs by walking up in the tree beginning from SLCAs. We solve the ALCA problem by first finding the list ï¿½ of all SLCAs and then for each Title Ben, Ben Ben Autonet, 0.1.1. 0.1.2. 0.2.0. 0.2.0 2.0 1.0 0.1 Input XML document T Ben, Ben, 0.3.0 .0.0 LevelTableBuilder level table LT IndexBuilder Class Class , , 0.3.1.0.0 0.1.0 0.1.1 Clas s, 0.1.2 Ben, 0.3.0.0.0 Clas s, 0.1.3 Clas s, 0.1.4 Class, CS2A, 0.1.2 0.1.1.0.0 Clas ses, 0.1 Dean, 0.0 John,0.0.0 Dea Instruct Instruc Instruc John, John, John, CS2A, CS3A, CS4A, CS5A, John, 0.1.1.0. 0.1.2.2. n, or, tor, tor, 0.1.0. 0.1.1. 0.1.2. 0.1.3.0. 0.1.4.0 0.0.0 0 0 0 .0 0.0 0.1.0.0 0.1.1.1 0.1.2.0 0.0 1.0 0.0 Particip John, OSP, ants, 0.2.0.0.0 0.3.1 0.2.0.0 Partici pants, 0.3.0.0 John, 0.2.0.0.0 Particip ants, 0.3.1.0 Sports Club, 0.3 Particip P2P, Proje Sch ants, 0.3. cts, ool, 0.3.1.0 0 0.2 0 Figure 5: B+ tree from the data of Figure 1 for Indexed Lookup Eager Algorithm Frequency table Btree (Keyword lists stored in Btree) Initializer Figure 6: XKSearch Architecture c P q.t P v a b v 1 ... r q.t+1 d v 3 v 2 Figure 7: Finding all LCAs Keyword Search Frequency hash table Answer Query Engine Â¤ ancestor of each Â¤ï¿½ node ï¿½ in check Â¤ whether is an LCA, as explained next. Â¤ï¿½ Let be a SLCA. Consider any Â¤ node that is an ancestor Â¤ï¿½ of (See Figure 7). If the subtree rooted Â¤ at contains a Â¤ï¿½ node with a keyword, say ï¿½ï¿½, that is not under Â¤ï¿½ node and is not an ancestor of Â¤ï¿½, Â¤ then is an LCA. To determine Â¤ whether contains such a node we use at most two lookups. The nodes under Â¤ but not under Â¤ï¿½ are divided into two parts by the path Â¤ï¿½ ï¿½ Â¤ from to Â¤ï¿½. Let ï¿½ node be the right match node Â¤ of ï¿½ï¿½ in (the keyword list of ï¿½ï¿½). If node ï¿½ is not Â¤ï¿½ under Â¤ï¿½ and is not under ï¿½ , then ï¿½ is in the left part ofï¿½ (otherwise ï¿½ would be Â¤ï¿½ under Â¤ï¿½ because is a SLCA) which Â¤ means is an LCA. Next, let ï¿½ be the child Â¤ of on the path from to Â¤ï¿½. If the Dewey id of Â¤ is Â\u2020 then the Dewey id of Â¤ ï¿½ Â\u2020 is Â¢Â¤ , Â¤ where is the ordinal number ï¿½ of among its siblings. The Â¡ node , which is the immediate right sibling ï¿½ of , has Dewey number Â\u2020 Â¢ ï¿½ Â¦Â¤ Â£ and is called the uncle node of Â¤ï¿½ under Â¤. Let ï¿½ be the Â§ right match node of Â¡ in ï¿½ï¿½. Â¤ ï¿½ If ï¿½, ï¿½ then is in the right side ï¿½ of , which Â¤ makes an LCA. The existence of any node containing a keyword ï¿½ï¿½ï¿½ from Â¢ Â¢ Â¢ under Â¤ but not under Â¤ï¿½ can be checked ï¿½ï¿½ï¿½ similarly. The subroutine ï¿½Â¡ ï¿½ï¿½ï¿½ï¿½ï¿½ Â¢ in Algorithm 3 is based on the above observations. Since a Â¤ node might be an ancestor node of multiple SLCAs, we want to avoid repeatedly checking Â¤ whether is an LCA. Instead of maintaining some data structures to record whether a node has been identified as an LCA or not, we use an approach that only needs to keep three nodes in memory. Â¤ï¿½ï¿½Â¤ï¿½ï¿½Â¤Â¤ Let be the first three nodes (see Figure 7) in listï¿½ the of SLCAs produced by the Eager algorithm, and Â© ï¿½ let ï¿½ï¿½ï¿½ Â¦Â¤ï¿½ï¿½Â¤ï¿½Â§. For each Â¤ node in the path Â¤ï¿½ from to Â©, we check Â¤ whether is an LCA or not. Then s Title, 0.1.2.2 Spor tsCl ub, 0.3 Stude nts, 0.1.2. 1 Titl TA, e, Title, 0.1. Title, Title, 0.1. 0.1.2. 1.2 0.1.3.0 0.1.4.0 1.0 2 we check each node in the path from Â¤ï¿½ to ï¿½ ï¿½ ï¿½ï¿½ï¿½ Â¦Â¤ï¿½ï¿½Â¤Â¤Â§ 6 , and so on. Algorithm 3 is based on this approach and guarantees that each of the ancestor nodes of all SLCAs is checked exactly once. Notice that in Algorithm 3 we do not need to produce all SLCAs first. Algorithm 3 pipelines the delivery of LCAs since Algorithm IL pipelines the delivery of SLCAs. The number of disk accesses of Algorithm 3 is ï¿½Â¦ï¿½ï¿½Â¨ï¿½ï¿½Â¨Â§. The main memory complexity of Algorithm 3 is ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ï¿½ ï¿½Â\u2022Â¦Â§ Â¨ï¿½Â¨Â§. Finding all SLCAs costs ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ï¿½Â\u2022Â¦Â§ Â¨ï¿½Â¨Â§. Checking whether the ancestors of the ï¿½ï¿½ï¿½ Â¢ï¿½ are LCAs or not costs ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½ï¿½ ï¿½Â\u2022Â¦Â§ Â¨ï¿½Â¨Â§ since we need to check ï¿½Â¦Â¨ï¿½ï¿½Â¨ï¿½Â§ nodes and checking each node costs ï¿½Â¦ï¿½ï¿½Â\u2022Â¦Â§ Â¨ï¿½Â¨Â§. ALGORITHM 3 (COMPUTING ALL LCAS). findLCA(List L) Â¢ //ï¿½ is the list of SLCAs Â¤ï¿½ ï¿½ Â¤ï¿½ ï¿½ Â©ï¿½Â\u2020Â¡Â¤ï¿½Â¢ ï¿½ ï¿½ ï¿½Â¦ï¿½Â§; = removeHead(ï¿½); Â¤ï¿½ current-lca=lca(Â¤ï¿½,Â¤ï¿½); for each ancestor Â¤ node Â¤ï¿½ of until current-lca //not including current-lca if (checkLCA(Â¤,Â¤ï¿½)==true) output Â¤. has more nodes Â¢ Â¤ï¿½ = Â¤ï¿½; whileï¿½ Â£ Â£ boolean checkLCA( Â¢ Â¤ï¿½Â¤ï¿½) forï¿½ ï¿½ Â£ ï¿½ Â¢ to ï¿½= rm(Â¤, ï¿½ï¿½) (ï¿½ Â¡ Â¤ï¿½ ï¿½ï¿½ Â¤ï¿½ Â¡ ï¿½ if ) return Â£ true; forï¿½ ï¿½ Â£ ï¿½ Â¢ to ï¿½= the uncle node Â¤ï¿½ of under ï¿½ Â¤; Â©Â\u2020Â¦ï¿½ï¿½ï¿½ï¿½Â§; ï¿½ (Â¤ ï¿½ ï¿½ if ) return Â£ true; return false; Â£ "},{"aspect":"expcomparison","tweet":" We evaluate the Scan Eager, Indexed Lookup Eager and Stack algorithms discussed in Section 4 for the SLCA semantics by varying the number and frequencies of keywords both on hot cache (Figures 8, 9 and 10) and on cold cache (Figures 11, 12 and 13). A program randomly chose forty queries for each experiment. The response time of each experiment on hot cache in Figures 8, 9 could be a descendent of Â©. 6ï¿½ 7 http://www.informatik.uni-trier.de/Â£ley/db # of disk main memory operations main memory accesses # ï¿½ï¿½ï¿½ #ï¿½ï¿½ operations ï¿½ï¿½ï¿½ Â£ ï¿½ï¿½Â£Â¤ # Dewey number compar- complexity operations isons ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§ ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§ Â¨ï¿½Â¨Â§ ï¿½Â¦ï¿½ï¿½Â¨ï¿½ï¿½Â¨Â\u2022Â¦Â§ Â¨ï¿½Â¨Â§ IL ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§ Â§ ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§ ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â§ ï¿½Â¦ï¿½Â¨ï¿½Â¨Â§ ï¿½Â¦ï¿½ï¿½Â¨ï¿½Â¨Â§ ï¿½Â¦ï¿½ ï¿½Â¦ï¿½Â¨ï¿½ï¿½Â¨Â\u2022Â¦Â§ Â§ ï¿½Â¦ï¿½Â¨ï¿½Â¨Â§ ï¿½Â¦ï¿½Â¨ï¿½Â¨Â§ ï¿½Â¦ï¿½ï¿½Â¨ï¿½Â¨Â§ ï¿½Â¦ï¿½ Scan Stack \u201a€“ Table 1: Complexity Analysis for Indexed Lookup Eager, Scan Eager and Stack where Â¨ï¿½ï¿½Â¨ (Â¨ï¿½Â¨) is the minimum (maximum) size of keyword lists ï¿½ï¿½ through ï¿½ï¿½, ï¿½ is the total number of blocks of all keyword lists on disk and ï¿½ is the maximum depth of the tree. and 10 is the average of the corresponding forty queries after five executions. The response time of each experiment on cold cache in Figures 11, 12 and 13 is the average of the corresponding forty queries each of which was run just once after a machine reboot. In Figure 8 each Â\u2020 query contains two keywords. The smaller frequency is shown in the caption while the bigger frequency is variable. For example, each query of Figure 8(c) in the \u201a€œFrequency of the large list=1000\u201a€ category contains two keywords where one of them has frequency of Â£Â¡Â¡ while the other keyword has frequency of Â£Â¡Â¡Â¡ . As can be seen from Figure 8, the performance of the Scan Eager and Stack algorithms degrades linearly when the size of the large keyword list increases, while the run time for IL algorithm is essentially constant and its performance is often several orders of magnitude better than Scan Eager and Stack. In all experiments Scan Eager performs a little better than Stack for the reasons explained in Section 3.3. In Figure 9, each Â\u2020 query contains a keyword of \u201a€œsmall\u201a€ frequency ( Â£Â¡ in Figure 9(a), Â£Â¡Â¡ in Figure 9(b), Â£Â¡Â¡Â¡ in Figure Â£Â¡Â¡Â¡Â¡ 9(c), in Figure 9(d)) and all other keywords Â\u2020 of have frequency of Â£Â¡Â¡Â¡Â¡Â¡ . For example, each query of Figure 9(b) in Â\u2020ï¿½ï¿½ï¿½ the ï¿½ ï¿½ Â¡ category contains five keywords where one of ï¿½Â¡Â©ï¿½ them has frequency of Â£Â¡Â¡ and the other four have frequency Â£Â¡Â¡Â¡Â¡Â¡ of . The performance of the Scan Eager and the Stack algorithms is essentially independent of Â¨ï¿½ï¿½Â¨. Keywords in Figure 10 have the frequencies shown in the caption. The Scan Eager and the Stack algorithms perform a little better than the Indexed Lookup Eager algorithm in most experiments since the Indexed Lookup Eager performs best when the frequencies of keyword lists vary greatly, while all keyword lists in Figure 10 have the same size and the cost of index lookups is more likely greater than the cost of a single scan. We repeated the experiments in Figures 8, 9 and 10 with cold cache and the results are reported in Figures 11, 12 and 13 respectively. We see similar relationships among the Scan Eager, Indexed Lookup Eager and Stack algorithms. However the differences between the performance of algorithms is not as significant as those in the hot cache experiments. The reason is that most keyword lists do not take many pages. Hence making a random access on the list is effectively equivalent to fetching the complete list. Notice that disk access time dominates any main memory cost as can be seen from the significant response time increases from the hot cache experiments to the cold cache experiments. We implemented XKSearchB that stores Dewey numbers without using a level table as discussed in Section 4. Experiments show that the size of the keyword lists and the time to construct them are proportional to the size of the input XML documents. On average, the size of indexes constructed by XKSearch Â¢Â¡Â£ is of XKSearchB; the construction time of XKSearch Â¡Â¡Â£ is of XK- SearchB; the query response time of XKSearch for hot cache is 70% of XKSearchB for the queries in Figures 8, 9 and 10. "}]}